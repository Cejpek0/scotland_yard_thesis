   @BOOK{DeepBlue,
      author =       "Monty Newborn",
      title =        "Kasparov versus deep blue: computer chess comes of age",
      publisher =    "Springer-VerlagBerlin, Heidelberg",
      year =         "1996",
      isbn =         "978-0-387-94820-1",
      edition =      "1",
    }

  @WEBPAGE{Dota2,
      author =       "OpenAI",
      title =        "OpenAI Five defeats Dota 2 world champions",
      howpublished = "online",
      year =         "2019",
      url =          "https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)",
      cited =        "2024-03-18"
    }

    @WEBPAGE{AlphaGo,
      author =       "Steven Borowiec",
      title =        "AlphaGo seals 4-1 victory over Go grandmaster Lee Sedol",
      howpublished = "online",
      year =         "2019",
      url =          "https://www.theguardian.com/technology/2016/mar/15/googles-alphago-seals-4-1-victory-over-grandmaster-lee-sedol",
      cited =        "2024-03-18"
    }

    @WEBPAGE{ScotlandYardRules,
    title =        "Scotland Yard Board Game Review and Rules",
    howpublished = "online",
    url =          "https://www.ultraboardgames.com/scotland-yard/game-rules.php",
    cited =        "2024-03-18"
    }

    @mastersthesis{Manille,
      author  = {Jonas Baes},
      school  = {UGent. Faculteit Ingenieurswetenschappen en Architectuur.},
      title   = {Application of Reinforcement Learning Algorithms to the Card Game Manille},
      year    = {2022}
    }

   @misc{PPO_Hide_Seek,
      title={Emergent Tool Use From Multi-Agent Autocurricula}, 
      author={Bowen Baker and Ingmar Kanitscheider and Todor Markov and Yi Wu and Glenn Powell and Bob McGrew and Igor Mordatch},
      year={2020},
      eprint={1909.07528},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
    }

  @techreport{Games_with_Incomplete_Information,
    author      = {Jonathan Levin},
    institution = {Stanford Graduate School of Business},
    title       = {Games of Incomplete Information},
    year        = {2002}
  }

  @techreport{Dynamic_Games_with_Incomplete_Informatio,
    author      = {Jonathan Levin},
    institution = {Stanford Graduate School of Business},
    title       = {Dynamic Games with Incomplete Information},
    year        = {2002}
  }
  
  @article{JOHN_C_HARSANYI,
    author  = {JOHN C HARSANYI},
    journal = {MANAGEMENT SCIENCE},
    number  = {3},
    title   = {GAMES WITH INCOMPLETE INFORMATION PLAYED BY "BAYESIAN" PLAYERS, I-III},
    volume  = {14},
    year    = {1967},
    month   = {11},
    location    = {University of California, Berkeley},
    language    = {english},
    url         = {http://www.dklevine.com/archive/refs41175.pdf},
    urldate     = {2024-03-19}

  }

  @webpage{Y_Narahari,
    author = {Y. Narahari},
    title = {Game Theory},
    howpublished = "online",
    year = {2012},
    url = {https://gtl.csa.iisc.ac.in/gametheory/ln/web-ncp13-bayesian.pdf},
    cited = {2024-03-19},
    institution = {Indian Institute of Science}
  }

  @article{Perolat_2022,
   title={Mastering the game of Stratego with model-free multiagent reinforcement learning},
   volume={378},
   ISSN={1095-9203},
   url={http://dx.doi.org/10.1126/science.add4679},
   DOI={10.1126/science.add4679},
   number={6623},
   journal={Science},
   publisher={American Association for the Advancement of Science (AAAS)},
   author={Perolat, Julien and De Vylder, Bart and Hennes, Daniel and Tarassov, Eugene and Strub, Florian and de Boer, Vincent and Muller, Paul and Connor, Jerome T. and Burch, Neil and Anthony, Thomas and McAleer, Stephen and Elie, Romuald and Cen, Sarah H. and Wang, Zhe and Gruslys, Audrunas and Malysheva, Aleksandra and Khan, Mina and Ozair, Sherjil and Timbers, Finbarr and Pohlen, Toby and Eccles, Tom and Rowland, Mark and Lanctot, Marc and Lespiau, Jean-Baptiste and Piot, Bilal and Omidshafiei, Shayegan and Lockhart, Edward and Sifre, Laurent and Beauguerlange, Nathalie and Munos, Remi and Silver, David and Singh, Satinder and Hassabis, Demis and Tuyls, Karl},
   year={2022},
   edition={1},
   month=dec, pages={990–996}
  }

  @webpage{Policies,
    author = {Thomas Carr},
    Reviewer = {Michal Aibin},
    title = {Policies in Reinforcement Learning},
    howpublished = "online",
    year = {2024},
    month = {March},
    url = {https://www.baeldung.com/cs/rl-deterministic-vs-stochastic-policies},
    cited = {2024-03-20}
  }

  @webpage{Stratego_image,
    author          = {Harry Guinness },
    journal         = {Popular Science},
    title           = {Here’s how a new AI mastered the tricky game of Stratego},
    year            = {2022 },
    howpublished    = "online",
    url             = {https://www.popsci.com/technology/ai-stratego/},
    cited           = {2024-03-20}
  }

  @webpage{scotland_original_image,
    author          = {Mliu92},
    title           = {Scotland Yard schematic},
    year            = {2023},
    howpublished    = "online",
    url             = {https://commons.wikimedia.org/wiki/File:Scotland_Yard_schematic.svg},
    cited           = {2024-03-20}
  }

  @webpage{RL_basics,
    author          = {Lilian Weng },
    title           = {A (Long) Peek into Reinforcement Learning },
    howpublished    = "online",
    year            = {2018 },
    month           = {February },
    url             = {https://lilianweng.github.io/posts/2018-02-19-rl-overview/#key-concepts},
    cited           = {2024-03-20}
  }

  @article{Exploitation_Exploration,
    doi = {10.1371/journal.pone.0095693},
    author = {Berger-Tal, Oded AND Nathan, Jonathan AND Meron, Ehud AND Saltz, David},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Exploration-Exploitation Dilemma: A Multidisciplinary Framework},
    year = {2014},
    month = {04},
    volume = {9},
    url = {https://doi.org/10.1371/journal.pone.0095693},
    pages = {1-8},
    abstract = {The trade-off between the need to obtain new knowledge and the need to use that knowledge to improve performance is one of the most basic trade-offs in nature, and optimal performance usually requires some balance between exploratory and exploitative behaviors. Researchers in many disciplines have been searching for the optimal solution to this dilemma. Here we present a novel model in which the exploration strategy itself is dynamic and varies with time in order to optimize a definite goal, such as the acquisition of energy, money, or prestige. Our model produced four very distinct phases: Knowledge establishment, Knowledge accumulation, Knowledge maintenance, and Knowledge exploitation, giving rise to a multidisciplinary framework that applies equally to humans, animals, and organizations. The framework can be used to explain a multitude of phenomena in various disciplines, such as the movement of animals in novel landscapes, the most efficient resource allocation for a start-up company, or the effects of old age on knowledge acquisition in humans.},
    number = {4},
    edition = {1},
}

@misc{GameSceneController,
  author       = {ChristianD37 (Youtube channel: CDcodes)},
  howpublished = {online},
  title        = {Game states},
  url = {https://github.com/ChristianD37/YoutubeTutorials/tree/master},
  year = {2021},
  month = {June},
  cited = {2024-03-20}
}

@website{Ray,
  author = {The Ray Team},
  url = {https://docs.ray.io},
  title = {Ray Documentation},
  year = {2024},
}

@webpage{Monte_Carlo_Tree_Search,
  author = {Rahul_Roy},
  title = {ML | Monte Carlo Tree Search (MCTS)},
  howpublished = "online",
  year = {2023},
  month = {May},
  url = {https://www.geeksforgeeks.org/ml-monte-carlo-tree-search-mcts/},
  cited = {2024-03-25}
}

   ---------------------------------------------------
