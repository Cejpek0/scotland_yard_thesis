{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 4000.0, "total_loss": 18.239287638664244}, "mr_x_policy": {"total_loss": 18.239287638664244, "policy_loss": -0.02674648277752567, "vf_loss": 9.432328927516938, "vf_loss_unclipped": 198567.046484375, "vf_explained_var": -0.00014229193329811095, "entropy": 1.356825239956379, "mean_kl_loss": 0.030533020874528062, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}, "cop_policy": {"total_loss": 8.827598696947097, "policy_loss": -0.03169588566670427, "vf_loss": 8.853311491012573, "vf_loss_unclipped": 104437.15952148437, "vf_explained_var": 0.0005940690636634827, "entropy": 1.3330684408545495, "mean_kl_loss": 0.029915109914591065, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 94.49999999980002, "episode_reward_min": -5366.829836830699, "episode_reward_mean": -674.1114266240902, "episode_len_mean": 28.06338028169014, "episode_media": {}, "episodes_this_iter": 142, "policy_reward_min": {"mr_x_policy": -3897.6666666666, "cop_policy": -2012.1875}, "policy_reward_max": {"mr_x_policy": 115.16666666719999, "cop_policy": 130.0}, "policy_reward_mean": {"mr_x_policy": -369.8967136149802, "cop_policy": -304.21471300910986}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-24.645833333100015, -1393.2649017652998, -407.0000000002, -999.7291666666002, -1090.2916666666001, -700.3124999997999, -1619.6666666666, -278.72023809539996, -220.02083333359997, 45.6666666668, -400.1874999999, -2641.333333333502, -2062.9553571431006, -1192.5178571429, -179.7619047617, -1002.0108225114994, -1285.2976190476004, -409.5887445890998, -1357.8333333333, -14.895833333199995, -1693.0208333332996, -1081.3333333328999, -421.095238096, -1110.9375, -306.89583333310003, -111.19913419979997, -706.7499999999, 89.2291666667, -806.0000000002, -113.70833333299998, -134.20833333340002, 73.59523809510002, -701.4999999996996, -703.7813852816, -311.7359307365, -1680.8749999999, -796.7922077925996, -720.1874999998, -3664.354166666399, -478.4154179158, 78.10416666690001, 15.166666666799998, -195.85714285720002, -601.8095238099004, -5366.829836830699, -100.0, -1979.0000000000002, -119.85416666700002, -307.0625000001, -517.6250000002004, -802.5059523809999, -516.5000000000999, -12.547619047900007, -894.3303571428002, -189.62797619089997, -695.6800595240002, -305.68749999979997, -905.3571428569992, -700.3541666666, -590.1666666671006, -1486.0442890453, -107.40692640729996, -209.89826839860004, -21.4999999999, -181.88244047659998, -100.0, -785.7142857143998, -387.1666666670999, -792.0833333328997, -800.7916666665999, -95.90476190460001, -381.27056277119993, -19.166666666399994, 84.43506493440002, -803.5476190477004, -191.90026640090002, -198.33333333349998, -613.5238095242001, -312.99999999979997, -307.43389943450006, -116.28571428589999, -4422.040178570798, -900.3571428572996, -39.74999999990001, -2031.6666666668996, -1150.8958333335006, -486.023809524, -407.7857142858, -151.45833333310003, -1402.6249999998001, -1309.3809523811003, -777.9241071428, -713.2943722949, -310.2083333334, -899.1125541130993, -1.6666666671000039, -602.4374999999998, -515.8333333334999, -785.7142857143996, 34.833333333599995, -516.7337662346, -2737.5745920751015, -605.2251082254002, -106.41666666679998, 26.5, -589.5952380951998, 94.49999999980002, -92.0833333333, 83.21428571410001, -14.928571429000023, -1180.5000000006, -205.6636904761, 87.69280719260003, -476.1466866469, -100.0, -115.45833333339999, -706.3749999994999, 18.95833333339999, -2783.9545454555014, -2263.3105717817007, -805.0416666661994, -411.2916666667, -1008.8030303037003, -1402.1666666663996, -221.83333333349998, -101.4166666667, -299.3333333333, -1105.7291666664003, -902.0208333329998, -1083.375, -1068.395833332799, -278.9999999999, -470.54166666669994, 5.25, -155.16666666630005, -82.95833333320002, -17.90476190520002, 22.958333333300004, -895.2500000000003, -207.43939393960002, -1055.1433566435996, 27.5], "episode_lengths": [24, 37, 28, 34, 33, 31, 41, 27, 26, 12, 28, 48, 45, 35, 26, 33, 37, 28, 37, 24, 39, 33, 28, 35, 27, 25, 31, 23, 32, 25, 22, 23, 31, 31, 27, 37, 32, 31, 54, 29, 23, 6, 26, 30, 67, 1, 39, 25, 27, 29, 32, 29, 24, 33, 26, 30, 27, 33, 31, 29, 37, 25, 26, 24, 26, 2, 32, 28, 32, 31, 25, 28, 24, 23, 31, 26, 26, 30, 27, 27, 25, 59, 33, 16, 43, 36, 29, 27, 15, 36, 37, 32, 31, 27, 32, 24, 29, 29, 32, 13, 29, 50, 30, 25, 9, 30, 23, 5, 23, 24, 36, 26, 23, 29, 2, 25, 31, 7, 47, 46, 32, 28, 34, 37, 26, 25, 4, 35, 32, 35, 35, 9, 13, 4, 26, 7, 24, 7, 32, 26, 34, 9], "policy_mr_x_policy_reward": [38.1666666669, -1014.8333333330996, -67.50000000019996, -1023.6666666666, -525.1666666666, -123.4999999998, -1471.6666666666, 102.3333333332, -47.8333333336, -84.3333333332, 66.00000000010003, -1769.8333333334997, -485.00000000020003, -817.0000000000001, 37.16666666690001, -727.5, -808.8333333332998, -238.9999999999, -1270.3333333333, -34.33333333319999, -953.3333333333003, -299.83333333290005, -455.00000000020003, -1137.0, -328.33333333310003, -140.33333333359997, -732.9999999999, 43.666666666699996, -439.0000000002, -174.33333333299998, -69.83333333339999, 42.333333333400006, -139.99999999970004, -447.8333333333, -332.6666666666, -699.9999999999001, -423.9999999999, 42.00000000019998, -1652.1666666664003, 94.33333333329999, 39.66666666689999, -92.3333333332, 40.50000000000001, -129.83333333320002, -3897.6666666666, -100.0, -1177.4999999999998, -152.66666666700002, -130.00000000010002, -562.0000000002004, -429.1666666667, -549.6666666662999, 44.33333333319999, -814.9999999999002, 95.66666666629999, -416.6666666668, 54.00000000020001, -334.6666666660001, -323.6666666666, -462.66666666709995, -608.6666666668999, -29.66666666650002, -33.66666666659998, -63.9999999999, 3.166666666300003, -100.0, -455.6666666666, -243.3333333334, 49.16666666710001, -524.6666666666001, -59.33333333300002, -42.50000000040002, -63.66666666640001, 63.99999999990002, -251.3333333333, 91.99999999989998, 38.1666666665, 43.833333333, -349.99999999979997, -231.66666666670002, 39.49999999989999, -2739.6666666662986, -762.3333333331998, -167.9999999999, -666.6666666669001, -269.3333333335, -569.6666666668001, -263.5, -67.8333333331, -829.4999999997997, -1342.6666666668002, -92.99999999989997, -551.3333333335001, -233.3333333334, -422.4999999998, 21.8333333329, -35.499999999999986, 57.00000000019999, -865.9999999997998, -85.1666666664, -541.6666666668, -1256.1666666665994, -231.6666666665, 65.33333333320002, -96.0, 60.666666667100024, 21.9999999998, -95.8333333333, 38.99999999989999, 60.0, -45.500000000600025, -245.33333333320002, 66.666666667, -194.83333333310003, -100.0, 63.1666666666, -245.49999999950006, -94.1666666666, -1615.6666666669003, -1684.6666666666997, 49.33333333380001, -253.1666666667, -742.0000000001, -979.6666666663999, -48.333333333500015, 73.3333333333, -199.3333333333, -844.1666666663999, -524.8333333329998, -709.4999999999999, 115.16666666719999, -86.4999999999, -388.6666666667, -98.5, -72.16666666630003, -92.3333333332, -39.33333333310001, -85.1666666667, -846.0000000000003, 68.00000000019999, -270.4999999998, -95.0], "policy_cop_policy_reward": [-62.8125, -378.43156843219987, -339.5, 23.9375, -565.125, -576.8125, -148.0, -381.0535714286, -172.1875, 130.0, -466.1875, -871.5, -1577.9553571429003, -375.51785714289997, -216.9285714286, -274.5108225114997, -476.4642857143, -170.58874458920008, -87.5, 19.4375, -739.6875, -781.5, 33.904761904199994, 26.0625, 21.4375, 29.1341991338, 26.25, 45.5625, -367.0, 60.625, -64.375, 31.261904761699995, -561.5, -255.94805194830002, 20.930735930100006, -980.875, -372.7922077927, -762.1875, -2012.1875, -572.7487512490997, 38.4375, 107.5, -236.35714285720002, -471.97619047669997, -1469.1631701641, 0.0, -801.5, 32.8125, -177.0625, 44.375, -373.3392857143, 33.166666666199994, -56.8809523811, -79.33035714290001, -285.29464285719996, -279.01339285719996, -359.6875, -570.6904761909998, -376.6875, -127.5, -877.3776223783999, -77.74025974079997, -176.23160173200006, 42.5, -185.0491071429, 0.0, -330.0476190478, -143.8333333337, -841.25, -276.125, -36.571428571599995, -338.7705627708, 44.5, 20.435064934499994, -552.2142857143999, -283.9002664008, -236.5, -657.3571428572, 37.0, -75.76723276779997, -155.7857142858, -1682.3735119044998, -138.02380952410007, 128.25, -1365.0, -881.5625, 83.6428571428, -144.2857142858, -83.625, -573.125, 33.2857142857, -684.9241071429, -161.9610389614, -76.875, -476.61255411329984, -23.5, -566.9375, -572.8333333336998, 80.28571428540006, 120.0, 24.93290043220001, -1481.4079254084995, -373.5584415589, -171.75, 122.5, -650.2619047622998, 72.5, 3.75, 44.2142857142, -74.92857142899997, -1135.0, 39.66964285710001, 21.0261405256, -281.3133533137999, 0.0, -178.625, -460.875, 113.125, -1168.2878787886002, -578.6439051149997, -854.375, -158.125, -266.8030303035998, -422.5, -173.5, -174.75, -100.0, -261.5625, -377.1875, -373.875, -1183.5625, -192.5, -81.875, 103.75, -83.0, 9.375, 21.4285714279, 108.125, -49.25, -275.43939393979997, -784.6433566437998, 122.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.188996969774585, "mean_inference_ms": 14.231270356525098, "mean_action_processing_ms": 0.26508725544596523, "mean_env_wait_ms": 0.11084443835787879, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005592930484825457, "StateBufferConnector_ms": 0.00508091819118446, "ViewRequirementAgentConnector_ms": 0.3306531570327114}}, "episode_reward_max": 94.49999999980002, "episode_reward_min": -5366.829836830699, "episode_reward_mean": -674.1114266240902, "episode_len_mean": 28.06338028169014, "episodes_this_iter": 142, "policy_reward_min": {"mr_x_policy": -3897.6666666666, "cop_policy": -2012.1875}, "policy_reward_max": {"mr_x_policy": 115.16666666719999, "cop_policy": 130.0}, "policy_reward_mean": {"mr_x_policy": -369.8967136149802, "cop_policy": -304.21471300910986}, "hist_stats": {"episode_reward": [-24.645833333100015, -1393.2649017652998, -407.0000000002, -999.7291666666002, -1090.2916666666001, -700.3124999997999, -1619.6666666666, -278.72023809539996, -220.02083333359997, 45.6666666668, -400.1874999999, -2641.333333333502, -2062.9553571431006, -1192.5178571429, -179.7619047617, -1002.0108225114994, -1285.2976190476004, -409.5887445890998, -1357.8333333333, -14.895833333199995, -1693.0208333332996, -1081.3333333328999, -421.095238096, -1110.9375, -306.89583333310003, -111.19913419979997, -706.7499999999, 89.2291666667, -806.0000000002, -113.70833333299998, -134.20833333340002, 73.59523809510002, -701.4999999996996, -703.7813852816, -311.7359307365, -1680.8749999999, -796.7922077925996, -720.1874999998, -3664.354166666399, -478.4154179158, 78.10416666690001, 15.166666666799998, -195.85714285720002, -601.8095238099004, -5366.829836830699, -100.0, -1979.0000000000002, -119.85416666700002, -307.0625000001, -517.6250000002004, -802.5059523809999, -516.5000000000999, -12.547619047900007, -894.3303571428002, -189.62797619089997, -695.6800595240002, -305.68749999979997, -905.3571428569992, -700.3541666666, -590.1666666671006, -1486.0442890453, -107.40692640729996, -209.89826839860004, -21.4999999999, -181.88244047659998, -100.0, -785.7142857143998, -387.1666666670999, -792.0833333328997, -800.7916666665999, -95.90476190460001, -381.27056277119993, -19.166666666399994, 84.43506493440002, -803.5476190477004, -191.90026640090002, -198.33333333349998, -613.5238095242001, -312.99999999979997, -307.43389943450006, -116.28571428589999, -4422.040178570798, -900.3571428572996, -39.74999999990001, -2031.6666666668996, -1150.8958333335006, -486.023809524, -407.7857142858, -151.45833333310003, -1402.6249999998001, -1309.3809523811003, -777.9241071428, -713.2943722949, -310.2083333334, -899.1125541130993, -1.6666666671000039, -602.4374999999998, -515.8333333334999, -785.7142857143996, 34.833333333599995, -516.7337662346, -2737.5745920751015, -605.2251082254002, -106.41666666679998, 26.5, -589.5952380951998, 94.49999999980002, -92.0833333333, 83.21428571410001, -14.928571429000023, -1180.5000000006, -205.6636904761, 87.69280719260003, -476.1466866469, -100.0, -115.45833333339999, -706.3749999994999, 18.95833333339999, -2783.9545454555014, -2263.3105717817007, -805.0416666661994, -411.2916666667, -1008.8030303037003, -1402.1666666663996, -221.83333333349998, -101.4166666667, -299.3333333333, -1105.7291666664003, -902.0208333329998, -1083.375, -1068.395833332799, -278.9999999999, -470.54166666669994, 5.25, -155.16666666630005, -82.95833333320002, -17.90476190520002, 22.958333333300004, -895.2500000000003, -207.43939393960002, -1055.1433566435996, 27.5], "episode_lengths": [24, 37, 28, 34, 33, 31, 41, 27, 26, 12, 28, 48, 45, 35, 26, 33, 37, 28, 37, 24, 39, 33, 28, 35, 27, 25, 31, 23, 32, 25, 22, 23, 31, 31, 27, 37, 32, 31, 54, 29, 23, 6, 26, 30, 67, 1, 39, 25, 27, 29, 32, 29, 24, 33, 26, 30, 27, 33, 31, 29, 37, 25, 26, 24, 26, 2, 32, 28, 32, 31, 25, 28, 24, 23, 31, 26, 26, 30, 27, 27, 25, 59, 33, 16, 43, 36, 29, 27, 15, 36, 37, 32, 31, 27, 32, 24, 29, 29, 32, 13, 29, 50, 30, 25, 9, 30, 23, 5, 23, 24, 36, 26, 23, 29, 2, 25, 31, 7, 47, 46, 32, 28, 34, 37, 26, 25, 4, 35, 32, 35, 35, 9, 13, 4, 26, 7, 24, 7, 32, 26, 34, 9], "policy_mr_x_policy_reward": [38.1666666669, -1014.8333333330996, -67.50000000019996, -1023.6666666666, -525.1666666666, -123.4999999998, -1471.6666666666, 102.3333333332, -47.8333333336, -84.3333333332, 66.00000000010003, -1769.8333333334997, -485.00000000020003, -817.0000000000001, 37.16666666690001, -727.5, -808.8333333332998, -238.9999999999, -1270.3333333333, -34.33333333319999, -953.3333333333003, -299.83333333290005, -455.00000000020003, -1137.0, -328.33333333310003, -140.33333333359997, -732.9999999999, 43.666666666699996, -439.0000000002, -174.33333333299998, -69.83333333339999, 42.333333333400006, -139.99999999970004, -447.8333333333, -332.6666666666, -699.9999999999001, -423.9999999999, 42.00000000019998, -1652.1666666664003, 94.33333333329999, 39.66666666689999, -92.3333333332, 40.50000000000001, -129.83333333320002, -3897.6666666666, -100.0, -1177.4999999999998, -152.66666666700002, -130.00000000010002, -562.0000000002004, -429.1666666667, -549.6666666662999, 44.33333333319999, -814.9999999999002, 95.66666666629999, -416.6666666668, 54.00000000020001, -334.6666666660001, -323.6666666666, -462.66666666709995, -608.6666666668999, -29.66666666650002, -33.66666666659998, -63.9999999999, 3.166666666300003, -100.0, -455.6666666666, -243.3333333334, 49.16666666710001, -524.6666666666001, -59.33333333300002, -42.50000000040002, -63.66666666640001, 63.99999999990002, -251.3333333333, 91.99999999989998, 38.1666666665, 43.833333333, -349.99999999979997, -231.66666666670002, 39.49999999989999, -2739.6666666662986, -762.3333333331998, -167.9999999999, -666.6666666669001, -269.3333333335, -569.6666666668001, -263.5, -67.8333333331, -829.4999999997997, -1342.6666666668002, -92.99999999989997, -551.3333333335001, -233.3333333334, -422.4999999998, 21.8333333329, -35.499999999999986, 57.00000000019999, -865.9999999997998, -85.1666666664, -541.6666666668, -1256.1666666665994, -231.6666666665, 65.33333333320002, -96.0, 60.666666667100024, 21.9999999998, -95.8333333333, 38.99999999989999, 60.0, -45.500000000600025, -245.33333333320002, 66.666666667, -194.83333333310003, -100.0, 63.1666666666, -245.49999999950006, -94.1666666666, -1615.6666666669003, -1684.6666666666997, 49.33333333380001, -253.1666666667, -742.0000000001, -979.6666666663999, -48.333333333500015, 73.3333333333, -199.3333333333, -844.1666666663999, -524.8333333329998, -709.4999999999999, 115.16666666719999, -86.4999999999, -388.6666666667, -98.5, -72.16666666630003, -92.3333333332, -39.33333333310001, -85.1666666667, -846.0000000000003, 68.00000000019999, -270.4999999998, -95.0], "policy_cop_policy_reward": [-62.8125, -378.43156843219987, -339.5, 23.9375, -565.125, -576.8125, -148.0, -381.0535714286, -172.1875, 130.0, -466.1875, -871.5, -1577.9553571429003, -375.51785714289997, -216.9285714286, -274.5108225114997, -476.4642857143, -170.58874458920008, -87.5, 19.4375, -739.6875, -781.5, 33.904761904199994, 26.0625, 21.4375, 29.1341991338, 26.25, 45.5625, -367.0, 60.625, -64.375, 31.261904761699995, -561.5, -255.94805194830002, 20.930735930100006, -980.875, -372.7922077927, -762.1875, -2012.1875, -572.7487512490997, 38.4375, 107.5, -236.35714285720002, -471.97619047669997, -1469.1631701641, 0.0, -801.5, 32.8125, -177.0625, 44.375, -373.3392857143, 33.166666666199994, -56.8809523811, -79.33035714290001, -285.29464285719996, -279.01339285719996, -359.6875, -570.6904761909998, -376.6875, -127.5, -877.3776223783999, -77.74025974079997, -176.23160173200006, 42.5, -185.0491071429, 0.0, -330.0476190478, -143.8333333337, -841.25, -276.125, -36.571428571599995, -338.7705627708, 44.5, 20.435064934499994, -552.2142857143999, -283.9002664008, -236.5, -657.3571428572, 37.0, -75.76723276779997, -155.7857142858, -1682.3735119044998, -138.02380952410007, 128.25, -1365.0, -881.5625, 83.6428571428, -144.2857142858, -83.625, -573.125, 33.2857142857, -684.9241071429, -161.9610389614, -76.875, -476.61255411329984, -23.5, -566.9375, -572.8333333336998, 80.28571428540006, 120.0, 24.93290043220001, -1481.4079254084995, -373.5584415589, -171.75, 122.5, -650.2619047622998, 72.5, 3.75, 44.2142857142, -74.92857142899997, -1135.0, 39.66964285710001, 21.0261405256, -281.3133533137999, 0.0, -178.625, -460.875, 113.125, -1168.2878787886002, -578.6439051149997, -854.375, -158.125, -266.8030303035998, -422.5, -173.5, -174.75, -100.0, -261.5625, -377.1875, -373.875, -1183.5625, -192.5, -81.875, 103.75, -83.0, 9.375, 21.4285714279, 108.125, -49.25, -275.43939393979997, -784.6433566437998, 122.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.188996969774585, "mean_inference_ms": 14.231270356525098, "mean_action_processing_ms": 0.26508725544596523, "mean_env_wait_ms": 0.11084443835787879, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005592930484825457, "StateBufferConnector_ms": 0.00508091819118446, "ViewRequirementAgentConnector_ms": 0.3306531570327114}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 0, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 54.46283843408185, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 4000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 8000, "timers": {"training_iteration_time_ms": 73444.575, "sample_time_ms": 63370.054, "synch_weights_time_ms": 24.503}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 8000, "num_agent_steps_trained": 0}, "done": true, "episodes_total": 142, "training_iteration": 1, "trial_id": "b7538_00000", "date": "2023-12-20_10-48-33", "timestamp": 1703065713, "time_this_iter_s": 73.47131586074829, "time_total_s": 73.47131586074829, "pid": 2964, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x0000016E06989510>", "policies_to_train": null, "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 100}, "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0.  0.  0. -1. -1.  0.], [24. 24. 24. 10. 10. 10. 10. 10. 10. 20.], (10,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1.], [24. 24. 24. 10. 10. 10. 10.], (7,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 73.47131586074829, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 8.976041666666665, "ram_util_percent": 65.540625, "gpu_util_percent0": 0.28125, "vram_util_percent0": 0.08820936414930557}}
