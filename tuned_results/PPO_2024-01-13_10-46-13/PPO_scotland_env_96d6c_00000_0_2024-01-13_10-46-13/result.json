{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2996.0, "total_loss": 19.417343298594158}, "mr_x_policy": {"total_loss": 19.417343298594158, "policy_loss": -0.0743461398058571, "vf_loss": 9.713275607426961, "vf_loss_unclipped": 31674.6861328125, "vf_explained_var": 0.0012730767329533895, "entropy": 1.3499395728111268, "mean_kl_loss": 0.03315697034057442, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}, "cop_policy": {"total_loss": 9.77178243001302, "policy_loss": -0.04411374945969631, "vf_loss": 9.809369071324666, "vf_loss_unclipped": 74963.25094401042, "vf_explained_var": 0.00019209583600362143, "entropy": 1.3151266117890676, "mean_kl_loss": 0.03263551633866074, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 950.6666666658999, "episode_reward_min": -1996.3333333337, "episode_reward_mean": -222.35294117657844, "episode_len_mean": 77.84313725490196, "episode_media": {}, "episodes_this_iter": 51, "policy_reward_min": {"mr_x_policy": -520.5000000002998, "cop_policy": -1587.5}, "policy_reward_max": {"mr_x_policy": 434.999999999, "cop_policy": 618.0}, "policy_reward_mean": {"mr_x_policy": -44.450980392264704, "cop_policy": -61.72108843537415}, "custom_metrics": {}, "hist_stats": {"episode_reward": [79.33333333409999, 911.8333333339999, -98.33333333339999, 327.6666666674, 407.8333333335, -374.6666666664, -821.3333333329999, 37.166666666600044, 509.3333333331999, 622.1666666655001, 53.49999999969996, 604.8333333332001, -99.3333333333, 33.49999999989997, 504.3333333328, 85.00000000029993, -121.3333333332, 70.66666666630002, 12.833333333500008, 238.16666666659995, -1114.5000000006999, -469.0000000011, -992.4999999995001, -840.0000000001, -1513.6666666654996, 950.6666666658999, 62.666666666700024, -102.16666666749994, 121.16666666670005, 206.66666666649996, 176.83333333280004, -276.9999999998, -65.49999999989998, -1668.0000000013, -634.6666666664996, -198.66666666650002, 72.33333333309997, -1494.5000000010002, -98.0, 350.33333333400003, -821.5000000006, -1512.3333333329, 832.6666666663999, -1426.833333334, 229.33333333249993, -266.00000000040006, -1996.3333333337, -1028.6666666661001, -3.3333333332999686, -356.1666666667, -446.5000000003001], "episode_lengths": [21, 100, 3, 107, 51, 8, 66, 114, 75, 102, 104, 100, 2, 73, 97, 107, 10, 61, 13, 29, 123, 70, 124, 111, 76, 104, 63, 103, 121, 100, 109, 56, 14, 118, 116, 5, 75, 132, 1, 59, 112, 110, 99, 78, 106, 59, 124, 123, 104, 17, 115], "policy_mr_x_policy_reward": [-96.66666666590001, 17.33333333399997, -98.33333333339999, 357.6666666674, -7.166666666499992, -174.6666666664, -219.83333333299998, -65.83333333339993, -215.66666666679998, 136.16666666550006, -167.0000000003, 229.83333333320002, -99.3333333333, -228.0000000001, 49.333333332799995, -477.99999999970004, -123.83333333319999, 157.16666666630002, -114.66666666649999, -62.83333333339999, 80.49999999929997, -300.5000000011, 363.0000000005, 267.4999999999, 50.333333334500026, 397.16666666590004, -471.33333333329995, 108.8333333325, 397.1666666667, 152.66666666650002, -18.166666667199983, 60.000000000200004, -199.99999999989998, -103.50000000130001, -113.66666666650002, -98.6666666665, -9.166666666899985, 434.999999999, -98.0, -95.16666666600001, -511.0000000006001, 69.66666666709997, 369.6666666664, -358.333333334, 40.83333333249997, -181.5000000004, -383.3333333337, -118.16666666610001, 224.66666666670002, -498.6666666667, -520.5000000002998], "policy_cop_policy_reward": [28.5, 131.0, 16.5, 493.0, 72.0, 329.5, 0.0, 0.0, -564.0, 440.0, 94.0, 196.5, 81.0, 137.5, -200.0, 0.0, 0.0, -239.5, 228.5, -590.5, -92.5, 397.5, -202.0, 251.5, 224.5, 249.0, 380.0, -35.5, 141.5, 296.0, 2.5, -78.0, 299.5, -145.5, 221.0, 0.0, 148.0, -40.0, 153.5, 61.5, 217.0, 176.5, -54.0, 324.5, 292.5, -98.0, 0.5, 100.0, -173.0, 68.5, 18.0, 15.5, 6.5, 105.5, 89.5, 155.0, 56.5, 557.5, -1587.5, -165.0, 63.5, -221.5, -10.5, 618.0, -1547.0, -426.5, -138.5, 169.5, -1138.5, -423.5, -1005.5, -135.0, 7.0, 135.0, 411.5, 127.0, 165.0, 242.0, -19.0, -248.0, 56.0, 15.0, -166.5, -124.5, 9.5, 162.0, -117.5, -499.5, 365.5, 329.0, -322.0, -190.5, 175.5, 13.0, 16.0, 105.5, -1185.0, -209.0, -170.5, -1157.5, 378.0, 258.5, -100.0, 0.0, 0.0, 245.0, -300.0, 136.5, -649.5, -1133.5, -146.5, 154.5, 141.0, 150.0, -171.0, -57.5, -82.0, -425.5, -1317.5, 161.0, -45.5, 328.0, 180.5, 43.0, 107.5, -1219.0, -169.5, 64.0, 294.0, -207.5, -76.0, 199.0, -1550.0, 411.5, -474.5, -204.0, -466.0, -240.5, -57.5, -164.0, -6.5, 25.0, 106.5, 11.0, -41.0, 328.5, -213.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8946547237702295, "mean_inference_ms": 7.6471870763693355, "mean_action_processing_ms": 0.2089369687340433, "mean_env_wait_ms": 0.242101523435822, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010443205880646659, "StateBufferConnector_ms": 0.009400133027720147, "ViewRequirementAgentConnector_ms": 0.46456342370709064}}, "episode_reward_max": 950.6666666658999, "episode_reward_min": -1996.3333333337, "episode_reward_mean": -222.35294117657844, "episode_len_mean": 77.84313725490196, "episodes_this_iter": 51, "policy_reward_min": {"mr_x_policy": -520.5000000002998, "cop_policy": -1587.5}, "policy_reward_max": {"mr_x_policy": 434.999999999, "cop_policy": 618.0}, "policy_reward_mean": {"mr_x_policy": -44.450980392264704, "cop_policy": -61.72108843537415}, "hist_stats": {"episode_reward": [79.33333333409999, 911.8333333339999, -98.33333333339999, 327.6666666674, 407.8333333335, -374.6666666664, -821.3333333329999, 37.166666666600044, 509.3333333331999, 622.1666666655001, 53.49999999969996, 604.8333333332001, -99.3333333333, 33.49999999989997, 504.3333333328, 85.00000000029993, -121.3333333332, 70.66666666630002, 12.833333333500008, 238.16666666659995, -1114.5000000006999, -469.0000000011, -992.4999999995001, -840.0000000001, -1513.6666666654996, 950.6666666658999, 62.666666666700024, -102.16666666749994, 121.16666666670005, 206.66666666649996, 176.83333333280004, -276.9999999998, -65.49999999989998, -1668.0000000013, -634.6666666664996, -198.66666666650002, 72.33333333309997, -1494.5000000010002, -98.0, 350.33333333400003, -821.5000000006, -1512.3333333329, 832.6666666663999, -1426.833333334, 229.33333333249993, -266.00000000040006, -1996.3333333337, -1028.6666666661001, -3.3333333332999686, -356.1666666667, -446.5000000003001], "episode_lengths": [21, 100, 3, 107, 51, 8, 66, 114, 75, 102, 104, 100, 2, 73, 97, 107, 10, 61, 13, 29, 123, 70, 124, 111, 76, 104, 63, 103, 121, 100, 109, 56, 14, 118, 116, 5, 75, 132, 1, 59, 112, 110, 99, 78, 106, 59, 124, 123, 104, 17, 115], "policy_mr_x_policy_reward": [-96.66666666590001, 17.33333333399997, -98.33333333339999, 357.6666666674, -7.166666666499992, -174.6666666664, -219.83333333299998, -65.83333333339993, -215.66666666679998, 136.16666666550006, -167.0000000003, 229.83333333320002, -99.3333333333, -228.0000000001, 49.333333332799995, -477.99999999970004, -123.83333333319999, 157.16666666630002, -114.66666666649999, -62.83333333339999, 80.49999999929997, -300.5000000011, 363.0000000005, 267.4999999999, 50.333333334500026, 397.16666666590004, -471.33333333329995, 108.8333333325, 397.1666666667, 152.66666666650002, -18.166666667199983, 60.000000000200004, -199.99999999989998, -103.50000000130001, -113.66666666650002, -98.6666666665, -9.166666666899985, 434.999999999, -98.0, -95.16666666600001, -511.0000000006001, 69.66666666709997, 369.6666666664, -358.333333334, 40.83333333249997, -181.5000000004, -383.3333333337, -118.16666666610001, 224.66666666670002, -498.6666666667, -520.5000000002998], "policy_cop_policy_reward": [28.5, 131.0, 16.5, 493.0, 72.0, 329.5, 0.0, 0.0, -564.0, 440.0, 94.0, 196.5, 81.0, 137.5, -200.0, 0.0, 0.0, -239.5, 228.5, -590.5, -92.5, 397.5, -202.0, 251.5, 224.5, 249.0, 380.0, -35.5, 141.5, 296.0, 2.5, -78.0, 299.5, -145.5, 221.0, 0.0, 148.0, -40.0, 153.5, 61.5, 217.0, 176.5, -54.0, 324.5, 292.5, -98.0, 0.5, 100.0, -173.0, 68.5, 18.0, 15.5, 6.5, 105.5, 89.5, 155.0, 56.5, 557.5, -1587.5, -165.0, 63.5, -221.5, -10.5, 618.0, -1547.0, -426.5, -138.5, 169.5, -1138.5, -423.5, -1005.5, -135.0, 7.0, 135.0, 411.5, 127.0, 165.0, 242.0, -19.0, -248.0, 56.0, 15.0, -166.5, -124.5, 9.5, 162.0, -117.5, -499.5, 365.5, 329.0, -322.0, -190.5, 175.5, 13.0, 16.0, 105.5, -1185.0, -209.0, -170.5, -1157.5, 378.0, 258.5, -100.0, 0.0, 0.0, 245.0, -300.0, 136.5, -649.5, -1133.5, -146.5, 154.5, 141.0, 150.0, -171.0, -57.5, -82.0, -425.5, -1317.5, 161.0, -45.5, 328.0, 180.5, 43.0, 107.5, -1219.0, -169.5, 64.0, 294.0, -207.5, -76.0, 199.0, -1550.0, 411.5, -474.5, -204.0, -466.0, -240.5, -57.5, -164.0, -6.5, 25.0, 106.5, 11.0, -41.0, 328.5, -213.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8946547237702295, "mean_inference_ms": 7.6471870763693355, "mean_action_processing_ms": 0.2089369687340433, "mean_env_wait_ms": 0.242101523435822, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010443205880646659, "StateBufferConnector_ms": 0.009400133027720147, "ViewRequirementAgentConnector_ms": 0.46456342370709064}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 94.45223845376363, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 4000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 3997, "timers": {"training_iteration_time_ms": 42349.446, "sample_time_ms": 36155.397, "synch_weights_time_ms": 10.72}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 51, "training_iteration": 1, "trial_id": "96d6c_00000", "date": "2024-01-13_10-47-14", "timestamp": 1705139234, "time_this_iter_s": 42.363834381103516, "time_total_s": 42.363834381103516, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F4940>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 42.363834381103516, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 18.138181818181817, "ram_util_percent": 69.17090909090908, "gpu_util_percent0": 0.1430909090909091, "vram_util_percent0": 0.08650568181818177}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2983.0, "total_loss": 19.290441767374674}, "mr_x_policy": {"total_loss": 19.290441767374674, "policy_loss": -0.07321339620587726, "vf_loss": 9.651367457707723, "vf_loss_unclipped": 15868.616438802082, "vf_explained_var": 0.002400761842727661, "entropy": 1.3289176126321156, "mean_kl_loss": 0.02350139212042753, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.45000001788139343}, "cop_policy": {"total_loss": 9.705237038930257, "policy_loss": -0.033265773214710255, "vf_loss": 9.733422342936198, "vf_loss_unclipped": 29874.674251302084, "vf_explained_var": -0.001398812731107076, "entropy": 1.3017168402671815, "mean_kl_loss": 0.016935092762590406, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 950.6666666658999, "episode_reward_min": -1996.3333333337, "episode_reward_mean": -30.485000000124987, "episode_len_mean": 74.2, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -549.4999999996999, "cop_policy": -1587.5}, "policy_reward_max": {"mr_x_policy": 434.999999999, "cop_policy": 618.0}, "policy_reward_mean": {"mr_x_policy": -29.710000000124996, "cop_policy": -0.2700348432055749}, "custom_metrics": {}, "hist_stats": {"episode_reward": [622.1666666655001, 53.49999999969996, 604.8333333332001, -99.3333333333, 33.49999999989997, 504.3333333328, 85.00000000029993, -121.3333333332, 70.66666666630002, 12.833333333500008, 238.16666666659995, -1114.5000000006999, -469.0000000011, -992.4999999995001, -840.0000000001, -1513.6666666654996, 950.6666666658999, 62.666666666700024, -102.16666666749994, 121.16666666670005, 206.66666666649996, 176.83333333280004, -276.9999999998, -65.49999999989998, -1668.0000000013, -634.6666666664996, -198.66666666650002, 72.33333333309997, -1494.5000000010002, -98.0, 350.33333333400003, -821.5000000006, -1512.3333333329, 832.6666666663999, -1426.833333334, 229.33333333249993, -266.00000000040006, -1996.3333333337, -1028.6666666661001, -3.3333333332999686, -356.1666666667, -446.5000000003001, 93.00000000030002, -98.6666666665, 281.4999999998, -144.99999999960002, 159.0000000002, -148.1666666663, -376.1666666671, 473.99999999989996, 443.16666666649996, -100.0, 519.8333333338, 57.8333333331, -62.66666666660001, -184.49999999970004, 101.49999999969998, 633.6666666670002, 103.49999999970001, 39.0, 833.5000000009999, 152.49999999930006, 355.8333333326, 548.3333333329001, 530.6666666671001, 110.3333333317, -12.333333333899972, 51.83333333350001, 112.8333333321, 345.833333332, -4.833333333000056, -266.3333333335999, -194.4999999992001, -93.9999999999, 275.83333333360014, 68.99999999939999, 182.66666666630002, -148.3333333332, 382.0000000003, 224.16666666630005, -245.8333333339, 318.66666666699996, -309.9999999996, 525.1666666663002, 464.99999999999994, 177.00000000019998, 737.3333333342998, -813.4999999996, 586.6666666671, 820.1666666650001, -100.33333333339999, 342.8333333343, 59.66666666630006, 762.9999999998, 380.5000000000999, 447.33333333269997, -106.6666666667, 64.33333333319996, -103.9999999999, 17.166666666300017], "episode_lengths": [102, 104, 100, 2, 73, 97, 107, 10, 61, 13, 29, 123, 70, 124, 111, 76, 104, 63, 103, 121, 100, 109, 56, 14, 118, 116, 5, 75, 132, 1, 59, 112, 110, 99, 78, 106, 59, 124, 123, 104, 17, 115, 64, 2, 44, 52, 52, 28, 103, 106, 100, 1, 50, 21, 19, 104, 61, 100, 34, 18, 98, 91, 104, 103, 98, 104, 44, 14, 105, 96, 69, 65, 108, 5, 106, 63, 98, 41, 86, 52, 109, 52, 108, 100, 101, 33, 94, 105, 67, 98, 3, 101, 64, 95, 69, 88, 10, 79, 2, 108], "policy_mr_x_policy_reward": [136.16666666550006, -167.0000000003, 229.83333333320002, -99.3333333333, -228.0000000001, 49.333333332799995, -477.99999999970004, -123.83333333319999, 157.16666666630002, -114.66666666649999, -62.83333333339999, 80.49999999929997, -300.5000000011, 363.0000000005, 267.4999999999, 50.333333334500026, 397.16666666590004, -471.33333333329995, 108.8333333325, 397.1666666667, 152.66666666650002, -18.166666667199983, 60.000000000200004, -199.99999999989998, -103.50000000130001, -113.66666666650002, -98.6666666665, -9.166666666899985, 434.999999999, -98.0, -95.16666666600001, -511.0000000006001, 69.66666666709997, 369.6666666664, -358.333333334, 40.83333333249997, -181.5000000004, -383.3333333337, -118.16666666610001, 224.66666666670002, -498.6666666667, -520.5000000002998, -196.99999999969998, -98.6666666665, -32.50000000019999, -94.49999999959999, 15.00000000019999, -222.6666666663, 36.833333332900004, 136.99999999989998, -54.33333333350003, -100.0, -117.66666666620002, -171.6666666669, -62.666666666599994, -549.4999999996999, -83.50000000029999, -132.83333333300007, -76.0000000003, -121.0, 218.000000001, 195.49999999930003, 155.33333333259995, 359.8333333329, -76.8333333329, 85.33333333169999, -69.3333333339, -92.66666666649999, -328.66666666789996, -79.166666668, 37.16666666699997, -30.333333333599995, 364.0000000007999, -93.9999999999, -51.6666666664, -159.00000000059998, 99.1666666663, -127.33333333319999, -51.99999999969999, -108.83333333370001, -1.3333333339000246, -151.333333333, 328.0000000003999, -126.33333333370005, 207.49999999999997, -102.9999999998, 68.33333333430002, -298.49999999960005, 96.16666666710002, 347.66666666500004, -100.33333333339999, 250.83333333429997, -123.3333333337, 61.49999999980001, -146.99999999989998, 34.333333332700036, -211.1666666667, 152.83333333320002, -103.9999999999, 293.1666666663], "policy_cop_policy_reward": [380.0, -35.5, 141.5, 296.0, 2.5, -78.0, 299.5, -145.5, 221.0, 0.0, 148.0, -40.0, 153.5, 61.5, 217.0, 176.5, -54.0, 324.5, 292.5, -98.0, 0.5, 100.0, -173.0, 68.5, 18.0, 15.5, 6.5, 105.5, 89.5, 155.0, 56.5, 557.5, -1587.5, -165.0, 63.5, -221.5, -10.5, 618.0, -1547.0, -426.5, -138.5, 169.5, -1138.5, -423.5, -1005.5, -135.0, 7.0, 135.0, 411.5, 127.0, 165.0, 242.0, -19.0, -248.0, 56.0, 15.0, -166.5, -124.5, 9.5, 162.0, -117.5, -499.5, 365.5, 329.0, -322.0, -190.5, 175.5, 13.0, 16.0, 105.5, -1185.0, -209.0, -170.5, -1157.5, 378.0, 258.5, -100.0, 0.0, 0.0, 245.0, -300.0, 136.5, -649.5, -1133.5, -146.5, 154.5, 141.0, 150.0, -171.0, -57.5, -82.0, -425.5, -1317.5, 161.0, -45.5, 328.0, 180.5, 43.0, 107.5, -1219.0, -169.5, 64.0, 294.0, -207.5, -76.0, 199.0, -1550.0, 411.5, -474.5, -204.0, -466.0, -240.5, -57.5, -164.0, -6.5, 25.0, 106.5, 11.0, -41.0, 328.5, -213.5, 155.5, 126.5, 8.0, 0.0, 106.0, 214.5, -6.5, -41.0, -176.5, 167.0, -168.0, 70.5, 241.5, 133.0, -81.0, 22.5, 246.5, 172.0, -831.5, 430.5, -259.5, 166.0, 366.0, -73.0, 204.5, 244.0, 194.0, 199.5, 41.5, 62.0, 126.0, 46.5, -162.0, 115.5, -76.5, 139.0, 302.5, 20.0, 61.5, 103.5, 113.0, 226.5, 427.0, 43.5, 30.0, 106.0, 112.0, 21.0, 27.0, 283.0, -10.0, 342.5, -349.5, 137.5, 169.0, 382.5, 307.5, -489.5, 341.5, -226.5, 73.5, 158.0, 157.0, 292.5, 307.0, -162.5, -119.5, -35.5, 166.0, -73.5, 108.0, 17.0, 19.5, 380.0, -180.5, 242.0, 86.5, 176.0, 162.5, 174.5, 35.5, -252.0, -655.5, 271.0, 148.5, -364.0, -119.0, -75.5, 0.0, 0.0, 0.0, -326.0, 374.0, 279.5, -228.5, 167.5, 289.0, 160.5, 149.5, -226.5, -130.0, 130.5, -21.5, 192.5, 208.0, 33.5, 213.0, 128.5, -8.5, 237.0, -370.0, -111.5, 232.0, 93.5, 144.5, -974.5, 139.0, 197.5, 212.0, 131.0, 308.5, 262.0, 152.0, -156.5, 94.0, 128.0, 58.0, 113.5, 202.0, 353.5, -764.0, -13.0, 262.0, 124.5, 202.0, 164.0, -80.5, 368.5, 184.5, 0.0, 0.0, 321.0, -466.5, 237.5, 86.5, -47.0, 143.5, 231.0, 206.5, 264.0, 174.5, 125.0, 228.0, 269.5, 222.0, -78.5, 100.0, 2.5, 2.0, 149.5, -309.5, 71.5, 0.0, 36.0, 58.0, -370.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8153727796094614, "mean_inference_ms": 7.343314256195957, "mean_action_processing_ms": 0.18983074030869737, "mean_env_wait_ms": 0.2246233902368787, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008499140691275548, "StateBufferConnector_ms": 0.005173201512808752, "ViewRequirementAgentConnector_ms": 0.3937693557353935}}, "episode_reward_max": 950.6666666658999, "episode_reward_min": -1996.3333333337, "episode_reward_mean": -30.485000000124987, "episode_len_mean": 74.2, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -549.4999999996999, "cop_policy": -1587.5}, "policy_reward_max": {"mr_x_policy": 434.999999999, "cop_policy": 618.0}, "policy_reward_mean": {"mr_x_policy": -29.710000000124996, "cop_policy": -0.2700348432055749}, "hist_stats": {"episode_reward": [622.1666666655001, 53.49999999969996, 604.8333333332001, -99.3333333333, 33.49999999989997, 504.3333333328, 85.00000000029993, -121.3333333332, 70.66666666630002, 12.833333333500008, 238.16666666659995, -1114.5000000006999, -469.0000000011, -992.4999999995001, -840.0000000001, -1513.6666666654996, 950.6666666658999, 62.666666666700024, -102.16666666749994, 121.16666666670005, 206.66666666649996, 176.83333333280004, -276.9999999998, -65.49999999989998, -1668.0000000013, -634.6666666664996, -198.66666666650002, 72.33333333309997, -1494.5000000010002, -98.0, 350.33333333400003, -821.5000000006, -1512.3333333329, 832.6666666663999, -1426.833333334, 229.33333333249993, -266.00000000040006, -1996.3333333337, -1028.6666666661001, -3.3333333332999686, -356.1666666667, -446.5000000003001, 93.00000000030002, -98.6666666665, 281.4999999998, -144.99999999960002, 159.0000000002, -148.1666666663, -376.1666666671, 473.99999999989996, 443.16666666649996, -100.0, 519.8333333338, 57.8333333331, -62.66666666660001, -184.49999999970004, 101.49999999969998, 633.6666666670002, 103.49999999970001, 39.0, 833.5000000009999, 152.49999999930006, 355.8333333326, 548.3333333329001, 530.6666666671001, 110.3333333317, -12.333333333899972, 51.83333333350001, 112.8333333321, 345.833333332, -4.833333333000056, -266.3333333335999, -194.4999999992001, -93.9999999999, 275.83333333360014, 68.99999999939999, 182.66666666630002, -148.3333333332, 382.0000000003, 224.16666666630005, -245.8333333339, 318.66666666699996, -309.9999999996, 525.1666666663002, 464.99999999999994, 177.00000000019998, 737.3333333342998, -813.4999999996, 586.6666666671, 820.1666666650001, -100.33333333339999, 342.8333333343, 59.66666666630006, 762.9999999998, 380.5000000000999, 447.33333333269997, -106.6666666667, 64.33333333319996, -103.9999999999, 17.166666666300017], "episode_lengths": [102, 104, 100, 2, 73, 97, 107, 10, 61, 13, 29, 123, 70, 124, 111, 76, 104, 63, 103, 121, 100, 109, 56, 14, 118, 116, 5, 75, 132, 1, 59, 112, 110, 99, 78, 106, 59, 124, 123, 104, 17, 115, 64, 2, 44, 52, 52, 28, 103, 106, 100, 1, 50, 21, 19, 104, 61, 100, 34, 18, 98, 91, 104, 103, 98, 104, 44, 14, 105, 96, 69, 65, 108, 5, 106, 63, 98, 41, 86, 52, 109, 52, 108, 100, 101, 33, 94, 105, 67, 98, 3, 101, 64, 95, 69, 88, 10, 79, 2, 108], "policy_mr_x_policy_reward": [136.16666666550006, -167.0000000003, 229.83333333320002, -99.3333333333, -228.0000000001, 49.333333332799995, -477.99999999970004, -123.83333333319999, 157.16666666630002, -114.66666666649999, -62.83333333339999, 80.49999999929997, -300.5000000011, 363.0000000005, 267.4999999999, 50.333333334500026, 397.16666666590004, -471.33333333329995, 108.8333333325, 397.1666666667, 152.66666666650002, -18.166666667199983, 60.000000000200004, -199.99999999989998, -103.50000000130001, -113.66666666650002, -98.6666666665, -9.166666666899985, 434.999999999, -98.0, -95.16666666600001, -511.0000000006001, 69.66666666709997, 369.6666666664, -358.333333334, 40.83333333249997, -181.5000000004, -383.3333333337, -118.16666666610001, 224.66666666670002, -498.6666666667, -520.5000000002998, -196.99999999969998, -98.6666666665, -32.50000000019999, -94.49999999959999, 15.00000000019999, -222.6666666663, 36.833333332900004, 136.99999999989998, -54.33333333350003, -100.0, -117.66666666620002, -171.6666666669, -62.666666666599994, -549.4999999996999, -83.50000000029999, -132.83333333300007, -76.0000000003, -121.0, 218.000000001, 195.49999999930003, 155.33333333259995, 359.8333333329, -76.8333333329, 85.33333333169999, -69.3333333339, -92.66666666649999, -328.66666666789996, -79.166666668, 37.16666666699997, -30.333333333599995, 364.0000000007999, -93.9999999999, -51.6666666664, -159.00000000059998, 99.1666666663, -127.33333333319999, -51.99999999969999, -108.83333333370001, -1.3333333339000246, -151.333333333, 328.0000000003999, -126.33333333370005, 207.49999999999997, -102.9999999998, 68.33333333430002, -298.49999999960005, 96.16666666710002, 347.66666666500004, -100.33333333339999, 250.83333333429997, -123.3333333337, 61.49999999980001, -146.99999999989998, 34.333333332700036, -211.1666666667, 152.83333333320002, -103.9999999999, 293.1666666663], "policy_cop_policy_reward": [380.0, -35.5, 141.5, 296.0, 2.5, -78.0, 299.5, -145.5, 221.0, 0.0, 148.0, -40.0, 153.5, 61.5, 217.0, 176.5, -54.0, 324.5, 292.5, -98.0, 0.5, 100.0, -173.0, 68.5, 18.0, 15.5, 6.5, 105.5, 89.5, 155.0, 56.5, 557.5, -1587.5, -165.0, 63.5, -221.5, -10.5, 618.0, -1547.0, -426.5, -138.5, 169.5, -1138.5, -423.5, -1005.5, -135.0, 7.0, 135.0, 411.5, 127.0, 165.0, 242.0, -19.0, -248.0, 56.0, 15.0, -166.5, -124.5, 9.5, 162.0, -117.5, -499.5, 365.5, 329.0, -322.0, -190.5, 175.5, 13.0, 16.0, 105.5, -1185.0, -209.0, -170.5, -1157.5, 378.0, 258.5, -100.0, 0.0, 0.0, 245.0, -300.0, 136.5, -649.5, -1133.5, -146.5, 154.5, 141.0, 150.0, -171.0, -57.5, -82.0, -425.5, -1317.5, 161.0, -45.5, 328.0, 180.5, 43.0, 107.5, -1219.0, -169.5, 64.0, 294.0, -207.5, -76.0, 199.0, -1550.0, 411.5, -474.5, -204.0, -466.0, -240.5, -57.5, -164.0, -6.5, 25.0, 106.5, 11.0, -41.0, 328.5, -213.5, 155.5, 126.5, 8.0, 0.0, 106.0, 214.5, -6.5, -41.0, -176.5, 167.0, -168.0, 70.5, 241.5, 133.0, -81.0, 22.5, 246.5, 172.0, -831.5, 430.5, -259.5, 166.0, 366.0, -73.0, 204.5, 244.0, 194.0, 199.5, 41.5, 62.0, 126.0, 46.5, -162.0, 115.5, -76.5, 139.0, 302.5, 20.0, 61.5, 103.5, 113.0, 226.5, 427.0, 43.5, 30.0, 106.0, 112.0, 21.0, 27.0, 283.0, -10.0, 342.5, -349.5, 137.5, 169.0, 382.5, 307.5, -489.5, 341.5, -226.5, 73.5, 158.0, 157.0, 292.5, 307.0, -162.5, -119.5, -35.5, 166.0, -73.5, 108.0, 17.0, 19.5, 380.0, -180.5, 242.0, 86.5, 176.0, 162.5, 174.5, 35.5, -252.0, -655.5, 271.0, 148.5, -364.0, -119.0, -75.5, 0.0, 0.0, 0.0, -326.0, 374.0, 279.5, -228.5, 167.5, 289.0, 160.5, 149.5, -226.5, -130.0, 130.5, -21.5, 192.5, 208.0, 33.5, 213.0, 128.5, -8.5, 237.0, -370.0, -111.5, 232.0, 93.5, 144.5, -974.5, 139.0, 197.5, 212.0, 131.0, 308.5, 262.0, 152.0, -156.5, 94.0, 128.0, 58.0, 113.5, 202.0, 353.5, -764.0, -13.0, 262.0, 124.5, 202.0, 164.0, -80.5, 368.5, 184.5, 0.0, 0.0, 321.0, -466.5, 237.5, 86.5, -47.0, 143.5, 231.0, 206.5, 264.0, 174.5, 125.0, 228.0, 269.5, 222.0, -78.5, 100.0, 2.5, 2.0, 149.5, -309.5, 71.5, 0.0, 36.0, 58.0, -370.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.8153727796094614, "mean_inference_ms": 7.343314256195957, "mean_action_processing_ms": 0.18983074030869737, "mean_env_wait_ms": 0.2246233902368787, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.008499140691275548, "StateBufferConnector_ms": 0.005173201512808752, "ViewRequirementAgentConnector_ms": 0.3937693557353935}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.64326037463529, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 8000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 7997, "timers": {"training_iteration_time_ms": 39415.698, "sample_time_ms": 33232.23, "synch_weights_time_ms": 11.139}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 109, "training_iteration": 2, "trial_id": "96d6c_00000", "date": "2024-01-13_10-47-51", "timestamp": 1705139271, "time_this_iter_s": 36.49785327911377, "time_total_s": 78.86168766021729, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F4310>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 78.86168766021729, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 7.262499999999999, "ram_util_percent": 65.17291666666667, "gpu_util_percent0": 0.3041666666666667, "vram_util_percent0": 0.08772786458333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2976.0, "total_loss": 19.059308369954426}, "mr_x_policy": {"total_loss": 19.059308369954426, "policy_loss": -0.08013407908535251, "vf_loss": 9.442619768778483, "vf_loss_unclipped": 13933.525830078124, "vf_explained_var": 0.0002934525410334269, "entropy": 1.2996484955151877, "mean_kl_loss": 0.02391710609651151, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.675000011920929}, "cop_policy": {"total_loss": 9.6860599676768, "policy_loss": -0.02725156960465635, "vf_loss": 9.7089586575826, "vf_loss_unclipped": 28379.45431315104, "vf_explained_var": -0.002018426855405172, "entropy": 1.2971437672773998, "mean_kl_loss": 0.014510111906080663, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1066.1666666673, "episode_reward_min": -813.4999999996, "episode_reward_mean": 214.14999999994205, "episode_len_mean": 72.6, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"mr_x_policy": -328.66666666789996, "cop_policy": -1027.5}, "policy_reward_max": {"mr_x_policy": 429.3333333337999, "cop_policy": 564.5}, "policy_reward_mean": {"mr_x_policy": 1.6899999999419975, "cop_policy": 73.01030927835052}, "custom_metrics": {}, "hist_stats": {"episode_reward": [101.49999999969998, 633.6666666670002, 103.49999999970001, 39.0, 833.5000000009999, 152.49999999930006, 355.8333333326, 548.3333333329001, 530.6666666671001, 110.3333333317, -12.333333333899972, 51.83333333350001, 112.8333333321, 345.833333332, -4.833333333000056, -266.3333333335999, -194.4999999992001, -93.9999999999, 275.83333333360014, 68.99999999939999, 182.66666666630002, -148.3333333332, 382.0000000003, 224.16666666630005, -245.8333333339, 318.66666666699996, -309.9999999996, 525.1666666663002, 464.99999999999994, 177.00000000019998, 737.3333333342998, -813.4999999996, 586.6666666671, 820.1666666650001, -100.33333333339999, 342.8333333343, 59.66666666630006, 762.9999999998, 380.5000000000999, 447.33333333269997, -106.6666666667, 64.33333333319996, -103.9999999999, 17.166666666300017, 335.1666666663, 646.3333333339, 368.3333333336, -187.50000000040004, 259.5000000008, 281.1666666664, -12.333333331399942, 251.0000000005, 1020.0000000008, 95.33333333360002, 493.50000000159986, -21.33333333329999, 246.6666666667, 541.4999999985998, -559.6666666664, -244.83333333510012, 705.3333333330999, -101.0000000001, 691.6666666671, 40.166666667299964, 124.83333333280001, 1066.1666666673, -199.3333333333, 1005.8333333332001, -199.3333333333, -173.50000000010002, 19.833333333599995, 750.6666666663999, 403.1666666666, -417.5, -156.6666666671, 21.50000000010006, -114.49999999949999, 149.1666666663, -277.33333333359997, -242.8333333338, 0.8333333335001214, -125.1666666664, -663.1666666671999, 940.8333333333001, 567.8333333334, 953.4999999998998, 916.5000000003001, -246.0000000002001, 134.4999999995, -721.6666666681001, -203.3333333331, 913.3333333338003, 69.1666666667, 354.3333333332, 562.6666666657001, 364.00000000119985, 974.4999999995001, -111.1666666665, 940.6666666664, 826.4999999989001], "episode_lengths": [61, 100, 34, 18, 98, 91, 104, 103, 98, 104, 44, 14, 105, 96, 69, 65, 108, 5, 106, 63, 98, 41, 86, 52, 109, 52, 108, 100, 101, 33, 94, 105, 67, 98, 3, 101, 64, 95, 69, 88, 10, 79, 2, 108, 102, 101, 94, 104, 99, 97, 100, 86, 96, 42, 96, 16, 99, 101, 50, 102, 104, 5, 101, 102, 89, 97, 1, 99, 1, 15, 13, 97, 76, 16, 17, 100, 16, 38, 41, 66, 108, 56, 110, 96, 101, 96, 100, 89, 23, 77, 6, 99, 22, 64, 98, 89, 98, 10, 95, 95], "policy_mr_x_policy_reward": [-83.50000000029999, -132.83333333300007, -76.0000000003, -121.0, 218.000000001, 195.49999999930003, 155.33333333259995, 359.8333333329, -76.8333333329, 85.33333333169999, -69.3333333339, -92.66666666649999, -328.66666666789996, -79.166666668, 37.16666666699997, -30.333333333599995, 364.0000000007999, -93.9999999999, -51.6666666664, -159.00000000059998, 99.1666666663, -127.33333333319999, -51.99999999969999, -108.83333333370001, -1.3333333339000246, -151.333333333, 328.0000000003999, -126.33333333370005, 207.49999999999997, -102.9999999998, 68.33333333430002, -298.49999999960005, 96.16666666710002, 347.66666666500004, -100.33333333339999, 250.83333333429997, -123.3333333337, 61.49999999980001, -146.99999999989998, 34.333333332700036, -211.1666666667, 152.83333333320002, -103.9999999999, 293.1666666663, 83.66666666629999, -249.66666666610007, -9.666666666400005, 88.4999999996, 8.000000000799998, 66.16666666640002, -20.833333331399995, -322.4999999995, 93.00000000080001, -97.66666666639999, 82.00000000159999, -180.3333333333, -281.8333333333, 309.99999999860006, -61.16666666639999, -107.33333333510001, 335.8333333331001, -101.0000000001, 61.666666667099996, -289.8333333327001, -111.66666666719999, 266.66666666730003, -199.3333333333, -2.166666666800017, -199.3333333333, -110.0000000001, -107.6666666664, 292.66666666640003, 34.66666666660004, -133.0, -104.6666666671, -119.9999999999, -80.9999999995, -67.3333333337, -87.33333333360001, 58.66666666620006, 91.83333333350001, -99.66666666639999, 194.3333333328, 265.3333333333, 381.3333333334, 182.49999999990007, -20.999999999700044, -240.50000000019998, -95.0000000005, -64.66666666809999, -103.3333333331, 429.3333333337999, -158.3333333333, -95.6666666668, 80.6666666657, -15.999999998800007, 190.49999999949998, -115.1666666665, 141.66666666639998, 179.49999999890002], "policy_cop_policy_reward": [20.0, 61.5, 103.5, 113.0, 226.5, 427.0, 43.5, 30.0, 106.0, 112.0, 21.0, 27.0, 283.0, -10.0, 342.5, -349.5, 137.5, 169.0, 382.5, 307.5, -489.5, 341.5, -226.5, 73.5, 158.0, 157.0, 292.5, 307.0, -162.5, -119.5, -35.5, 166.0, -73.5, 108.0, 17.0, 19.5, 380.0, -180.5, 242.0, 86.5, 176.0, 162.5, 174.5, 35.5, -252.0, -655.5, 271.0, 148.5, -364.0, -119.0, -75.5, 0.0, 0.0, 0.0, -326.0, 374.0, 279.5, -228.5, 167.5, 289.0, 160.5, 149.5, -226.5, -130.0, 130.5, -21.5, 192.5, 208.0, 33.5, 213.0, 128.5, -8.5, 237.0, -370.0, -111.5, 232.0, 93.5, 144.5, -974.5, 139.0, 197.5, 212.0, 131.0, 308.5, 262.0, 152.0, -156.5, 94.0, 128.0, 58.0, 113.5, 202.0, 353.5, -764.0, -13.0, 262.0, 124.5, 202.0, 164.0, -80.5, 368.5, 184.5, 0.0, 0.0, 321.0, -466.5, 237.5, 86.5, -47.0, 143.5, 231.0, 206.5, 264.0, 174.5, 125.0, 228.0, 269.5, 222.0, -78.5, 100.0, 2.5, 2.0, 149.5, -309.5, 71.5, 0.0, 36.0, 58.0, -370.0, 216.5, 196.5, -161.5, 235.5, 228.0, 432.5, 170.0, 88.5, 119.5, 225.0, -136.5, -364.5, -275.0, 307.5, 219.0, 166.0, 47.5, 1.5, -116.0, 139.5, -15.0, 26.5, 282.5, 264.5, 343.0, 428.5, 155.5, 52.0, 78.0, 63.0, 141.0, 134.0, 136.5, 23.0, 110.0, 26.0, 84.5, 289.5, 154.5, 485.0, 89.0, -342.5, -388.0, 180.5, -291.0, -835.5, 328.0, 370.0, -31.5, 564.5, -163.5, 0.0, 0.0, 0.0, 174.5, 297.0, 158.5, 231.5, 122.0, -23.5, 324.0, 34.0, -121.5, 269.5, 489.5, 40.5, 526.0, 216.0, 266.0, -185.5, 16.5, 105.5, 100.5, 11.0, 16.0, 1.0, 155.5, 301.5, 192.5, -61.0, 237.0, -97.0, 3.5, -191.0, -96.0, 14.5, 29.5, 173.0, -72.0, 40.5, 110.0, -186.0, 42.5, 147.5, 69.5, -0.5, -313.0, -13.5, 136.5, -349.5, -101.0, 149.0, -187.5, 193.5, -97.0, 172.0, -348.0, 150.5, -103.0, -710.5, -44.0, 190.0, 236.5, 249.0, 91.0, -102.0, 197.5, 343.0, 94.0, 334.0, 214.5, 414.0, 309.0, -361.5, 108.0, 248.0, 51.0, 114.0, 64.5, -1027.5, 261.5, 109.0, -100.0, 0.0, 0.0, 268.0, 183.5, 32.5, 106.0, 56.5, 65.0, 138.0, 130.0, 182.0, -36.0, 209.0, 309.0, 236.5, -85.0, 228.5, 125.0, 340.0, 319.0, 1.0, 100.0, -97.0, 209.0, 359.0, 231.0, 111.5, 307.5, 228.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7308727393694047, "mean_inference_ms": 7.025589390369391, "mean_action_processing_ms": 0.16871731538120124, "mean_env_wait_ms": 0.2052573481514073, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007380499984278824, "StateBufferConnector_ms": 0.005719035562842784, "ViewRequirementAgentConnector_ms": 0.33197703987661037}}, "episode_reward_max": 1066.1666666673, "episode_reward_min": -813.4999999996, "episode_reward_mean": 214.14999999994205, "episode_len_mean": 72.6, "episodes_this_iter": 56, "policy_reward_min": {"mr_x_policy": -328.66666666789996, "cop_policy": -1027.5}, "policy_reward_max": {"mr_x_policy": 429.3333333337999, "cop_policy": 564.5}, "policy_reward_mean": {"mr_x_policy": 1.6899999999419975, "cop_policy": 73.01030927835052}, "hist_stats": {"episode_reward": [101.49999999969998, 633.6666666670002, 103.49999999970001, 39.0, 833.5000000009999, 152.49999999930006, 355.8333333326, 548.3333333329001, 530.6666666671001, 110.3333333317, -12.333333333899972, 51.83333333350001, 112.8333333321, 345.833333332, -4.833333333000056, -266.3333333335999, -194.4999999992001, -93.9999999999, 275.83333333360014, 68.99999999939999, 182.66666666630002, -148.3333333332, 382.0000000003, 224.16666666630005, -245.8333333339, 318.66666666699996, -309.9999999996, 525.1666666663002, 464.99999999999994, 177.00000000019998, 737.3333333342998, -813.4999999996, 586.6666666671, 820.1666666650001, -100.33333333339999, 342.8333333343, 59.66666666630006, 762.9999999998, 380.5000000000999, 447.33333333269997, -106.6666666667, 64.33333333319996, -103.9999999999, 17.166666666300017, 335.1666666663, 646.3333333339, 368.3333333336, -187.50000000040004, 259.5000000008, 281.1666666664, -12.333333331399942, 251.0000000005, 1020.0000000008, 95.33333333360002, 493.50000000159986, -21.33333333329999, 246.6666666667, 541.4999999985998, -559.6666666664, -244.83333333510012, 705.3333333330999, -101.0000000001, 691.6666666671, 40.166666667299964, 124.83333333280001, 1066.1666666673, -199.3333333333, 1005.8333333332001, -199.3333333333, -173.50000000010002, 19.833333333599995, 750.6666666663999, 403.1666666666, -417.5, -156.6666666671, 21.50000000010006, -114.49999999949999, 149.1666666663, -277.33333333359997, -242.8333333338, 0.8333333335001214, -125.1666666664, -663.1666666671999, 940.8333333333001, 567.8333333334, 953.4999999998998, 916.5000000003001, -246.0000000002001, 134.4999999995, -721.6666666681001, -203.3333333331, 913.3333333338003, 69.1666666667, 354.3333333332, 562.6666666657001, 364.00000000119985, 974.4999999995001, -111.1666666665, 940.6666666664, 826.4999999989001], "episode_lengths": [61, 100, 34, 18, 98, 91, 104, 103, 98, 104, 44, 14, 105, 96, 69, 65, 108, 5, 106, 63, 98, 41, 86, 52, 109, 52, 108, 100, 101, 33, 94, 105, 67, 98, 3, 101, 64, 95, 69, 88, 10, 79, 2, 108, 102, 101, 94, 104, 99, 97, 100, 86, 96, 42, 96, 16, 99, 101, 50, 102, 104, 5, 101, 102, 89, 97, 1, 99, 1, 15, 13, 97, 76, 16, 17, 100, 16, 38, 41, 66, 108, 56, 110, 96, 101, 96, 100, 89, 23, 77, 6, 99, 22, 64, 98, 89, 98, 10, 95, 95], "policy_mr_x_policy_reward": [-83.50000000029999, -132.83333333300007, -76.0000000003, -121.0, 218.000000001, 195.49999999930003, 155.33333333259995, 359.8333333329, -76.8333333329, 85.33333333169999, -69.3333333339, -92.66666666649999, -328.66666666789996, -79.166666668, 37.16666666699997, -30.333333333599995, 364.0000000007999, -93.9999999999, -51.6666666664, -159.00000000059998, 99.1666666663, -127.33333333319999, -51.99999999969999, -108.83333333370001, -1.3333333339000246, -151.333333333, 328.0000000003999, -126.33333333370005, 207.49999999999997, -102.9999999998, 68.33333333430002, -298.49999999960005, 96.16666666710002, 347.66666666500004, -100.33333333339999, 250.83333333429997, -123.3333333337, 61.49999999980001, -146.99999999989998, 34.333333332700036, -211.1666666667, 152.83333333320002, -103.9999999999, 293.1666666663, 83.66666666629999, -249.66666666610007, -9.666666666400005, 88.4999999996, 8.000000000799998, 66.16666666640002, -20.833333331399995, -322.4999999995, 93.00000000080001, -97.66666666639999, 82.00000000159999, -180.3333333333, -281.8333333333, 309.99999999860006, -61.16666666639999, -107.33333333510001, 335.8333333331001, -101.0000000001, 61.666666667099996, -289.8333333327001, -111.66666666719999, 266.66666666730003, -199.3333333333, -2.166666666800017, -199.3333333333, -110.0000000001, -107.6666666664, 292.66666666640003, 34.66666666660004, -133.0, -104.6666666671, -119.9999999999, -80.9999999995, -67.3333333337, -87.33333333360001, 58.66666666620006, 91.83333333350001, -99.66666666639999, 194.3333333328, 265.3333333333, 381.3333333334, 182.49999999990007, -20.999999999700044, -240.50000000019998, -95.0000000005, -64.66666666809999, -103.3333333331, 429.3333333337999, -158.3333333333, -95.6666666668, 80.6666666657, -15.999999998800007, 190.49999999949998, -115.1666666665, 141.66666666639998, 179.49999999890002], "policy_cop_policy_reward": [20.0, 61.5, 103.5, 113.0, 226.5, 427.0, 43.5, 30.0, 106.0, 112.0, 21.0, 27.0, 283.0, -10.0, 342.5, -349.5, 137.5, 169.0, 382.5, 307.5, -489.5, 341.5, -226.5, 73.5, 158.0, 157.0, 292.5, 307.0, -162.5, -119.5, -35.5, 166.0, -73.5, 108.0, 17.0, 19.5, 380.0, -180.5, 242.0, 86.5, 176.0, 162.5, 174.5, 35.5, -252.0, -655.5, 271.0, 148.5, -364.0, -119.0, -75.5, 0.0, 0.0, 0.0, -326.0, 374.0, 279.5, -228.5, 167.5, 289.0, 160.5, 149.5, -226.5, -130.0, 130.5, -21.5, 192.5, 208.0, 33.5, 213.0, 128.5, -8.5, 237.0, -370.0, -111.5, 232.0, 93.5, 144.5, -974.5, 139.0, 197.5, 212.0, 131.0, 308.5, 262.0, 152.0, -156.5, 94.0, 128.0, 58.0, 113.5, 202.0, 353.5, -764.0, -13.0, 262.0, 124.5, 202.0, 164.0, -80.5, 368.5, 184.5, 0.0, 0.0, 321.0, -466.5, 237.5, 86.5, -47.0, 143.5, 231.0, 206.5, 264.0, 174.5, 125.0, 228.0, 269.5, 222.0, -78.5, 100.0, 2.5, 2.0, 149.5, -309.5, 71.5, 0.0, 36.0, 58.0, -370.0, 216.5, 196.5, -161.5, 235.5, 228.0, 432.5, 170.0, 88.5, 119.5, 225.0, -136.5, -364.5, -275.0, 307.5, 219.0, 166.0, 47.5, 1.5, -116.0, 139.5, -15.0, 26.5, 282.5, 264.5, 343.0, 428.5, 155.5, 52.0, 78.0, 63.0, 141.0, 134.0, 136.5, 23.0, 110.0, 26.0, 84.5, 289.5, 154.5, 485.0, 89.0, -342.5, -388.0, 180.5, -291.0, -835.5, 328.0, 370.0, -31.5, 564.5, -163.5, 0.0, 0.0, 0.0, 174.5, 297.0, 158.5, 231.5, 122.0, -23.5, 324.0, 34.0, -121.5, 269.5, 489.5, 40.5, 526.0, 216.0, 266.0, -185.5, 16.5, 105.5, 100.5, 11.0, 16.0, 1.0, 155.5, 301.5, 192.5, -61.0, 237.0, -97.0, 3.5, -191.0, -96.0, 14.5, 29.5, 173.0, -72.0, 40.5, 110.0, -186.0, 42.5, 147.5, 69.5, -0.5, -313.0, -13.5, 136.5, -349.5, -101.0, 149.0, -187.5, 193.5, -97.0, 172.0, -348.0, 150.5, -103.0, -710.5, -44.0, 190.0, 236.5, 249.0, 91.0, -102.0, 197.5, 343.0, 94.0, 334.0, 214.5, 414.0, 309.0, -361.5, 108.0, 248.0, 51.0, 114.0, 64.5, -1027.5, 261.5, 109.0, -100.0, 0.0, 0.0, 268.0, 183.5, 32.5, 106.0, 56.5, 65.0, 138.0, 130.0, 182.0, -36.0, 209.0, 309.0, 236.5, -85.0, 228.5, 125.0, 340.0, 319.0, 1.0, 100.0, -97.0, 209.0, 359.0, 231.0, 111.5, 307.5, 228.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7308727393694047, "mean_inference_ms": 7.025589390369391, "mean_action_processing_ms": 0.16871731538120124, "mean_env_wait_ms": 0.2052573481514073, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.007380499984278824, "StateBufferConnector_ms": 0.005719035562842784, "ViewRequirementAgentConnector_ms": 0.33197703987661037}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 110.06487157198212, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 12000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 11997, "timers": {"training_iteration_time_ms": 38391.2, "sample_time_ms": 32234.035, "synch_weights_time_ms": 10.992}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 165, "training_iteration": 3, "trial_id": "96d6c_00000", "date": "2024-01-13_10-48-27", "timestamp": 1705139307, "time_this_iter_s": 36.35605764389038, "time_total_s": 115.21774530410767, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F5D80>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 115.21774530410767, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 6.735416666666666, "ram_util_percent": 63.293749999999996, "gpu_util_percent0": 0.29687500000000006, "vram_util_percent0": 0.08772786458333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2948.0, "total_loss": 19.081152770478848}, "mr_x_policy": {"total_loss": 19.081152770478848, "policy_loss": -0.0750327796312207, "vf_loss": 9.461890624741377, "vf_loss_unclipped": 19073.685124801377, "vf_explained_var": 0.0066789004762293925, "entropy": 1.28205343222214, "mean_kl_loss": 0.018000492452070613, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.675000011920929}, "cop_policy": {"total_loss": 9.682144649958206, "policy_loss": -0.021164774199182137, "vf_loss": 9.698283373299292, "vf_loss_unclipped": 49787.7250893803, "vf_explained_var": -0.002678371081917973, "entropy": 1.3004724292431848, "mean_kl_loss": 0.016753268438135866, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1174.8333333326, "episode_reward_min": -1923.0000000001003, "episode_reward_mean": 247.494999999999, "episode_len_mean": 66.4, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"cop_policy": -2121.0, "mr_x_policy": -618.9999999995}, "policy_reward_max": {"cop_policy": 564.5, "mr_x_policy": 429.3333333337999}, "policy_reward_mean": {"cop_policy": 97.9927536231884, "mr_x_policy": -22.965000000001005}, "custom_metrics": {}, "hist_stats": {"episode_reward": [705.3333333330999, -101.0000000001, 691.6666666671, 40.166666667299964, 124.83333333280001, 1066.1666666673, -199.3333333333, 1005.8333333332001, -199.3333333333, -173.50000000010002, 19.833333333599995, 750.6666666663999, 403.1666666666, -417.5, -156.6666666671, 21.50000000010006, -114.49999999949999, 149.1666666663, -277.33333333359997, -242.8333333338, 0.8333333335001214, -125.1666666664, -663.1666666671999, 940.8333333333001, 567.8333333334, 953.4999999998998, 916.5000000003001, -246.0000000002001, 134.4999999995, -721.6666666681001, -203.3333333331, 913.3333333338003, 69.1666666667, 354.3333333332, 562.6666666657001, 364.00000000119985, 974.4999999995001, -111.1666666665, 940.6666666664, 826.4999999989001, 582.3333333330002, -97.6666666667, -346.16666666609996, -98.0, 428.6666666672, -238.1666666667, -197.6666666667, 471.83333333370007, 726.6666666674998, 1080.1666666669003, 634.5000000009999, 219.50000000000003, -1058.9999999993001, -100.0, 771.1666666663, -10.1666666669, 511.66666666729986, 410.1666666665999, 464.6666666663, 974.3333333325, 1174.8333333326, -6.499999999600021, 109.49999999950006, -169.49999999949995, -22.166666667200015, 148.00000000080001, 578.4999999992, 466.16666666689997, -129.1666666663, 813.3333333333002, 325.333333333, 865.5000000004002, 294.6666666665, 754.6666666666001, -99.3333333333, 498.99999999920004, 1171.5000000000998, 191.1666666667, -105.6666666665, 190.66666666679998, 84.0, 887.3333333325999, 219.66666666650002, -295.166666667, 62.666666667, -197.0, 891.9999999996999, 503.1666666667999, 106.49999999960002, 519.1666666663001, 1165.0000000000002, 45.33333333349999, -458.4999999983999, -185.49999999980002, -280.16666666640003, 1089.4999999999998, 130.66666666759997, -99.33333333329999, -1923.0000000001003, 758.8333333334], "episode_lengths": [104, 5, 101, 102, 89, 97, 1, 99, 1, 15, 13, 97, 76, 16, 17, 100, 16, 38, 41, 66, 108, 56, 110, 96, 101, 96, 100, 89, 23, 77, 6, 99, 22, 64, 98, 89, 98, 10, 95, 95, 101, 1, 22, 1, 93, 19, 1, 102, 93, 94, 96, 96, 119, 1, 99, 21, 100, 68, 101, 98, 95, 37, 79, 108, 103, 99, 101, 85, 17, 96, 98, 83, 57, 95, 1, 76, 96, 56, 5, 97, 31, 98, 25, 18, 37, 2, 95, 97, 47, 95, 95, 16, 82, 62, 41, 98, 78, 5, 83, 99], "policy_cop_policy_reward": [-31.5, 564.5, -163.5, 0.0, 0.0, 0.0, 174.5, 297.0, 158.5, 231.5, 122.0, -23.5, 324.0, 34.0, -121.5, 269.5, 489.5, 40.5, 526.0, 216.0, 266.0, -185.5, 16.5, 105.5, 100.5, 11.0, 16.0, 1.0, 155.5, 301.5, 192.5, -61.0, 237.0, -97.0, 3.5, -191.0, -96.0, 14.5, 29.5, 173.0, -72.0, 40.5, 110.0, -186.0, 42.5, 147.5, 69.5, -0.5, -313.0, -13.5, 136.5, -349.5, -101.0, 149.0, -187.5, 193.5, -97.0, 172.0, -348.0, 150.5, -103.0, -710.5, -44.0, 190.0, 236.5, 249.0, 91.0, -102.0, 197.5, 343.0, 94.0, 334.0, 214.5, 414.0, 309.0, -361.5, 108.0, 248.0, 51.0, 114.0, 64.5, -1027.5, 261.5, 109.0, -100.0, 0.0, 0.0, 268.0, 183.5, 32.5, 106.0, 56.5, 65.0, 138.0, 130.0, 182.0, -36.0, 209.0, 309.0, 236.5, -85.0, 228.5, 125.0, 340.0, 319.0, 1.0, 100.0, -97.0, 209.0, 359.0, 231.0, 111.5, 307.5, 228.0, 328.5, -41.5, 346.5, -281.5, 108.0, -10.5, -51.0, 222.0, 267.5, -92.0, 44.0, 116.5, 222.5, 374.5, -431.0, 284.0, 240.5, 92.0, 292.0, 283.0, 252.5, 21.0, 324.5, 133.0, 170.5, -84.0, 213.5, -2121.0, 376.0, 525.5, 50.0, 212.0, 245.0, -62.5, 33.0, 116.0, -68.5, 101.0, 263.0, 95.5, 281.5, 36.0, 344.5, 171.5, 286.5, 117.0, 329.5, 286.0, 310.0, 244.5, 355.5, 189.5, 27.5, 142.5, 131.5, 94.0, 165.0, 94.5, 14.0, 341.0, -150.5, 288.0, -14.0, -114.0, 74.5, 296.0, 270.0, 325.5, -56.5, 229.0, 152.0, 52.0, 43.5, 109.5, -91.0, 277.0, 188.0, 94.0, -1.0, 43.0, 165.0, 318.5, 289.0, 143.0, 116.5, 94.5, 35.0, 170.0, 304.0, 102.5, 205.5, 191.0, 185.5, 456.0, 323.5, 292.5, 187.0, -76.0, 151.5, 0.0, 0.0, 0.0, -264.0, 185.5, 229.0, 131.5, -18.0, 55.5, 330.0, 312.5, 389.0, 72.5, 69.0, 135.0, -195.0, 19.5, 4.0, 126.5, 147.0, -38.5, 353.0, 248.5, 140.5, 27.5, 60.0, 348.0, 210.5, 105.0, -76.0, 101.0, 237.0, 229.0, 232.0, 375.5, 394.0, 46.5, 111.5, -63.5, 52.0, -84.0, -115.5, -412.0, 110.0, 165.0, -456.0, 123.5, 152.5, 478.5, 464.0, 224.5, -48.5, 301.0, 252.0, 0.0, 0.0, 0.0, -1292.0, 157.0, -407.0, 255.5, 353.0, 178.5], "policy_mr_x_policy_reward": [335.8333333331001, -101.0000000001, 61.666666667099996, -289.8333333327001, -111.66666666719999, 266.66666666730003, -199.3333333333, -2.166666666800017, -199.3333333333, -110.0000000001, -107.6666666664, 292.66666666640003, 34.66666666660004, -133.0, -104.6666666671, -119.9999999999, -80.9999999995, -67.3333333337, -87.33333333360001, 58.66666666620006, 91.83333333350001, -99.66666666639999, 194.3333333328, 265.3333333333, 381.3333333334, 182.49999999990007, -20.999999999700044, -240.50000000019998, -95.0000000005, -64.66666666809999, -103.3333333331, 429.3333333337999, -158.3333333333, -95.6666666668, 80.6666666657, -15.999999998800007, 190.49999999949998, -115.1666666665, 141.66666666639998, 179.49999999890002, -51.16666666700003, -97.6666666667, -162.1666666661, -98.0, -9.833333332799995, -306.6666666667, -197.6666666667, 305.83333333370007, 110.16666666749998, 252.6666666669, 156.00000000099993, -80.50000000000001, 160.50000000069997, -100.0, 264.16666666630005, -96.6666666669, 216.16666666729998, -2.83333333340002, -337.83333333370007, 241.83333333249996, 264.8333333326, -365.99999999960005, -281.0000000005, -618.9999999995, -145.66666666720002, -108.49999999920003, 39.49999999919999, 33.16666666690003, -191.1666666663, 254.33333333330003, 118.33333333299998, 115.00000000039995, 48.66666666649999, 178.1666666666, -99.3333333333, -83.00000000080001, 99.50000000010002, -71.3333333333, -105.6666666665, 40.166666666800005, -84.99999999999999, -144.16666666740002, -56.83333333350001, -123.666666667, -172.33333333299998, -197.0, 149.99999999969998, 67.6666666668, -133.0000000004, -47.83333333370001, 163.5, -49.16666666649999, -310.9999999984, -48.499999999799996, -100.16666666639999, -77.5, -373.8333333324001, -99.33333333329999, -381.0000000001, -28.166666666599973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6944602537935645, "mean_inference_ms": 6.903707453782462, "mean_action_processing_ms": 0.15865570894015338, "mean_env_wait_ms": 0.1959838868766594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005734463532765706, "StateBufferConnector_ms": 0.005401795109113057, "ViewRequirementAgentConnector_ms": 0.3483039637406667}}, "episode_reward_max": 1174.8333333326, "episode_reward_min": -1923.0000000001003, "episode_reward_mean": 247.494999999999, "episode_len_mean": 66.4, "episodes_this_iter": 60, "policy_reward_min": {"cop_policy": -2121.0, "mr_x_policy": -618.9999999995}, "policy_reward_max": {"cop_policy": 564.5, "mr_x_policy": 429.3333333337999}, "policy_reward_mean": {"cop_policy": 97.9927536231884, "mr_x_policy": -22.965000000001005}, "hist_stats": {"episode_reward": [705.3333333330999, -101.0000000001, 691.6666666671, 40.166666667299964, 124.83333333280001, 1066.1666666673, -199.3333333333, 1005.8333333332001, -199.3333333333, -173.50000000010002, 19.833333333599995, 750.6666666663999, 403.1666666666, -417.5, -156.6666666671, 21.50000000010006, -114.49999999949999, 149.1666666663, -277.33333333359997, -242.8333333338, 0.8333333335001214, -125.1666666664, -663.1666666671999, 940.8333333333001, 567.8333333334, 953.4999999998998, 916.5000000003001, -246.0000000002001, 134.4999999995, -721.6666666681001, -203.3333333331, 913.3333333338003, 69.1666666667, 354.3333333332, 562.6666666657001, 364.00000000119985, 974.4999999995001, -111.1666666665, 940.6666666664, 826.4999999989001, 582.3333333330002, -97.6666666667, -346.16666666609996, -98.0, 428.6666666672, -238.1666666667, -197.6666666667, 471.83333333370007, 726.6666666674998, 1080.1666666669003, 634.5000000009999, 219.50000000000003, -1058.9999999993001, -100.0, 771.1666666663, -10.1666666669, 511.66666666729986, 410.1666666665999, 464.6666666663, 974.3333333325, 1174.8333333326, -6.499999999600021, 109.49999999950006, -169.49999999949995, -22.166666667200015, 148.00000000080001, 578.4999999992, 466.16666666689997, -129.1666666663, 813.3333333333002, 325.333333333, 865.5000000004002, 294.6666666665, 754.6666666666001, -99.3333333333, 498.99999999920004, 1171.5000000000998, 191.1666666667, -105.6666666665, 190.66666666679998, 84.0, 887.3333333325999, 219.66666666650002, -295.166666667, 62.666666667, -197.0, 891.9999999996999, 503.1666666667999, 106.49999999960002, 519.1666666663001, 1165.0000000000002, 45.33333333349999, -458.4999999983999, -185.49999999980002, -280.16666666640003, 1089.4999999999998, 130.66666666759997, -99.33333333329999, -1923.0000000001003, 758.8333333334], "episode_lengths": [104, 5, 101, 102, 89, 97, 1, 99, 1, 15, 13, 97, 76, 16, 17, 100, 16, 38, 41, 66, 108, 56, 110, 96, 101, 96, 100, 89, 23, 77, 6, 99, 22, 64, 98, 89, 98, 10, 95, 95, 101, 1, 22, 1, 93, 19, 1, 102, 93, 94, 96, 96, 119, 1, 99, 21, 100, 68, 101, 98, 95, 37, 79, 108, 103, 99, 101, 85, 17, 96, 98, 83, 57, 95, 1, 76, 96, 56, 5, 97, 31, 98, 25, 18, 37, 2, 95, 97, 47, 95, 95, 16, 82, 62, 41, 98, 78, 5, 83, 99], "policy_cop_policy_reward": [-31.5, 564.5, -163.5, 0.0, 0.0, 0.0, 174.5, 297.0, 158.5, 231.5, 122.0, -23.5, 324.0, 34.0, -121.5, 269.5, 489.5, 40.5, 526.0, 216.0, 266.0, -185.5, 16.5, 105.5, 100.5, 11.0, 16.0, 1.0, 155.5, 301.5, 192.5, -61.0, 237.0, -97.0, 3.5, -191.0, -96.0, 14.5, 29.5, 173.0, -72.0, 40.5, 110.0, -186.0, 42.5, 147.5, 69.5, -0.5, -313.0, -13.5, 136.5, -349.5, -101.0, 149.0, -187.5, 193.5, -97.0, 172.0, -348.0, 150.5, -103.0, -710.5, -44.0, 190.0, 236.5, 249.0, 91.0, -102.0, 197.5, 343.0, 94.0, 334.0, 214.5, 414.0, 309.0, -361.5, 108.0, 248.0, 51.0, 114.0, 64.5, -1027.5, 261.5, 109.0, -100.0, 0.0, 0.0, 268.0, 183.5, 32.5, 106.0, 56.5, 65.0, 138.0, 130.0, 182.0, -36.0, 209.0, 309.0, 236.5, -85.0, 228.5, 125.0, 340.0, 319.0, 1.0, 100.0, -97.0, 209.0, 359.0, 231.0, 111.5, 307.5, 228.0, 328.5, -41.5, 346.5, -281.5, 108.0, -10.5, -51.0, 222.0, 267.5, -92.0, 44.0, 116.5, 222.5, 374.5, -431.0, 284.0, 240.5, 92.0, 292.0, 283.0, 252.5, 21.0, 324.5, 133.0, 170.5, -84.0, 213.5, -2121.0, 376.0, 525.5, 50.0, 212.0, 245.0, -62.5, 33.0, 116.0, -68.5, 101.0, 263.0, 95.5, 281.5, 36.0, 344.5, 171.5, 286.5, 117.0, 329.5, 286.0, 310.0, 244.5, 355.5, 189.5, 27.5, 142.5, 131.5, 94.0, 165.0, 94.5, 14.0, 341.0, -150.5, 288.0, -14.0, -114.0, 74.5, 296.0, 270.0, 325.5, -56.5, 229.0, 152.0, 52.0, 43.5, 109.5, -91.0, 277.0, 188.0, 94.0, -1.0, 43.0, 165.0, 318.5, 289.0, 143.0, 116.5, 94.5, 35.0, 170.0, 304.0, 102.5, 205.5, 191.0, 185.5, 456.0, 323.5, 292.5, 187.0, -76.0, 151.5, 0.0, 0.0, 0.0, -264.0, 185.5, 229.0, 131.5, -18.0, 55.5, 330.0, 312.5, 389.0, 72.5, 69.0, 135.0, -195.0, 19.5, 4.0, 126.5, 147.0, -38.5, 353.0, 248.5, 140.5, 27.5, 60.0, 348.0, 210.5, 105.0, -76.0, 101.0, 237.0, 229.0, 232.0, 375.5, 394.0, 46.5, 111.5, -63.5, 52.0, -84.0, -115.5, -412.0, 110.0, 165.0, -456.0, 123.5, 152.5, 478.5, 464.0, 224.5, -48.5, 301.0, 252.0, 0.0, 0.0, 0.0, -1292.0, 157.0, -407.0, 255.5, 353.0, 178.5], "policy_mr_x_policy_reward": [335.8333333331001, -101.0000000001, 61.666666667099996, -289.8333333327001, -111.66666666719999, 266.66666666730003, -199.3333333333, -2.166666666800017, -199.3333333333, -110.0000000001, -107.6666666664, 292.66666666640003, 34.66666666660004, -133.0, -104.6666666671, -119.9999999999, -80.9999999995, -67.3333333337, -87.33333333360001, 58.66666666620006, 91.83333333350001, -99.66666666639999, 194.3333333328, 265.3333333333, 381.3333333334, 182.49999999990007, -20.999999999700044, -240.50000000019998, -95.0000000005, -64.66666666809999, -103.3333333331, 429.3333333337999, -158.3333333333, -95.6666666668, 80.6666666657, -15.999999998800007, 190.49999999949998, -115.1666666665, 141.66666666639998, 179.49999999890002, -51.16666666700003, -97.6666666667, -162.1666666661, -98.0, -9.833333332799995, -306.6666666667, -197.6666666667, 305.83333333370007, 110.16666666749998, 252.6666666669, 156.00000000099993, -80.50000000000001, 160.50000000069997, -100.0, 264.16666666630005, -96.6666666669, 216.16666666729998, -2.83333333340002, -337.83333333370007, 241.83333333249996, 264.8333333326, -365.99999999960005, -281.0000000005, -618.9999999995, -145.66666666720002, -108.49999999920003, 39.49999999919999, 33.16666666690003, -191.1666666663, 254.33333333330003, 118.33333333299998, 115.00000000039995, 48.66666666649999, 178.1666666666, -99.3333333333, -83.00000000080001, 99.50000000010002, -71.3333333333, -105.6666666665, 40.166666666800005, -84.99999999999999, -144.16666666740002, -56.83333333350001, -123.666666667, -172.33333333299998, -197.0, 149.99999999969998, 67.6666666668, -133.0000000004, -47.83333333370001, 163.5, -49.16666666649999, -310.9999999984, -48.499999999799996, -100.16666666639999, -77.5, -373.8333333324001, -99.33333333329999, -381.0000000001, -28.166666666599973]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6944602537935645, "mean_inference_ms": 6.903707453782462, "mean_action_processing_ms": 0.15865570894015338, "mean_env_wait_ms": 0.1959838868766594, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005734463532765706, "StateBufferConnector_ms": 0.005401795109113057, "ViewRequirementAgentConnector_ms": 0.3483039637406667}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.91021014185586, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 16000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 15997, "timers": {"training_iteration_time_ms": 37891.736, "sample_time_ms": 31772.906, "synch_weights_time_ms": 10.624}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 225, "training_iteration": 4, "trial_id": "96d6c_00000", "date": "2024-01-13_10-49-04", "timestamp": 1705139344, "time_this_iter_s": 36.411296129226685, "time_total_s": 151.62904143333435, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F67A0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 151.62904143333435, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 6.825531914893616, "ram_util_percent": 61.64893617021275, "gpu_util_percent0": 0.30425531914893617, "vram_util_percent0": 0.08772786458333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2968.0, "total_loss": 19.229694080352782}, "mr_x_policy": {"total_loss": 19.229694080352782, "policy_loss": -0.08471264303273832, "vf_loss": 9.66309240659078, "vf_loss_unclipped": 19639.45633138021, "vf_explained_var": 0.0021711637576421103, "entropy": 1.2313905835151673, "mean_kl_loss": 0.021414335946246865, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.63685973485311, "policy_loss": -0.02395205169644517, "vf_loss": 9.655397335688273, "vf_loss_unclipped": 24561.404931640624, "vf_explained_var": -0.0037744253873825072, "entropy": 1.270818394422531, "mean_kl_loss": 0.018047740962841393, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1171.5000000000998, "episode_reward_min": -1923.0000000001003, "episode_reward_mean": 216.323333333347, "episode_len_mean": 64.37, "episode_media": {}, "episodes_this_iter": 63, "policy_reward_min": {"cop_policy": -1292.0, "mr_x_policy": -618.9999999995}, "policy_reward_max": {"cop_policy": 478.5, "mr_x_policy": 367.6666666658}, "policy_reward_mean": {"cop_policy": 88.71305841924399, "mr_x_policy": -41.83166666665301}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-169.49999999949995, -22.166666667200015, 148.00000000080001, 578.4999999992, 466.16666666689997, -129.1666666663, 813.3333333333002, 325.333333333, 865.5000000004002, 294.6666666665, 754.6666666666001, -99.3333333333, 498.99999999920004, 1171.5000000000998, 191.1666666667, -105.6666666665, 190.66666666679998, 84.0, 887.3333333325999, 219.66666666650002, -295.166666667, 62.666666667, -197.0, 891.9999999996999, 503.1666666667999, 106.49999999960002, 519.1666666663001, 1165.0000000000002, 45.33333333349999, -458.4999999983999, -185.49999999980002, -280.16666666640003, 1089.4999999999998, 130.66666666759997, -99.33333333329999, -1923.0000000001003, 758.8333333334, 796.3333333339, -1.3333333329999988, 110.33333333339999, -199.0, 15.666666666099985, 656.9999999998998, 88.1666666668, 86.00000000019998, 82.00000000040002, -113.00000000000001, -97.6666666666, 716.8333333338, 630.1666666675999, 52.49999999989999, 904.4999999995001, -352.16666666729986, 427.8333333327001, 889.3333333336999, -725.6666666665001, -142.6666666671, -168.16666666640003, 328.3333333331, 120.83333333330008, 899.6666666658, 183.99999999999986, 326.9999999996, -102.9999999998, 294.1666666668, 87.50000000010007, 257.66666666610007, 807.8333333340998, -384.8333333337, -43.666666666699996, 579.9999999997, -225.99999999999994, 95.33333333339999, 320.6666666649, 274.8333333331999, -110.9999999999, -181.8333333332, 195.50000000010004, 447.3333333343, 658.3333333334999, -23.16666666660001, 60.000000000100044, 1119.5000000000998, 290.83333333459996, -109.83333333259999, 172.49999999919996, 93.83333333320002, -13.166666666599841, 1.4999999998999982, -107.0000000001, 311.66666666609996, 176.00000000039995, 646.8333333328001, 70.833333334, 341.83333333279995, -42.8333333331, 655.9999999998998, 104.0000000001, -13.000000000300087, 612.5000000003998], "episode_lengths": [108, 103, 99, 101, 85, 17, 96, 98, 83, 57, 95, 1, 76, 96, 56, 5, 97, 31, 98, 25, 18, 37, 2, 95, 97, 47, 95, 95, 16, 82, 62, 41, 98, 78, 5, 83, 99, 101, 29, 30, 1, 82, 97, 23, 29, 54, 8, 14, 97, 103, 29, 96, 50, 69, 93, 41, 22, 43, 101, 102, 99, 107, 70, 8, 48, 106, 43, 97, 40, 14, 98, 106, 25, 100, 104, 4, 15, 43, 101, 97, 27, 44, 97, 74, 18, 100, 27, 105, 26, 7, 100, 103, 100, 59, 103, 15, 96, 16, 107, 97], "policy_cop_policy_reward": [94.5, 14.0, 341.0, -150.5, 288.0, -14.0, -114.0, 74.5, 296.0, 270.0, 325.5, -56.5, 229.0, 152.0, 52.0, 43.5, 109.5, -91.0, 277.0, 188.0, 94.0, -1.0, 43.0, 165.0, 318.5, 289.0, 143.0, 116.5, 94.5, 35.0, 170.0, 304.0, 102.5, 205.5, 191.0, 185.5, 456.0, 323.5, 292.5, 187.0, -76.0, 151.5, 0.0, 0.0, 0.0, -264.0, 185.5, 229.0, 131.5, -18.0, 55.5, 330.0, 312.5, 389.0, 72.5, 69.0, 135.0, -195.0, 19.5, 4.0, 126.5, 147.0, -38.5, 353.0, 248.5, 140.5, 27.5, 60.0, 348.0, 210.5, 105.0, -76.0, 101.0, 237.0, 229.0, 232.0, 375.5, 394.0, 46.5, 111.5, -63.5, 52.0, -84.0, -115.5, -412.0, 110.0, 165.0, -456.0, 123.5, 152.5, 478.5, 464.0, 224.5, -48.5, 301.0, 252.0, 0.0, 0.0, 0.0, -1292.0, 157.0, -407.0, 255.5, 353.0, 178.5, -99.0, 430.0, 311.5, -157.5, 152.0, 72.0, 133.5, 57.0, 39.5, -138.0, 205.5, 39.5, 256.5, 188.0, 3.0, 35.0, 114.0, 48.5, 120.5, 29.5, 64.5, -41.0, 205.0, 197.5, 0.0, 0.0, 0.0, -96.0, 12.0, 105.0, 141.0, 227.5, 230.5, 325.0, -247.0, 410.0, -63.0, 56.5, 137.0, 288.0, 187.5, 220.5, -205.0, -148.0, 104.5, 220.5, 202.0, 111.5, 267.0, 306.0, 177.5, -878.0, 119.0, 156.0, 35.0, -179.0, 118.5, 85.0, -248.0, 118.5, -365.5, 274.5, 149.5, 111.0, 305.5, -367.5, 432.5, 236.0, -136.5, 78.0, 407.0, -27.5, 150.5, 225.5, 198.0, 0.0, 0.0, 0.0, 57.5, 217.0, 122.5, 415.0, -504.0, 245.5, 32.0, 149.0, 148.0, 33.5, 191.0, 327.5, -54.0, 112.0, 154.5, 9.5, 1.0, 26.5, 186.0, 232.0, 230.5, -474.0, 247.0, 90.5, 132.0, 19.5, 52.0, 260.0, -375.5, 321.0, 129.5, -269.5, 362.5, 0.0, 0.0, 0.0, -186.0, 100.5, 14.0, 13.0, 202.0, -27.5, 248.0, 270.0, -348.5, 98.0, 129.0, 225.5, -127.5, 55.5, 118.0, 43.5, 163.0, 86.5, 349.0, 285.0, 291.0, 185.5, 125.0, -110.0, 107.0, -93.5, 17.0, 358.0, 105.5, 94.5, 43.0, 128.0, 38.0, -341.5, 405.5, 177.5, -57.0, 10.0, 145.5, 0.0, 0.0, 0.0, 84.0, -398.0, 371.0, 331.5, 195.5, -615.5, 174.0, -93.5, 297.0, 238.5, -390.5, 157.5, 359.0, 117.5, 286.5, -89.5, 108.0, 25.0, 208.0, 216.0, 41.0, 23.0, 42.0, 112.0, 230.5, -760.0, 162.0, 290.0, 104.5, 243.5], "policy_mr_x_policy_reward": [-618.9999999995, -145.66666666720002, -108.49999999920003, 39.49999999919999, 33.16666666690003, -191.1666666663, 254.33333333330003, 118.33333333299998, 115.00000000039995, 48.66666666649999, 178.1666666666, -99.3333333333, -83.00000000080001, 99.50000000010002, -71.3333333333, -105.6666666665, 40.166666666800005, -84.99999999999999, -144.16666666740002, -56.83333333350001, -123.666666667, -172.33333333299998, -197.0, 149.99999999969998, 67.6666666668, -133.0000000004, -47.83333333370001, 163.5, -49.16666666649999, -310.9999999984, -48.499999999799996, -100.16666666639999, -77.5, -373.8333333324001, -99.33333333329999, -381.0000000001, -28.166666666599973, 153.83333333390001, -67.83333333300001, -119.6666666666, -199.0, -91.3333333339, 209.49999999989993, -109.3333333332, -128.4999999998, -279.4999999996, -113.00000000000001, -118.6666666666, 117.83333333379998, 142.16666666760003, -78.0000000001, 208.4999999995, -103.6666666673, -106.1666666673, 138.8333333337, -122.6666666665, -117.1666666671, -123.66666666639999, 269.8333333331, 71.83333333329999, 367.6666666658, -273.49999999999994, -247.0000000004, -102.9999999998, -102.83333333319999, -68.99999999990003, -71.33333333389999, 255.83333333410002, -597.3333333337001, -80.66666666670001, -68.50000000029999, -89.5, -108.16666666660001, 115.16666666489999, 52.33333333320001, -110.9999999999, -110.33333333319999, 8.000000000099988, 277.8333333343, 205.8333333335, -69.16666666660001, -232.9999999999, 194.50000000010002, 90.33333333460001, -140.3333333326, -385.5000000008, -115.16666666679998, -254.6666666666, -97.0000000001, -107.0000000001, 254.6666666661, 264.5000000004, 269.33333333280007, 65.33333333399997, -421.16666666719993, -86.3333333331, 190.9999999999, -72.9999999999, 354.4999999997, -25.499999999600018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6773389924509083, "mean_inference_ms": 6.841503269510695, "mean_action_processing_ms": 0.15418168916530445, "mean_env_wait_ms": 0.19009308767756306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00773202344245717, "StateBufferConnector_ms": 0.007151589175771336, "ViewRequirementAgentConnector_ms": 0.3258967762671146}}, "episode_reward_max": 1171.5000000000998, "episode_reward_min": -1923.0000000001003, "episode_reward_mean": 216.323333333347, "episode_len_mean": 64.37, "episodes_this_iter": 63, "policy_reward_min": {"cop_policy": -1292.0, "mr_x_policy": -618.9999999995}, "policy_reward_max": {"cop_policy": 478.5, "mr_x_policy": 367.6666666658}, "policy_reward_mean": {"cop_policy": 88.71305841924399, "mr_x_policy": -41.83166666665301}, "hist_stats": {"episode_reward": [-169.49999999949995, -22.166666667200015, 148.00000000080001, 578.4999999992, 466.16666666689997, -129.1666666663, 813.3333333333002, 325.333333333, 865.5000000004002, 294.6666666665, 754.6666666666001, -99.3333333333, 498.99999999920004, 1171.5000000000998, 191.1666666667, -105.6666666665, 190.66666666679998, 84.0, 887.3333333325999, 219.66666666650002, -295.166666667, 62.666666667, -197.0, 891.9999999996999, 503.1666666667999, 106.49999999960002, 519.1666666663001, 1165.0000000000002, 45.33333333349999, -458.4999999983999, -185.49999999980002, -280.16666666640003, 1089.4999999999998, 130.66666666759997, -99.33333333329999, -1923.0000000001003, 758.8333333334, 796.3333333339, -1.3333333329999988, 110.33333333339999, -199.0, 15.666666666099985, 656.9999999998998, 88.1666666668, 86.00000000019998, 82.00000000040002, -113.00000000000001, -97.6666666666, 716.8333333338, 630.1666666675999, 52.49999999989999, 904.4999999995001, -352.16666666729986, 427.8333333327001, 889.3333333336999, -725.6666666665001, -142.6666666671, -168.16666666640003, 328.3333333331, 120.83333333330008, 899.6666666658, 183.99999999999986, 326.9999999996, -102.9999999998, 294.1666666668, 87.50000000010007, 257.66666666610007, 807.8333333340998, -384.8333333337, -43.666666666699996, 579.9999999997, -225.99999999999994, 95.33333333339999, 320.6666666649, 274.8333333331999, -110.9999999999, -181.8333333332, 195.50000000010004, 447.3333333343, 658.3333333334999, -23.16666666660001, 60.000000000100044, 1119.5000000000998, 290.83333333459996, -109.83333333259999, 172.49999999919996, 93.83333333320002, -13.166666666599841, 1.4999999998999982, -107.0000000001, 311.66666666609996, 176.00000000039995, 646.8333333328001, 70.833333334, 341.83333333279995, -42.8333333331, 655.9999999998998, 104.0000000001, -13.000000000300087, 612.5000000003998], "episode_lengths": [108, 103, 99, 101, 85, 17, 96, 98, 83, 57, 95, 1, 76, 96, 56, 5, 97, 31, 98, 25, 18, 37, 2, 95, 97, 47, 95, 95, 16, 82, 62, 41, 98, 78, 5, 83, 99, 101, 29, 30, 1, 82, 97, 23, 29, 54, 8, 14, 97, 103, 29, 96, 50, 69, 93, 41, 22, 43, 101, 102, 99, 107, 70, 8, 48, 106, 43, 97, 40, 14, 98, 106, 25, 100, 104, 4, 15, 43, 101, 97, 27, 44, 97, 74, 18, 100, 27, 105, 26, 7, 100, 103, 100, 59, 103, 15, 96, 16, 107, 97], "policy_cop_policy_reward": [94.5, 14.0, 341.0, -150.5, 288.0, -14.0, -114.0, 74.5, 296.0, 270.0, 325.5, -56.5, 229.0, 152.0, 52.0, 43.5, 109.5, -91.0, 277.0, 188.0, 94.0, -1.0, 43.0, 165.0, 318.5, 289.0, 143.0, 116.5, 94.5, 35.0, 170.0, 304.0, 102.5, 205.5, 191.0, 185.5, 456.0, 323.5, 292.5, 187.0, -76.0, 151.5, 0.0, 0.0, 0.0, -264.0, 185.5, 229.0, 131.5, -18.0, 55.5, 330.0, 312.5, 389.0, 72.5, 69.0, 135.0, -195.0, 19.5, 4.0, 126.5, 147.0, -38.5, 353.0, 248.5, 140.5, 27.5, 60.0, 348.0, 210.5, 105.0, -76.0, 101.0, 237.0, 229.0, 232.0, 375.5, 394.0, 46.5, 111.5, -63.5, 52.0, -84.0, -115.5, -412.0, 110.0, 165.0, -456.0, 123.5, 152.5, 478.5, 464.0, 224.5, -48.5, 301.0, 252.0, 0.0, 0.0, 0.0, -1292.0, 157.0, -407.0, 255.5, 353.0, 178.5, -99.0, 430.0, 311.5, -157.5, 152.0, 72.0, 133.5, 57.0, 39.5, -138.0, 205.5, 39.5, 256.5, 188.0, 3.0, 35.0, 114.0, 48.5, 120.5, 29.5, 64.5, -41.0, 205.0, 197.5, 0.0, 0.0, 0.0, -96.0, 12.0, 105.0, 141.0, 227.5, 230.5, 325.0, -247.0, 410.0, -63.0, 56.5, 137.0, 288.0, 187.5, 220.5, -205.0, -148.0, 104.5, 220.5, 202.0, 111.5, 267.0, 306.0, 177.5, -878.0, 119.0, 156.0, 35.0, -179.0, 118.5, 85.0, -248.0, 118.5, -365.5, 274.5, 149.5, 111.0, 305.5, -367.5, 432.5, 236.0, -136.5, 78.0, 407.0, -27.5, 150.5, 225.5, 198.0, 0.0, 0.0, 0.0, 57.5, 217.0, 122.5, 415.0, -504.0, 245.5, 32.0, 149.0, 148.0, 33.5, 191.0, 327.5, -54.0, 112.0, 154.5, 9.5, 1.0, 26.5, 186.0, 232.0, 230.5, -474.0, 247.0, 90.5, 132.0, 19.5, 52.0, 260.0, -375.5, 321.0, 129.5, -269.5, 362.5, 0.0, 0.0, 0.0, -186.0, 100.5, 14.0, 13.0, 202.0, -27.5, 248.0, 270.0, -348.5, 98.0, 129.0, 225.5, -127.5, 55.5, 118.0, 43.5, 163.0, 86.5, 349.0, 285.0, 291.0, 185.5, 125.0, -110.0, 107.0, -93.5, 17.0, 358.0, 105.5, 94.5, 43.0, 128.0, 38.0, -341.5, 405.5, 177.5, -57.0, 10.0, 145.5, 0.0, 0.0, 0.0, 84.0, -398.0, 371.0, 331.5, 195.5, -615.5, 174.0, -93.5, 297.0, 238.5, -390.5, 157.5, 359.0, 117.5, 286.5, -89.5, 108.0, 25.0, 208.0, 216.0, 41.0, 23.0, 42.0, 112.0, 230.5, -760.0, 162.0, 290.0, 104.5, 243.5], "policy_mr_x_policy_reward": [-618.9999999995, -145.66666666720002, -108.49999999920003, 39.49999999919999, 33.16666666690003, -191.1666666663, 254.33333333330003, 118.33333333299998, 115.00000000039995, 48.66666666649999, 178.1666666666, -99.3333333333, -83.00000000080001, 99.50000000010002, -71.3333333333, -105.6666666665, 40.166666666800005, -84.99999999999999, -144.16666666740002, -56.83333333350001, -123.666666667, -172.33333333299998, -197.0, 149.99999999969998, 67.6666666668, -133.0000000004, -47.83333333370001, 163.5, -49.16666666649999, -310.9999999984, -48.499999999799996, -100.16666666639999, -77.5, -373.8333333324001, -99.33333333329999, -381.0000000001, -28.166666666599973, 153.83333333390001, -67.83333333300001, -119.6666666666, -199.0, -91.3333333339, 209.49999999989993, -109.3333333332, -128.4999999998, -279.4999999996, -113.00000000000001, -118.6666666666, 117.83333333379998, 142.16666666760003, -78.0000000001, 208.4999999995, -103.6666666673, -106.1666666673, 138.8333333337, -122.6666666665, -117.1666666671, -123.66666666639999, 269.8333333331, 71.83333333329999, 367.6666666658, -273.49999999999994, -247.0000000004, -102.9999999998, -102.83333333319999, -68.99999999990003, -71.33333333389999, 255.83333333410002, -597.3333333337001, -80.66666666670001, -68.50000000029999, -89.5, -108.16666666660001, 115.16666666489999, 52.33333333320001, -110.9999999999, -110.33333333319999, 8.000000000099988, 277.8333333343, 205.8333333335, -69.16666666660001, -232.9999999999, 194.50000000010002, 90.33333333460001, -140.3333333326, -385.5000000008, -115.16666666679998, -254.6666666666, -97.0000000001, -107.0000000001, 254.6666666661, 264.5000000004, 269.33333333280007, 65.33333333399997, -421.16666666719993, -86.3333333331, 190.9999999999, -72.9999999999, 354.4999999997, -25.499999999600018]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6773389924509083, "mean_inference_ms": 6.841503269510695, "mean_action_processing_ms": 0.15418168916530445, "mean_env_wait_ms": 0.19009308767756306, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00773202344245717, "StateBufferConnector_ms": 0.007151589175771336, "ViewRequirementAgentConnector_ms": 0.3258967762671146}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.06904840011444, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 20000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 19997, "timers": {"training_iteration_time_ms": 37648.192, "sample_time_ms": 31487.922, "synch_weights_time_ms": 10.604}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 288, "training_iteration": 5, "trial_id": "96d6c_00000", "date": "2024-01-13_10-49-40", "timestamp": 1705139380, "time_this_iter_s": 36.68987727165222, "time_total_s": 188.31891870498657, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F7910>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 188.31891870498657, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 6.7326530612244895, "ram_util_percent": 62.45510204081632, "gpu_util_percent0": 0.2975510204081632, "vram_util_percent0": 0.08757839073129253}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2960.0, "total_loss": 19.122572326660155}, "mr_x_policy": {"total_loss": 19.122572326660155, "policy_loss": -0.07898915668483823, "vf_loss": 9.478055429458617, "vf_loss_unclipped": 13963.415543619793, "vf_explained_var": -0.0012033283710479736, "entropy": 1.2150682787100473, "mean_kl_loss": 0.015572971057614874, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.707738463083903, "policy_loss": -0.024524443154223263, "vf_loss": 9.72698187828064, "vf_loss_unclipped": 26393.288948567708, "vf_explained_var": -0.0005591442187627157, "entropy": 1.2644931336243947, "mean_kl_loss": 0.01760333474133707, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1381.8333333318994, "episode_reward_min": -1536.6666666672004, "episode_reward_mean": 271.324999999914, "episode_len_mean": 71.02, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"mr_x_policy": -597.3333333337001, "cop_policy": -1098.0}, "policy_reward_max": {"mr_x_policy": 390.83333333240006, "cop_policy": 499.0}, "policy_reward_mean": {"mr_x_policy": -10.335000000085998, "cop_policy": 93.88666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [427.8333333327001, 889.3333333336999, -725.6666666665001, -142.6666666671, -168.16666666640003, 328.3333333331, 120.83333333330008, 899.6666666658, 183.99999999999986, 326.9999999996, -102.9999999998, 294.1666666668, 87.50000000010007, 257.66666666610007, 807.8333333340998, -384.8333333337, -43.666666666699996, 579.9999999997, -225.99999999999994, 95.33333333339999, 320.6666666649, 274.8333333331999, -110.9999999999, -181.8333333332, 195.50000000010004, 447.3333333343, 658.3333333334999, -23.16666666660001, 60.000000000100044, 1119.5000000000998, 290.83333333459996, -109.83333333259999, 172.49999999919996, 93.83333333320002, -13.166666666599841, 1.4999999998999982, -107.0000000001, 311.66666666609996, 176.00000000039995, 646.8333333328001, 70.833333334, 341.83333333279995, -42.8333333331, 655.9999999998998, 104.0000000001, -13.000000000300087, 612.5000000003998, 1010.999999998, -60.0, -40.1666666662, 96.16666666660001, -64.00000000000003, 529.4999999999001, 580.8333333337, 35.166666667200005, -357.6666666668, 573.3333333342999, 317.66666666689997, 1137.8333333334, -1536.6666666672004, 890.6666666671, -930.9999999999, 146.33333333259995, 526.6666666666, 81.4999999994, 707.9999999994, 138.66666666720002, 209.4999999996001, 134.5000000005, 1036.0, 286.83333333350004, 765.3333333333, 178.33333333259998, 749.3333333339001, 710.4999999996999, 110.99999999939999, 578.1666666663001, 564.3333333329999, 302.8333333322, 295.3333333339, 789.0000000003998, 99.16666666610001, 1381.8333333318994, 413.3333333332, 619.166666666, 452.0000000002001, -202.9999999998, 824.6666666664005, -96.33333333449995, -149.16666666619992, 817.8333333324, 223.16666666730003, 473.66666666599997, -110.9999999998, 815.1666666668, 82.6666666662, -105.6666666667, 305.8333333334, 1124.9999999992, 211.16666666739997], "episode_lengths": [69, 93, 41, 22, 43, 101, 102, 99, 107, 70, 8, 48, 106, 43, 97, 40, 14, 98, 106, 25, 100, 104, 4, 15, 43, 101, 97, 27, 44, 97, 74, 18, 100, 27, 105, 26, 7, 100, 103, 100, 59, 103, 15, 96, 16, 107, 97, 98, 11, 23, 13, 19, 98, 97, 14, 105, 101, 37, 97, 119, 93, 87, 100, 98, 32, 94, 102, 98, 34, 96, 100, 96, 71, 99, 97, 25, 99, 95, 102, 96, 96, 64, 98, 98, 93, 102, 36, 94, 76, 103, 99, 25, 60, 8, 101, 35, 8, 96, 93, 54], "policy_mr_x_policy_reward": [-106.1666666673, 138.8333333337, -122.6666666665, -117.1666666671, -123.66666666639999, 269.8333333331, 71.83333333329999, 367.6666666658, -273.49999999999994, -247.0000000004, -102.9999999998, -102.83333333319999, -68.99999999990003, -71.33333333389999, 255.83333333410002, -597.3333333337001, -80.66666666670001, -68.50000000029999, -89.5, -108.16666666660001, 115.16666666489999, 52.33333333320001, -110.9999999999, -110.33333333319999, 8.000000000099988, 277.8333333343, 205.8333333335, -69.16666666660001, -232.9999999999, 194.50000000010002, 90.33333333460001, -140.3333333326, -385.5000000008, -115.16666666679998, -254.6666666666, -97.0000000001, -107.0000000001, 254.6666666661, 264.5000000004, 269.33333333280007, 65.33333333399997, -421.16666666719993, -86.3333333331, 190.9999999999, -72.9999999999, 354.4999999997, -25.499999999600018, 120.99999999800002, -179.0, -66.1666666662, -61.3333333334, -158.5, -185.0000000001, 184.83333333370004, -105.3333333328, 152.33333333320002, 198.8333333343, -38.83333333310001, 284.3333333334, -105.16666666720002, 134.1666666671, -387.4999999999, -53.16666666740002, 27.1666666666, -198.50000000059998, 103.9999999994, -539.3333333328002, -156.50000000039998, -123.9999999995, 245.50000000000003, -8.666666666500006, 215.33333333330003, -511.6666666674001, 333.33333333390004, 13.999999999700028, -103.5000000006, 155.6666666663, 81.333333333, 115.33333333219998, 53.83333333390001, 68.50000000040001, -103.8333333339, 283.8333333319, 56.83333333319999, 43.166666666000005, 68.00000000019999, -218.9999999998, 164.16666666639998, -63.8333333345, 153.33333333379997, 390.83333333240006, -36.8333333327, 29.16666666599997, -110.9999999998, 15.666666666799992, -138.3333333338, -105.6666666667, 22.833333333400002, 207.4999999992, -135.3333333326], "policy_cop_policy_reward": [220.5, 202.0, 111.5, 267.0, 306.0, 177.5, -878.0, 119.0, 156.0, 35.0, -179.0, 118.5, 85.0, -248.0, 118.5, -365.5, 274.5, 149.5, 111.0, 305.5, -367.5, 432.5, 236.0, -136.5, 78.0, 407.0, -27.5, 150.5, 225.5, 198.0, 0.0, 0.0, 0.0, 57.5, 217.0, 122.5, 415.0, -504.0, 245.5, 32.0, 149.0, 148.0, 33.5, 191.0, 327.5, -54.0, 112.0, 154.5, 9.5, 1.0, 26.5, 186.0, 232.0, 230.5, -474.0, 247.0, 90.5, 132.0, 19.5, 52.0, 260.0, -375.5, 321.0, 129.5, -269.5, 362.5, 0.0, 0.0, 0.0, -186.0, 100.5, 14.0, 13.0, 202.0, -27.5, 248.0, 270.0, -348.5, 98.0, 129.0, 225.5, -127.5, 55.5, 118.0, 43.5, 163.0, 86.5, 349.0, 285.0, 291.0, 185.5, 125.0, -110.0, 107.0, -93.5, 17.0, 358.0, 105.5, 94.5, 43.0, 128.0, 38.0, -341.5, 405.5, 177.5, -57.0, 10.0, 145.5, 0.0, 0.0, 0.0, 84.0, -398.0, 371.0, 331.5, 195.5, -615.5, 174.0, -93.5, 297.0, 238.5, -390.5, 157.5, 359.0, 117.5, 286.5, -89.5, 108.0, 25.0, 208.0, 216.0, 41.0, 23.0, 42.0, 112.0, 230.5, -760.0, 162.0, 290.0, 104.5, 243.5, 112.0, 314.0, 464.0, 101.0, 9.0, 9.0, -185.5, 124.5, 87.0, 104.5, 24.0, 29.0, -48.5, 34.0, 109.0, 328.0, 266.5, 120.0, -159.0, 319.0, 236.0, 108.0, 7.0, 25.5, 78.5, -797.0, 208.5, 79.0, -144.0, 439.5, 109.0, 165.0, 82.5, 492.0, 3.0, 358.5, -1006.0, 314.0, -739.5, 268.0, 302.0, 186.5, -1098.0, 262.5, 292.0, -294.0, 175.0, 318.5, 247.0, 138.5, 114.0, 57.0, 129.0, 94.0, 267.0, 217.5, 119.5, 160.0, 233.0, 285.0, -58.5, 360.5, 64.0, 150.5, 38.0, 70.0, 366.0, 359.0, 65.5, 85.0, -29.0, 239.5, -40.0, 270.5, 319.5, 179.0, 221.5, 289.5, 399.0, -316.5, 333.5, 106.5, 364.5, 225.5, 128.0, 66.5, 20.0, -97.0, 208.0, 311.5, 14.5, 179.0, 289.5, -246.0, 383.5, 50.0, -48.0, 124.5, 165.0, 171.5, 377.0, 172.0, -146.5, 121.5, 228.0, 499.0, 111.5, 487.5, 226.0, 151.5, -21.0, 148.0, 273.0, 155.0, 131.5, 11.5, 241.0, -169.0, 67.0, 118.0, 175.0, 307.5, 178.0, -208.0, 100.5, 75.0, -447.5, 268.0, -123.0, 144.0, 107.5, 175.5, 51.5, 124.0, 84.5, 214.0, 76.0, 154.5, 0.0, 0.0, 0.0, 281.0, 140.5, 378.0, 32.0, 125.0, 64.0, 0.0, 0.0, 0.0, -109.5, 198.5, 194.0, 232.5, 303.0, 382.0, 163.0, 113.0, 70.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6724437714494172, "mean_inference_ms": 6.801707335845367, "mean_action_processing_ms": 0.1517051248919556, "mean_env_wait_ms": 0.18707233038636153, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013225436210632324, "StateBufferConnector_ms": 0.01050114631652832, "ViewRequirementAgentConnector_ms": 0.33665454387664795}}, "episode_reward_max": 1381.8333333318994, "episode_reward_min": -1536.6666666672004, "episode_reward_mean": 271.324999999914, "episode_len_mean": 71.02, "episodes_this_iter": 53, "policy_reward_min": {"mr_x_policy": -597.3333333337001, "cop_policy": -1098.0}, "policy_reward_max": {"mr_x_policy": 390.83333333240006, "cop_policy": 499.0}, "policy_reward_mean": {"mr_x_policy": -10.335000000085998, "cop_policy": 93.88666666666667}, "hist_stats": {"episode_reward": [427.8333333327001, 889.3333333336999, -725.6666666665001, -142.6666666671, -168.16666666640003, 328.3333333331, 120.83333333330008, 899.6666666658, 183.99999999999986, 326.9999999996, -102.9999999998, 294.1666666668, 87.50000000010007, 257.66666666610007, 807.8333333340998, -384.8333333337, -43.666666666699996, 579.9999999997, -225.99999999999994, 95.33333333339999, 320.6666666649, 274.8333333331999, -110.9999999999, -181.8333333332, 195.50000000010004, 447.3333333343, 658.3333333334999, -23.16666666660001, 60.000000000100044, 1119.5000000000998, 290.83333333459996, -109.83333333259999, 172.49999999919996, 93.83333333320002, -13.166666666599841, 1.4999999998999982, -107.0000000001, 311.66666666609996, 176.00000000039995, 646.8333333328001, 70.833333334, 341.83333333279995, -42.8333333331, 655.9999999998998, 104.0000000001, -13.000000000300087, 612.5000000003998, 1010.999999998, -60.0, -40.1666666662, 96.16666666660001, -64.00000000000003, 529.4999999999001, 580.8333333337, 35.166666667200005, -357.6666666668, 573.3333333342999, 317.66666666689997, 1137.8333333334, -1536.6666666672004, 890.6666666671, -930.9999999999, 146.33333333259995, 526.6666666666, 81.4999999994, 707.9999999994, 138.66666666720002, 209.4999999996001, 134.5000000005, 1036.0, 286.83333333350004, 765.3333333333, 178.33333333259998, 749.3333333339001, 710.4999999996999, 110.99999999939999, 578.1666666663001, 564.3333333329999, 302.8333333322, 295.3333333339, 789.0000000003998, 99.16666666610001, 1381.8333333318994, 413.3333333332, 619.166666666, 452.0000000002001, -202.9999999998, 824.6666666664005, -96.33333333449995, -149.16666666619992, 817.8333333324, 223.16666666730003, 473.66666666599997, -110.9999999998, 815.1666666668, 82.6666666662, -105.6666666667, 305.8333333334, 1124.9999999992, 211.16666666739997], "episode_lengths": [69, 93, 41, 22, 43, 101, 102, 99, 107, 70, 8, 48, 106, 43, 97, 40, 14, 98, 106, 25, 100, 104, 4, 15, 43, 101, 97, 27, 44, 97, 74, 18, 100, 27, 105, 26, 7, 100, 103, 100, 59, 103, 15, 96, 16, 107, 97, 98, 11, 23, 13, 19, 98, 97, 14, 105, 101, 37, 97, 119, 93, 87, 100, 98, 32, 94, 102, 98, 34, 96, 100, 96, 71, 99, 97, 25, 99, 95, 102, 96, 96, 64, 98, 98, 93, 102, 36, 94, 76, 103, 99, 25, 60, 8, 101, 35, 8, 96, 93, 54], "policy_mr_x_policy_reward": [-106.1666666673, 138.8333333337, -122.6666666665, -117.1666666671, -123.66666666639999, 269.8333333331, 71.83333333329999, 367.6666666658, -273.49999999999994, -247.0000000004, -102.9999999998, -102.83333333319999, -68.99999999990003, -71.33333333389999, 255.83333333410002, -597.3333333337001, -80.66666666670001, -68.50000000029999, -89.5, -108.16666666660001, 115.16666666489999, 52.33333333320001, -110.9999999999, -110.33333333319999, 8.000000000099988, 277.8333333343, 205.8333333335, -69.16666666660001, -232.9999999999, 194.50000000010002, 90.33333333460001, -140.3333333326, -385.5000000008, -115.16666666679998, -254.6666666666, -97.0000000001, -107.0000000001, 254.6666666661, 264.5000000004, 269.33333333280007, 65.33333333399997, -421.16666666719993, -86.3333333331, 190.9999999999, -72.9999999999, 354.4999999997, -25.499999999600018, 120.99999999800002, -179.0, -66.1666666662, -61.3333333334, -158.5, -185.0000000001, 184.83333333370004, -105.3333333328, 152.33333333320002, 198.8333333343, -38.83333333310001, 284.3333333334, -105.16666666720002, 134.1666666671, -387.4999999999, -53.16666666740002, 27.1666666666, -198.50000000059998, 103.9999999994, -539.3333333328002, -156.50000000039998, -123.9999999995, 245.50000000000003, -8.666666666500006, 215.33333333330003, -511.6666666674001, 333.33333333390004, 13.999999999700028, -103.5000000006, 155.6666666663, 81.333333333, 115.33333333219998, 53.83333333390001, 68.50000000040001, -103.8333333339, 283.8333333319, 56.83333333319999, 43.166666666000005, 68.00000000019999, -218.9999999998, 164.16666666639998, -63.8333333345, 153.33333333379997, 390.83333333240006, -36.8333333327, 29.16666666599997, -110.9999999998, 15.666666666799992, -138.3333333338, -105.6666666667, 22.833333333400002, 207.4999999992, -135.3333333326], "policy_cop_policy_reward": [220.5, 202.0, 111.5, 267.0, 306.0, 177.5, -878.0, 119.0, 156.0, 35.0, -179.0, 118.5, 85.0, -248.0, 118.5, -365.5, 274.5, 149.5, 111.0, 305.5, -367.5, 432.5, 236.0, -136.5, 78.0, 407.0, -27.5, 150.5, 225.5, 198.0, 0.0, 0.0, 0.0, 57.5, 217.0, 122.5, 415.0, -504.0, 245.5, 32.0, 149.0, 148.0, 33.5, 191.0, 327.5, -54.0, 112.0, 154.5, 9.5, 1.0, 26.5, 186.0, 232.0, 230.5, -474.0, 247.0, 90.5, 132.0, 19.5, 52.0, 260.0, -375.5, 321.0, 129.5, -269.5, 362.5, 0.0, 0.0, 0.0, -186.0, 100.5, 14.0, 13.0, 202.0, -27.5, 248.0, 270.0, -348.5, 98.0, 129.0, 225.5, -127.5, 55.5, 118.0, 43.5, 163.0, 86.5, 349.0, 285.0, 291.0, 185.5, 125.0, -110.0, 107.0, -93.5, 17.0, 358.0, 105.5, 94.5, 43.0, 128.0, 38.0, -341.5, 405.5, 177.5, -57.0, 10.0, 145.5, 0.0, 0.0, 0.0, 84.0, -398.0, 371.0, 331.5, 195.5, -615.5, 174.0, -93.5, 297.0, 238.5, -390.5, 157.5, 359.0, 117.5, 286.5, -89.5, 108.0, 25.0, 208.0, 216.0, 41.0, 23.0, 42.0, 112.0, 230.5, -760.0, 162.0, 290.0, 104.5, 243.5, 112.0, 314.0, 464.0, 101.0, 9.0, 9.0, -185.5, 124.5, 87.0, 104.5, 24.0, 29.0, -48.5, 34.0, 109.0, 328.0, 266.5, 120.0, -159.0, 319.0, 236.0, 108.0, 7.0, 25.5, 78.5, -797.0, 208.5, 79.0, -144.0, 439.5, 109.0, 165.0, 82.5, 492.0, 3.0, 358.5, -1006.0, 314.0, -739.5, 268.0, 302.0, 186.5, -1098.0, 262.5, 292.0, -294.0, 175.0, 318.5, 247.0, 138.5, 114.0, 57.0, 129.0, 94.0, 267.0, 217.5, 119.5, 160.0, 233.0, 285.0, -58.5, 360.5, 64.0, 150.5, 38.0, 70.0, 366.0, 359.0, 65.5, 85.0, -29.0, 239.5, -40.0, 270.5, 319.5, 179.0, 221.5, 289.5, 399.0, -316.5, 333.5, 106.5, 364.5, 225.5, 128.0, 66.5, 20.0, -97.0, 208.0, 311.5, 14.5, 179.0, 289.5, -246.0, 383.5, 50.0, -48.0, 124.5, 165.0, 171.5, 377.0, 172.0, -146.5, 121.5, 228.0, 499.0, 111.5, 487.5, 226.0, 151.5, -21.0, 148.0, 273.0, 155.0, 131.5, 11.5, 241.0, -169.0, 67.0, 118.0, 175.0, 307.5, 178.0, -208.0, 100.5, 75.0, -447.5, 268.0, -123.0, 144.0, 107.5, 175.5, 51.5, 124.0, 84.5, 214.0, 76.0, 154.5, 0.0, 0.0, 0.0, 281.0, 140.5, 378.0, 32.0, 125.0, 64.0, 0.0, 0.0, 0.0, -109.5, 198.5, 194.0, 232.5, 303.0, 382.0, 163.0, 113.0, 70.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6724437714494172, "mean_inference_ms": 6.801707335845367, "mean_action_processing_ms": 0.1517051248919556, "mean_env_wait_ms": 0.18707233038636153, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.013225436210632324, "StateBufferConnector_ms": 0.01050114631652832, "ViewRequirementAgentConnector_ms": 0.33665454387664795}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.93127676755597, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 24000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 23997, "timers": {"training_iteration_time_ms": 37437.888, "sample_time_ms": 31301.628, "synch_weights_time_ms": 10.337}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 341, "training_iteration": 6, "trial_id": "96d6c_00000", "date": "2024-01-13_10-50-17", "timestamp": 1705139417, "time_this_iter_s": 36.40136957168579, "time_total_s": 224.72028827667236, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F6F80>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 224.72028827667236, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 12.20212765957447, "ram_util_percent": 67.59999999999998, "gpu_util_percent0": 0.26276595744680853, "vram_util_percent0": 0.08756510416666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2973.0, "total_loss": 19.198091729482016}, "mr_x_policy": {"total_loss": 19.198091729482016, "policy_loss": -0.07586660764742797, "vf_loss": 9.534123849868774, "vf_loss_unclipped": 12527.322786458333, "vf_explained_var": 0.004421218236287435, "entropy": 1.1988646328449248, "mean_kl_loss": 0.015004781762885007, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.724642340342204, "policy_loss": -0.028515363356564193, "vf_loss": 9.749200121561687, "vf_loss_unclipped": 18626.60662434896, "vf_explained_var": -0.006374739607175191, "entropy": 1.2632916450500489, "mean_kl_loss": 0.013191509312006626, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1381.8333333318994, "episode_reward_min": -1536.6666666672004, "episode_reward_mean": 358.2433333332459, "episode_len_mean": 74.17, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"mr_x_policy": -539.3333333328002, "cop_policy": -1098.0}, "policy_reward_max": {"mr_x_policy": 421.333333334, "cop_policy": 499.0}, "policy_reward_mean": {"mr_x_policy": 13.748333333245993, "cop_policy": 119.61631944444444}, "custom_metrics": {}, "hist_stats": {"episode_reward": [317.66666666689997, 1137.8333333334, -1536.6666666672004, 890.6666666671, -930.9999999999, 146.33333333259995, 526.6666666666, 81.4999999994, 707.9999999994, 138.66666666720002, 209.4999999996001, 134.5000000005, 1036.0, 286.83333333350004, 765.3333333333, 178.33333333259998, 749.3333333339001, 710.4999999996999, 110.99999999939999, 578.1666666663001, 564.3333333329999, 302.8333333322, 295.3333333339, 789.0000000003998, 99.16666666610001, 1381.8333333318994, 413.3333333332, 619.166666666, 452.0000000002001, -202.9999999998, 824.6666666664005, -96.33333333449995, -149.16666666619992, 817.8333333324, 223.16666666730003, 473.66666666599997, -110.9999999998, 815.1666666668, 82.6666666662, -105.6666666667, 305.8333333334, 1124.9999999992, 211.16666666739997, 250.00000000019995, 491.3333333335001, 761.3333333333999, 1016.5000000006, -104.33333333320007, 888.0000000002001, 262.33333333339993, -308.49999999889985, 613.9999999995, 139.16666666740002, -17.999999999900012, 655.8333333334997, 556.4999999999, 553.5000000004999, -254.33333333320002, 552.6666666649, -97.3333333334, -100.33333333339999, 212.1666666666, 585.4999999999, 1079.1666666667998, 31.16666666669998, 266.4999999995, -214.50000000039995, 880.8333333329001, 649.3333333334, -25.499999999800025, -199.3333333333, 440.33333333400003, 763.0000000001002, 234.16666666670002, 442.00000000010004, 498.33333333349987, 2.6666666666000083, 14.500000000400036, -49.499999999899984, 319.166666666, 41.83333333360001, -187.3333333334, 1025.1666666663, -100.0, -8.166666666599994, 668.6666666666999, 166.50000000000003, 26.33333333370001, 423.1666666664999, 920.8333333319, 914.8333333337999, 539.3333333337, 416.6666666671, 71.33333333310003, 951.6666666656, 260.33333333319996, 849.1666666662001, 633.6666666670001, 772.6666666657001, 279.16666666640003], "episode_lengths": [37, 97, 119, 93, 87, 100, 98, 32, 94, 102, 98, 34, 96, 100, 96, 71, 99, 97, 25, 99, 95, 102, 96, 96, 64, 98, 98, 93, 102, 36, 94, 76, 103, 99, 25, 60, 8, 101, 35, 8, 96, 93, 54, 103, 53, 97, 93, 53, 96, 29, 106, 95, 46, 9, 95, 96, 98, 12, 98, 1, 1, 36, 96, 95, 104, 99, 104, 96, 95, 62, 1, 103, 95, 98, 100, 58, 48, 68, 39, 80, 29, 6, 97, 1, 12, 100, 97, 19, 97, 97, 93, 95, 79, 18, 96, 90, 97, 96, 97, 37], "policy_mr_x_policy_reward": [-38.83333333310001, 284.3333333334, -105.16666666720002, 134.1666666671, -387.4999999999, -53.16666666740002, 27.1666666666, -198.50000000059998, 103.9999999994, -539.3333333328002, -156.50000000039998, -123.9999999995, 245.50000000000003, -8.666666666500006, 215.33333333330003, -511.6666666674001, 333.33333333390004, 13.999999999700028, -103.5000000006, 155.6666666663, 81.333333333, 115.33333333219998, 53.83333333390001, 68.50000000040001, -103.8333333339, 283.8333333319, 56.83333333319999, 43.166666666000005, 68.00000000019999, -218.9999999998, 164.16666666639998, -63.8333333345, 153.33333333379997, 390.83333333240006, -36.8333333327, 29.16666666599997, -110.9999999998, 15.666666666799992, -138.3333333338, -105.6666666667, 22.833333333400002, 207.4999999992, -135.3333333326, -284.99999999979997, -19.666666666499992, 284.3333333334, 226.5000000006, 1.6666666668000119, 139.50000000020003, -39.1666666666, -230.99999999890005, 154.99999999950003, -103.83333333259999, -120.49999999990001, 100.33333333350004, 166.9999999999, -200.4999999995, -374.8333333332, 91.16666666490005, -97.3333333334, -100.33333333339999, -153.3333333334, 182.99999999989996, 314.1666666668, 236.16666666669997, -190.0000000005, 122.4999999996, 151.8333333329, 104.33333333340005, -36.99999999979998, -199.3333333333, 421.333333334, 213.50000000009996, 100.6666666667, 227.0000000001, -35.66666666649998, -120.33333333339999, 28.000000000400007, -50.999999999899984, -203.83333333399992, -140.1666666664, -187.3333333334, 253.6666666663, -100.0, -125.6666666666, 377.66666666669994, 23.5, -122.16666666629999, 161.66666666650002, 5.333333331899997, 173.8333333338, 20.8333333337, -29.833333332899983, -91.66666666689999, -46.833333334399995, 17.333333333200002, 186.6666666662, 162.66666666699996, 60.666666665700006, -57.83333333359999], "policy_cop_policy_reward": [109.0, 165.0, 82.5, 492.0, 3.0, 358.5, -1006.0, 314.0, -739.5, 268.0, 302.0, 186.5, -1098.0, 262.5, 292.0, -294.0, 175.0, 318.5, 247.0, 138.5, 114.0, 57.0, 129.0, 94.0, 267.0, 217.5, 119.5, 160.0, 233.0, 285.0, -58.5, 360.5, 64.0, 150.5, 38.0, 70.0, 366.0, 359.0, 65.5, 85.0, -29.0, 239.5, -40.0, 270.5, 319.5, 179.0, 221.5, 289.5, 399.0, -316.5, 333.5, 106.5, 364.5, 225.5, 128.0, 66.5, 20.0, -97.0, 208.0, 311.5, 14.5, 179.0, 289.5, -246.0, 383.5, 50.0, -48.0, 124.5, 165.0, 171.5, 377.0, 172.0, -146.5, 121.5, 228.0, 499.0, 111.5, 487.5, 226.0, 151.5, -21.0, 148.0, 273.0, 155.0, 131.5, 11.5, 241.0, -169.0, 67.0, 118.0, 175.0, 307.5, 178.0, -208.0, 100.5, 75.0, -447.5, 268.0, -123.0, 144.0, 107.5, 175.5, 51.5, 124.0, 84.5, 214.0, 76.0, 154.5, 0.0, 0.0, 0.0, 281.0, 140.5, 378.0, 32.0, 125.0, 64.0, 0.0, 0.0, 0.0, -109.5, 198.5, 194.0, 232.5, 303.0, 382.0, 163.0, 113.0, 70.5, 353.0, 243.5, -61.5, 121.0, 241.0, 149.0, -25.5, 357.0, 145.5, 339.0, 266.5, 184.5, -20.5, -324.5, 239.0, 178.0, 278.5, 292.0, 73.0, 52.0, 176.5, -417.0, 220.0, 119.5, 141.0, 251.0, 67.0, 161.0, 146.0, -64.0, 100.0, 1.5, 1.0, 253.0, 242.0, 60.5, 262.0, -43.0, 170.5, 182.5, 313.0, 258.5, 11.0, 9.0, 100.5, 164.0, 147.5, 150.0, 78.0, 146.5, 141.0, 18.0, 152.5, 232.0, 94.5, 263.5, 407.0, 248.0, -399.5, -53.5, 261.5, -52.5, 247.5, -291.0, -319.0, 273.0, 195.0, 281.5, 252.5, -1.0, 194.0, 352.0, 45.0, -150.0, 116.5, -280.0, 296.5, 2.5, 215.5, 316.0, 18.0, 145.0, 250.5, -262.0, 150.5, -22.5, 87.0, 250.0, 112.0, 172.0, 151.5, 115.0, -143.5, -372.0, 234.5, 124.0, 140.0, 30.0, -168.5, 179.0, 75.0, 269.0, 22.5, 31.0, 128.5, 0.0, 0.0, 0.0, -49.5, 410.5, 410.5, 9.5, 5.0, 103.0, 357.0, -14.5, -51.5, -302.0, 114.0, 331.0, 14.0, 112.0, 22.5, 51.5, 324.5, -114.5, 400.0, 304.5, 211.0, 257.5, 283.0, 200.5, 34.5, 279.0, 205.0, 262.5, 161.5, 22.5, 121.0, 19.0, 23.0, 409.0, 354.5, 235.0, 267.5, -192.0, 167.5, 272.0, 230.5, 160.0, -19.5, 185.0, 305.5, 95.5, 405.5, 211.0, 82.5, 187.0, 67.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6699705213788647, "mean_inference_ms": 6.759271256338643, "mean_action_processing_ms": 0.14984397116636644, "mean_env_wait_ms": 0.18514885416488172, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010323037906568877, "StateBufferConnector_ms": 0.01764747561240683, "ViewRequirementAgentConnector_ms": 0.33499087606157574}}, "episode_reward_max": 1381.8333333318994, "episode_reward_min": -1536.6666666672004, "episode_reward_mean": 358.2433333332459, "episode_len_mean": 74.17, "episodes_this_iter": 57, "policy_reward_min": {"mr_x_policy": -539.3333333328002, "cop_policy": -1098.0}, "policy_reward_max": {"mr_x_policy": 421.333333334, "cop_policy": 499.0}, "policy_reward_mean": {"mr_x_policy": 13.748333333245993, "cop_policy": 119.61631944444444}, "hist_stats": {"episode_reward": [317.66666666689997, 1137.8333333334, -1536.6666666672004, 890.6666666671, -930.9999999999, 146.33333333259995, 526.6666666666, 81.4999999994, 707.9999999994, 138.66666666720002, 209.4999999996001, 134.5000000005, 1036.0, 286.83333333350004, 765.3333333333, 178.33333333259998, 749.3333333339001, 710.4999999996999, 110.99999999939999, 578.1666666663001, 564.3333333329999, 302.8333333322, 295.3333333339, 789.0000000003998, 99.16666666610001, 1381.8333333318994, 413.3333333332, 619.166666666, 452.0000000002001, -202.9999999998, 824.6666666664005, -96.33333333449995, -149.16666666619992, 817.8333333324, 223.16666666730003, 473.66666666599997, -110.9999999998, 815.1666666668, 82.6666666662, -105.6666666667, 305.8333333334, 1124.9999999992, 211.16666666739997, 250.00000000019995, 491.3333333335001, 761.3333333333999, 1016.5000000006, -104.33333333320007, 888.0000000002001, 262.33333333339993, -308.49999999889985, 613.9999999995, 139.16666666740002, -17.999999999900012, 655.8333333334997, 556.4999999999, 553.5000000004999, -254.33333333320002, 552.6666666649, -97.3333333334, -100.33333333339999, 212.1666666666, 585.4999999999, 1079.1666666667998, 31.16666666669998, 266.4999999995, -214.50000000039995, 880.8333333329001, 649.3333333334, -25.499999999800025, -199.3333333333, 440.33333333400003, 763.0000000001002, 234.16666666670002, 442.00000000010004, 498.33333333349987, 2.6666666666000083, 14.500000000400036, -49.499999999899984, 319.166666666, 41.83333333360001, -187.3333333334, 1025.1666666663, -100.0, -8.166666666599994, 668.6666666666999, 166.50000000000003, 26.33333333370001, 423.1666666664999, 920.8333333319, 914.8333333337999, 539.3333333337, 416.6666666671, 71.33333333310003, 951.6666666656, 260.33333333319996, 849.1666666662001, 633.6666666670001, 772.6666666657001, 279.16666666640003], "episode_lengths": [37, 97, 119, 93, 87, 100, 98, 32, 94, 102, 98, 34, 96, 100, 96, 71, 99, 97, 25, 99, 95, 102, 96, 96, 64, 98, 98, 93, 102, 36, 94, 76, 103, 99, 25, 60, 8, 101, 35, 8, 96, 93, 54, 103, 53, 97, 93, 53, 96, 29, 106, 95, 46, 9, 95, 96, 98, 12, 98, 1, 1, 36, 96, 95, 104, 99, 104, 96, 95, 62, 1, 103, 95, 98, 100, 58, 48, 68, 39, 80, 29, 6, 97, 1, 12, 100, 97, 19, 97, 97, 93, 95, 79, 18, 96, 90, 97, 96, 97, 37], "policy_mr_x_policy_reward": [-38.83333333310001, 284.3333333334, -105.16666666720002, 134.1666666671, -387.4999999999, -53.16666666740002, 27.1666666666, -198.50000000059998, 103.9999999994, -539.3333333328002, -156.50000000039998, -123.9999999995, 245.50000000000003, -8.666666666500006, 215.33333333330003, -511.6666666674001, 333.33333333390004, 13.999999999700028, -103.5000000006, 155.6666666663, 81.333333333, 115.33333333219998, 53.83333333390001, 68.50000000040001, -103.8333333339, 283.8333333319, 56.83333333319999, 43.166666666000005, 68.00000000019999, -218.9999999998, 164.16666666639998, -63.8333333345, 153.33333333379997, 390.83333333240006, -36.8333333327, 29.16666666599997, -110.9999999998, 15.666666666799992, -138.3333333338, -105.6666666667, 22.833333333400002, 207.4999999992, -135.3333333326, -284.99999999979997, -19.666666666499992, 284.3333333334, 226.5000000006, 1.6666666668000119, 139.50000000020003, -39.1666666666, -230.99999999890005, 154.99999999950003, -103.83333333259999, -120.49999999990001, 100.33333333350004, 166.9999999999, -200.4999999995, -374.8333333332, 91.16666666490005, -97.3333333334, -100.33333333339999, -153.3333333334, 182.99999999989996, 314.1666666668, 236.16666666669997, -190.0000000005, 122.4999999996, 151.8333333329, 104.33333333340005, -36.99999999979998, -199.3333333333, 421.333333334, 213.50000000009996, 100.6666666667, 227.0000000001, -35.66666666649998, -120.33333333339999, 28.000000000400007, -50.999999999899984, -203.83333333399992, -140.1666666664, -187.3333333334, 253.6666666663, -100.0, -125.6666666666, 377.66666666669994, 23.5, -122.16666666629999, 161.66666666650002, 5.333333331899997, 173.8333333338, 20.8333333337, -29.833333332899983, -91.66666666689999, -46.833333334399995, 17.333333333200002, 186.6666666662, 162.66666666699996, 60.666666665700006, -57.83333333359999], "policy_cop_policy_reward": [109.0, 165.0, 82.5, 492.0, 3.0, 358.5, -1006.0, 314.0, -739.5, 268.0, 302.0, 186.5, -1098.0, 262.5, 292.0, -294.0, 175.0, 318.5, 247.0, 138.5, 114.0, 57.0, 129.0, 94.0, 267.0, 217.5, 119.5, 160.0, 233.0, 285.0, -58.5, 360.5, 64.0, 150.5, 38.0, 70.0, 366.0, 359.0, 65.5, 85.0, -29.0, 239.5, -40.0, 270.5, 319.5, 179.0, 221.5, 289.5, 399.0, -316.5, 333.5, 106.5, 364.5, 225.5, 128.0, 66.5, 20.0, -97.0, 208.0, 311.5, 14.5, 179.0, 289.5, -246.0, 383.5, 50.0, -48.0, 124.5, 165.0, 171.5, 377.0, 172.0, -146.5, 121.5, 228.0, 499.0, 111.5, 487.5, 226.0, 151.5, -21.0, 148.0, 273.0, 155.0, 131.5, 11.5, 241.0, -169.0, 67.0, 118.0, 175.0, 307.5, 178.0, -208.0, 100.5, 75.0, -447.5, 268.0, -123.0, 144.0, 107.5, 175.5, 51.5, 124.0, 84.5, 214.0, 76.0, 154.5, 0.0, 0.0, 0.0, 281.0, 140.5, 378.0, 32.0, 125.0, 64.0, 0.0, 0.0, 0.0, -109.5, 198.5, 194.0, 232.5, 303.0, 382.0, 163.0, 113.0, 70.5, 353.0, 243.5, -61.5, 121.0, 241.0, 149.0, -25.5, 357.0, 145.5, 339.0, 266.5, 184.5, -20.5, -324.5, 239.0, 178.0, 278.5, 292.0, 73.0, 52.0, 176.5, -417.0, 220.0, 119.5, 141.0, 251.0, 67.0, 161.0, 146.0, -64.0, 100.0, 1.5, 1.0, 253.0, 242.0, 60.5, 262.0, -43.0, 170.5, 182.5, 313.0, 258.5, 11.0, 9.0, 100.5, 164.0, 147.5, 150.0, 78.0, 146.5, 141.0, 18.0, 152.5, 232.0, 94.5, 263.5, 407.0, 248.0, -399.5, -53.5, 261.5, -52.5, 247.5, -291.0, -319.0, 273.0, 195.0, 281.5, 252.5, -1.0, 194.0, 352.0, 45.0, -150.0, 116.5, -280.0, 296.5, 2.5, 215.5, 316.0, 18.0, 145.0, 250.5, -262.0, 150.5, -22.5, 87.0, 250.0, 112.0, 172.0, 151.5, 115.0, -143.5, -372.0, 234.5, 124.0, 140.0, 30.0, -168.5, 179.0, 75.0, 269.0, 22.5, 31.0, 128.5, 0.0, 0.0, 0.0, -49.5, 410.5, 410.5, 9.5, 5.0, 103.0, 357.0, -14.5, -51.5, -302.0, 114.0, 331.0, 14.0, 112.0, 22.5, 51.5, 324.5, -114.5, 400.0, 304.5, 211.0, 257.5, 283.0, 200.5, 34.5, 279.0, 205.0, 262.5, 161.5, 22.5, 121.0, 19.0, 23.0, 409.0, 354.5, 235.0, 267.5, -192.0, 167.5, 272.0, 230.5, 160.0, -19.5, 185.0, 305.5, 95.5, 405.5, 211.0, 82.5, 187.0, 67.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6699705213788647, "mean_inference_ms": 6.759271256338643, "mean_action_processing_ms": 0.14984397116636644, "mean_env_wait_ms": 0.18514885416488172, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.010323037906568877, "StateBufferConnector_ms": 0.01764747561240683, "ViewRequirementAgentConnector_ms": 0.33499087606157574}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 111.35271255319442, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 28000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 27997, "timers": {"training_iteration_time_ms": 37221.317, "sample_time_ms": 31107.699, "synch_weights_time_ms": 10.036}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 398, "training_iteration": 7, "trial_id": "96d6c_00000", "date": "2024-01-13_10-50-53", "timestamp": 1705139453, "time_this_iter_s": 35.936652421951294, "time_total_s": 260.65694069862366, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E4430>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 260.65694069862366, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 8.87872340425532, "ram_util_percent": 69.76382978723403, "gpu_util_percent0": 0.2702127659574468, "vram_util_percent0": 0.09013810394503545}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2995.0, "total_loss": 19.244839096069335}, "mr_x_policy": {"total_loss": 19.244839096069335, "policy_loss": -0.07653519231826067, "vf_loss": 9.605048576990763, "vf_loss_unclipped": 19482.24052734375, "vf_explained_var": 0.0032945722341537476, "entropy": 1.1573167622089386, "mean_kl_loss": 0.01931700173184557, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.696767234802246, "policy_loss": -0.026043005241081118, "vf_loss": 9.717074918746949, "vf_loss_unclipped": 27846.617789713542, "vf_explained_var": -0.005554294586181641, "entropy": 1.2529464701811472, "mean_kl_loss": 0.019117509239064627, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1259.9999999991999, "episode_reward_min": -805.6666666678997, "episode_reward_mean": 399.13333333328393, "episode_len_mean": 69.09, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -203.83333333399992, "cop_policy": -1665.0}, "policy_reward_max": {"mr_x_policy": 513.8333333321, "cop_policy": 413.5}, "policy_reward_mean": {"mr_x_policy": 74.803333333284, "cop_policy": 116.66546762589928}, "custom_metrics": {}, "hist_stats": {"episode_reward": [552.6666666649, -97.3333333334, -100.33333333339999, 212.1666666666, 585.4999999999, 1079.1666666667998, 31.16666666669998, 266.4999999995, -214.50000000039995, 880.8333333329001, 649.3333333334, -25.499999999800025, -199.3333333333, 440.33333333400003, 763.0000000001002, 234.16666666670002, 442.00000000010004, 498.33333333349987, 2.6666666666000083, 14.500000000400036, -49.499999999899984, 319.166666666, 41.83333333360001, -187.3333333334, 1025.1666666663, -100.0, -8.166666666599994, 668.6666666666999, 166.50000000000003, 26.33333333370001, 423.1666666664999, 920.8333333319, 914.8333333337999, 539.3333333337, 416.6666666671, 71.33333333310003, 951.6666666656, 260.33333333319996, 849.1666666662001, 633.6666666670001, 772.6666666657001, 279.16666666640003, 589.3333333332, 1070.8333333342002, 943.9999999997, 781.3333333329999, -55.33333333240003, -101.6666666667, 261.9999999999, 51.00000000029999, 643.1666666670001, 124.66666666729998, -100.3333333333, 41.333333333599995, 540.4999999998, 793.6666666681001, 607.3333333337, 950.8333333339999, -96.6666666665, 1016.3333333324999, -97.6666666667, 814.6666666661, 863.3333333332, 270.83333333280007, -113.16666666589998, 1259.9999999991999, 938.3333333346, 387.6666666667, 1189.8333333332998, 466.33333333390016, 17.333333333599995, 750.3333333329001, 489.499999999, -333.33333333300004, -6.333333334300025, 428.9999999988, 1132.1666666669998, 248.1666666666, 376.99999999880004, 289.9999999996, 324.5000000005, -78.1666666669, 523.1666666668, 755.3333333329, 855.8333333335999, 572.8333333327, 451.16666666689986, -105.3333333332, 183.16666666700007, 979.3333333330002, 9.000000000100002, 608.1666666673, 582.6666666658999, 735.3333333339999, 373.00000000040006, -805.6666666678997, -105.66666666660001, 668.9999999999, -102.6666666667, 1101.1666666667002], "episode_lengths": [98, 1, 1, 36, 96, 95, 104, 99, 104, 96, 95, 62, 1, 103, 95, 98, 100, 58, 48, 68, 39, 80, 29, 6, 97, 1, 12, 100, 97, 19, 97, 97, 93, 95, 79, 18, 96, 90, 97, 96, 97, 37, 94, 93, 95, 98, 50, 8, 39, 13, 99, 83, 1, 13, 54, 98, 99, 96, 2, 94, 1, 100, 83, 103, 23, 95, 95, 97, 94, 102, 13, 93, 96, 38, 104, 102, 94, 98, 98, 55, 35, 12, 54, 94, 101, 62, 49, 6, 41, 97, 13, 98, 95, 96, 97, 117, 4, 98, 2, 95], "policy_mr_x_policy_reward": [91.16666666490005, -97.3333333334, -100.33333333339999, -153.3333333334, 182.99999999989996, 314.1666666668, 236.16666666669997, -190.0000000005, 122.4999999996, 151.8333333329, 104.33333333340005, -36.99999999979998, -199.3333333333, 421.333333334, 213.50000000009996, 100.6666666667, 227.0000000001, -35.66666666649998, -120.33333333339999, 28.000000000400007, -50.999999999899984, -203.83333333399992, -140.1666666664, -187.3333333334, 253.6666666663, -100.0, -125.6666666666, 377.66666666669994, 23.5, -122.16666666629999, 161.66666666650002, 5.333333331899997, 173.8333333338, 20.8333333337, -29.833333332899983, -91.66666666689999, -46.833333334399995, 17.333333333200002, 186.6666666662, 162.66666666699996, 60.666666665700006, -57.83333333359999, 70.33333333320002, 237.83333333419998, 273.99999999970004, 214.333333333, -50.33333333240001, -101.6666666667, -60.50000000010001, -88.9999999997, 319.666666667, -96.83333333270002, -100.3333333333, -97.6666666664, 49.999999999799996, 301.1666666681, 280.33333333369995, 213.83333333400003, -96.6666666665, 275.3333333325, -97.6666666667, 449.1666666661, 117.83333333319999, 309.83333333279995, -98.6666666659, 388.4999999992, 167.3333333346, 32.666666666699996, 287.33333333330006, 247.33333333390001, -109.6666666664, 106.8333333329, 154.99999999900004, -94.333333333, 241.66666666569998, 278.4999999988, 293.166666667, 75.66666666660001, -118.50000000120002, -93.0000000004, -30.99999999949999, -97.1666666669, 8.666666666799998, 104.83333333290003, 386.3333333335999, 56.83333333269999, -16.8333333331, -105.3333333332, -111.333333333, 203.83333333300004, -114.9999999999, 234.16666666729998, 153.16666666589998, 200.833333334, 84.00000000040001, 513.8333333321, -105.66666666660001, 245.49999999989998, -102.6666666667, 342.6666666667], "policy_cop_policy_reward": [164.0, 147.5, 150.0, 78.0, 146.5, 141.0, 18.0, 152.5, 232.0, 94.5, 263.5, 407.0, 248.0, -399.5, -53.5, 261.5, -52.5, 247.5, -291.0, -319.0, 273.0, 195.0, 281.5, 252.5, -1.0, 194.0, 352.0, 45.0, -150.0, 116.5, -280.0, 296.5, 2.5, 215.5, 316.0, 18.0, 145.0, 250.5, -262.0, 150.5, -22.5, 87.0, 250.0, 112.0, 172.0, 151.5, 115.0, -143.5, -372.0, 234.5, 124.0, 140.0, 30.0, -168.5, 179.0, 75.0, 269.0, 22.5, 31.0, 128.5, 0.0, 0.0, 0.0, -49.5, 410.5, 410.5, 9.5, 5.0, 103.0, 357.0, -14.5, -51.5, -302.0, 114.0, 331.0, 14.0, 112.0, 22.5, 51.5, 324.5, -114.5, 400.0, 304.5, 211.0, 257.5, 283.0, 200.5, 34.5, 279.0, 205.0, 262.5, 161.5, 22.5, 121.0, 19.0, 23.0, 409.0, 354.5, 235.0, 267.5, -192.0, 167.5, 272.0, 230.5, 160.0, -19.5, 185.0, 305.5, 95.5, 405.5, 211.0, 82.5, 187.0, 67.5, 191.0, 124.5, 203.5, 200.5, 273.0, 359.5, 242.0, 309.5, 118.5, 205.0, 119.0, 243.0, -223.5, 114.0, 104.5, 0.0, 0.0, 0.0, 77.0, 133.0, 112.5, 15.5, 19.0, 105.5, -25.5, 250.5, 98.5, -261.0, 202.5, 280.0, 19.5, 103.0, 16.5, 142.5, 167.0, 181.0, 59.5, 399.5, 33.5, 330.5, -160.0, 156.5, 260.0, 267.5, 209.5, 0.0, 282.0, 178.5, 280.5, 343.5, 131.0, -109.0, 153.5, 207.5, 384.5, 171.0, 352.5, -562.5, -170.5, 40.5, 115.5, 267.0, 348.5, 256.0, 118.0, 342.0, 311.0, 226.0, -96.5, 225.5, 245.0, 294.0, 363.5, 402.0, -76.0, -107.0, 104.5, 11.0, 11.5, 220.0, 251.5, 172.0, -97.0, 112.0, 319.5, -55.0, 164.5, -348.5, 331.0, -33.0, -546.0, -6.5, -256.5, 413.5, 220.5, 232.5, 386.0, 225.0, -58.0, 5.5, 59.0, 192.5, 244.0, 89.5, 152.0, 141.5, 92.0, 141.0, 122.5, -93.5, 102.0, 10.5, 160.0, 197.0, 157.5, 202.0, 179.5, 269.0, 19.5, 106.5, 343.5, 187.5, 89.5, 239.0, 169.0, 167.5, 131.5, 0.0, 0.0, 0.0, 47.5, 95.0, 152.0, 367.5, 335.0, 73.0, 9.5, 9.0, 105.5, -3.0, 128.5, 248.5, 201.5, -79.0, 307.0, 74.5, 213.0, 247.0, -178.5, 168.0, 299.5, -1665.0, -65.5, 411.0, 0.0, 0.0, 0.0, -144.0, 299.0, 268.5, 0.0, 209.0, 246.5, 303.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6598457822476207, "mean_inference_ms": 6.67207914246127, "mean_action_processing_ms": 0.14752634788041363, "mean_env_wait_ms": 0.18229871827960742, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004646458576634987, "StateBufferConnector_ms": 0.011149140977367912, "ViewRequirementAgentConnector_ms": 0.3208251343559973}}, "episode_reward_max": 1259.9999999991999, "episode_reward_min": -805.6666666678997, "episode_reward_mean": 399.13333333328393, "episode_len_mean": 69.09, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -203.83333333399992, "cop_policy": -1665.0}, "policy_reward_max": {"mr_x_policy": 513.8333333321, "cop_policy": 413.5}, "policy_reward_mean": {"mr_x_policy": 74.803333333284, "cop_policy": 116.66546762589928}, "hist_stats": {"episode_reward": [552.6666666649, -97.3333333334, -100.33333333339999, 212.1666666666, 585.4999999999, 1079.1666666667998, 31.16666666669998, 266.4999999995, -214.50000000039995, 880.8333333329001, 649.3333333334, -25.499999999800025, -199.3333333333, 440.33333333400003, 763.0000000001002, 234.16666666670002, 442.00000000010004, 498.33333333349987, 2.6666666666000083, 14.500000000400036, -49.499999999899984, 319.166666666, 41.83333333360001, -187.3333333334, 1025.1666666663, -100.0, -8.166666666599994, 668.6666666666999, 166.50000000000003, 26.33333333370001, 423.1666666664999, 920.8333333319, 914.8333333337999, 539.3333333337, 416.6666666671, 71.33333333310003, 951.6666666656, 260.33333333319996, 849.1666666662001, 633.6666666670001, 772.6666666657001, 279.16666666640003, 589.3333333332, 1070.8333333342002, 943.9999999997, 781.3333333329999, -55.33333333240003, -101.6666666667, 261.9999999999, 51.00000000029999, 643.1666666670001, 124.66666666729998, -100.3333333333, 41.333333333599995, 540.4999999998, 793.6666666681001, 607.3333333337, 950.8333333339999, -96.6666666665, 1016.3333333324999, -97.6666666667, 814.6666666661, 863.3333333332, 270.83333333280007, -113.16666666589998, 1259.9999999991999, 938.3333333346, 387.6666666667, 1189.8333333332998, 466.33333333390016, 17.333333333599995, 750.3333333329001, 489.499999999, -333.33333333300004, -6.333333334300025, 428.9999999988, 1132.1666666669998, 248.1666666666, 376.99999999880004, 289.9999999996, 324.5000000005, -78.1666666669, 523.1666666668, 755.3333333329, 855.8333333335999, 572.8333333327, 451.16666666689986, -105.3333333332, 183.16666666700007, 979.3333333330002, 9.000000000100002, 608.1666666673, 582.6666666658999, 735.3333333339999, 373.00000000040006, -805.6666666678997, -105.66666666660001, 668.9999999999, -102.6666666667, 1101.1666666667002], "episode_lengths": [98, 1, 1, 36, 96, 95, 104, 99, 104, 96, 95, 62, 1, 103, 95, 98, 100, 58, 48, 68, 39, 80, 29, 6, 97, 1, 12, 100, 97, 19, 97, 97, 93, 95, 79, 18, 96, 90, 97, 96, 97, 37, 94, 93, 95, 98, 50, 8, 39, 13, 99, 83, 1, 13, 54, 98, 99, 96, 2, 94, 1, 100, 83, 103, 23, 95, 95, 97, 94, 102, 13, 93, 96, 38, 104, 102, 94, 98, 98, 55, 35, 12, 54, 94, 101, 62, 49, 6, 41, 97, 13, 98, 95, 96, 97, 117, 4, 98, 2, 95], "policy_mr_x_policy_reward": [91.16666666490005, -97.3333333334, -100.33333333339999, -153.3333333334, 182.99999999989996, 314.1666666668, 236.16666666669997, -190.0000000005, 122.4999999996, 151.8333333329, 104.33333333340005, -36.99999999979998, -199.3333333333, 421.333333334, 213.50000000009996, 100.6666666667, 227.0000000001, -35.66666666649998, -120.33333333339999, 28.000000000400007, -50.999999999899984, -203.83333333399992, -140.1666666664, -187.3333333334, 253.6666666663, -100.0, -125.6666666666, 377.66666666669994, 23.5, -122.16666666629999, 161.66666666650002, 5.333333331899997, 173.8333333338, 20.8333333337, -29.833333332899983, -91.66666666689999, -46.833333334399995, 17.333333333200002, 186.6666666662, 162.66666666699996, 60.666666665700006, -57.83333333359999, 70.33333333320002, 237.83333333419998, 273.99999999970004, 214.333333333, -50.33333333240001, -101.6666666667, -60.50000000010001, -88.9999999997, 319.666666667, -96.83333333270002, -100.3333333333, -97.6666666664, 49.999999999799996, 301.1666666681, 280.33333333369995, 213.83333333400003, -96.6666666665, 275.3333333325, -97.6666666667, 449.1666666661, 117.83333333319999, 309.83333333279995, -98.6666666659, 388.4999999992, 167.3333333346, 32.666666666699996, 287.33333333330006, 247.33333333390001, -109.6666666664, 106.8333333329, 154.99999999900004, -94.333333333, 241.66666666569998, 278.4999999988, 293.166666667, 75.66666666660001, -118.50000000120002, -93.0000000004, -30.99999999949999, -97.1666666669, 8.666666666799998, 104.83333333290003, 386.3333333335999, 56.83333333269999, -16.8333333331, -105.3333333332, -111.333333333, 203.83333333300004, -114.9999999999, 234.16666666729998, 153.16666666589998, 200.833333334, 84.00000000040001, 513.8333333321, -105.66666666660001, 245.49999999989998, -102.6666666667, 342.6666666667], "policy_cop_policy_reward": [164.0, 147.5, 150.0, 78.0, 146.5, 141.0, 18.0, 152.5, 232.0, 94.5, 263.5, 407.0, 248.0, -399.5, -53.5, 261.5, -52.5, 247.5, -291.0, -319.0, 273.0, 195.0, 281.5, 252.5, -1.0, 194.0, 352.0, 45.0, -150.0, 116.5, -280.0, 296.5, 2.5, 215.5, 316.0, 18.0, 145.0, 250.5, -262.0, 150.5, -22.5, 87.0, 250.0, 112.0, 172.0, 151.5, 115.0, -143.5, -372.0, 234.5, 124.0, 140.0, 30.0, -168.5, 179.0, 75.0, 269.0, 22.5, 31.0, 128.5, 0.0, 0.0, 0.0, -49.5, 410.5, 410.5, 9.5, 5.0, 103.0, 357.0, -14.5, -51.5, -302.0, 114.0, 331.0, 14.0, 112.0, 22.5, 51.5, 324.5, -114.5, 400.0, 304.5, 211.0, 257.5, 283.0, 200.5, 34.5, 279.0, 205.0, 262.5, 161.5, 22.5, 121.0, 19.0, 23.0, 409.0, 354.5, 235.0, 267.5, -192.0, 167.5, 272.0, 230.5, 160.0, -19.5, 185.0, 305.5, 95.5, 405.5, 211.0, 82.5, 187.0, 67.5, 191.0, 124.5, 203.5, 200.5, 273.0, 359.5, 242.0, 309.5, 118.5, 205.0, 119.0, 243.0, -223.5, 114.0, 104.5, 0.0, 0.0, 0.0, 77.0, 133.0, 112.5, 15.5, 19.0, 105.5, -25.5, 250.5, 98.5, -261.0, 202.5, 280.0, 19.5, 103.0, 16.5, 142.5, 167.0, 181.0, 59.5, 399.5, 33.5, 330.5, -160.0, 156.5, 260.0, 267.5, 209.5, 0.0, 282.0, 178.5, 280.5, 343.5, 131.0, -109.0, 153.5, 207.5, 384.5, 171.0, 352.5, -562.5, -170.5, 40.5, 115.5, 267.0, 348.5, 256.0, 118.0, 342.0, 311.0, 226.0, -96.5, 225.5, 245.0, 294.0, 363.5, 402.0, -76.0, -107.0, 104.5, 11.0, 11.5, 220.0, 251.5, 172.0, -97.0, 112.0, 319.5, -55.0, 164.5, -348.5, 331.0, -33.0, -546.0, -6.5, -256.5, 413.5, 220.5, 232.5, 386.0, 225.0, -58.0, 5.5, 59.0, 192.5, 244.0, 89.5, 152.0, 141.5, 92.0, 141.0, 122.5, -93.5, 102.0, 10.5, 160.0, 197.0, 157.5, 202.0, 179.5, 269.0, 19.5, 106.5, 343.5, 187.5, 89.5, 239.0, 169.0, 167.5, 131.5, 0.0, 0.0, 0.0, 47.5, 95.0, 152.0, 367.5, 335.0, 73.0, 9.5, 9.0, 105.5, -3.0, 128.5, 248.5, 201.5, -79.0, 307.0, 74.5, 213.0, 247.0, -178.5, 168.0, 299.5, -1665.0, -65.5, 411.0, 0.0, 0.0, 0.0, -144.0, 299.0, 268.5, 0.0, 209.0, 246.5, 303.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6598457822476207, "mean_inference_ms": 6.67207914246127, "mean_action_processing_ms": 0.14752634788041363, "mean_env_wait_ms": 0.18229871827960742, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.004646458576634987, "StateBufferConnector_ms": 0.011149140977367912, "ViewRequirementAgentConnector_ms": 0.3208251343559973}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.36965373399661, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 32000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 31997, "timers": {"training_iteration_time_ms": 36621.513, "sample_time_ms": 30537.468, "synch_weights_time_ms": 9.799}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 456, "training_iteration": 8, "trial_id": "96d6c_00000", "date": "2024-01-13_10-51-26", "timestamp": 1705139486, "time_this_iter_s": 32.437543630599976, "time_total_s": 293.09448432922363, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F27B880>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 293.09448432922363, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 6.332558139534884, "ram_util_percent": 69.5813953488372, "gpu_util_percent0": 0.21953488372093022, "vram_util_percent0": 0.09163411458333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2960.0, "total_loss": 19.07127466201782}, "mr_x_policy": {"total_loss": 19.07127466201782, "policy_loss": -0.08469103775957289, "vf_loss": 9.476785707473756, "vf_loss_unclipped": 16695.87433268229, "vf_explained_var": 0.006374387939771017, "entropy": 1.164663169781367, "mean_kl_loss": 0.019975252502384442, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.658955065409343, "policy_loss": -0.02798931112338323, "vf_loss": 9.68335116704305, "vf_loss_unclipped": 19215.724609375, "vf_explained_var": 0.002118857701619466, "entropy": 1.2405913492043814, "mean_kl_loss": 0.011977807910443516, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1272.6666666658998, "episode_reward_min": -805.6666666678997, "episode_reward_mean": 440.84333333327197, "episode_len_mean": 71.12, "episode_media": {}, "episodes_this_iter": 57, "policy_reward_min": {"mr_x_policy": -439.00000000050005, "cop_policy": -1665.0}, "policy_reward_max": {"mr_x_policy": 513.8333333321, "cop_policy": 454.5}, "policy_reward_mean": {"mr_x_policy": 65.51333333327199, "cop_policy": 129.4241379310345}, "custom_metrics": {}, "hist_stats": {"episode_reward": [950.8333333339999, -96.6666666665, 1016.3333333324999, -97.6666666667, 814.6666666661, 863.3333333332, 270.83333333280007, -113.16666666589998, 1259.9999999991999, 938.3333333346, 387.6666666667, 1189.8333333332998, 466.33333333390016, 17.333333333599995, 750.3333333329001, 489.499999999, -333.33333333300004, -6.333333334300025, 428.9999999988, 1132.1666666669998, 248.1666666666, 376.99999999880004, 289.9999999996, 324.5000000005, -78.1666666669, 523.1666666668, 755.3333333329, 855.8333333335999, 572.8333333327, 451.16666666689986, -105.3333333332, 183.16666666700007, 979.3333333330002, 9.000000000100002, 608.1666666673, 582.6666666658999, 735.3333333339999, 373.00000000040006, -805.6666666678997, -105.66666666660001, 668.9999999999, -102.6666666667, 1101.1666666667002, 569.9999999996002, -158.00000000010002, 42.50000000009999, 918.0000000000999, 619.9999999986999, 683.8333333332, 982.4999999999002, -66.83333333339999, 330.6666666661001, 106.3333333335, 1173.4999999991, 187.6666666666, 432.99999999989984, 462.5000000008, 422.6666666672999, 572.1666666671001, 1272.6666666658998, 26.166666665800065, 545.6666666666001, 798.1666666663, 1111.9999999998, 745.8333333332001, 726.3333333333, -97.0, 694.4999999994001, -90.16666666699987, 746.3333333336001, 372.0, 889.0000000011999, 199.3333333336, 466.1666666669001, -202.33333333349998, -99.3333333333, 348.16666666570006, 1025.6666666664, 615.8333333333999, -192.33333333320002, -104.9999999998, 668.8333333337999, 8.00000000019999, 790.4999999998001, 1079.8333333334, 183.00000000030002, 588.6666666662001, 374.9999999999999, 218.99999999950006, -106.33333333319999, 795.6666666676999, 95.00000000040001, 1148.666666667, 613.4999999996999, 209.50000000030002, 717.3333333324999, 143.99999999920004, -95.0, 741.6666666668998, 58.66666666809999], "episode_lengths": [96, 2, 94, 1, 100, 83, 103, 23, 95, 95, 97, 94, 102, 13, 93, 96, 38, 104, 102, 94, 98, 98, 55, 35, 12, 54, 94, 101, 62, 49, 6, 41, 97, 13, 98, 95, 96, 97, 117, 4, 98, 2, 95, 96, 19, 30, 95, 97, 96, 95, 20, 99, 19, 94, 34, 97, 97, 100, 97, 95, 90, 96, 79, 97, 97, 98, 1, 95, 104, 98, 51, 96, 101, 102, 6, 6, 52, 95, 100, 9, 4, 61, 9, 100, 94, 24, 99, 99, 100, 4, 94, 18, 95, 97, 41, 95, 101, 4, 76, 102], "policy_mr_x_policy_reward": [213.83333333400003, -96.6666666665, 275.3333333325, -97.6666666667, 449.1666666661, 117.83333333319999, 309.83333333279995, -98.6666666659, 388.4999999992, 167.3333333346, 32.666666666699996, 287.33333333330006, 247.33333333390001, -109.6666666664, 106.8333333329, 154.99999999900004, -94.333333333, 241.66666666569998, 278.4999999988, 293.166666667, 75.66666666660001, -118.50000000120002, -93.0000000004, -30.99999999949999, -97.1666666669, 8.666666666799998, 104.83333333290003, 386.3333333335999, 56.83333333269999, -16.8333333331, -105.3333333332, -111.333333333, 203.83333333300004, -114.9999999999, 234.16666666729998, 153.16666666589998, 200.833333334, 84.00000000040001, 513.8333333321, -105.66666666660001, 245.49999999989998, -102.6666666667, 342.6666666667, 145.99999999960002, -312.50000000010004, -119.49999999990001, 244.50000000010002, 62.49999999870001, -3.6666666668000194, 255.4999999999, -129.3333333334, 185.6666666661, -83.16666666649999, 188.4999999991, -156.33333333340002, -192.0000000001, 58.50000000079999, 219.66666666730003, 193.1666666671, 403.16666666589987, -128.8333333342, -169.8333333334, 93.16666666629995, 190.49999999980002, -92.66666666679994, 262.8333333332999, -97.0, 157.49999999939996, -188.16666666699993, 84.83333333360001, -24.0, 249.0000000012, -13.16666666639998, 341.6666666669, -102.3333333335, -99.3333333333, -51.833333334299994, 119.16666666640002, 306.83333333339993, -192.33333333320002, -104.9999999998, 43.3333333338, -98.49999999980001, -152.50000000020006, 272.3333333334, -60.9999999997, 282.6666666662, 37.50000000000003, -439.00000000050005, -106.33333333319999, 174.1666666677, -86.9999999996, 375.166666667, -44.5000000003, -95.9999999997, -120.66666666750001, 164.9999999992, -95.0, 49.666666666900014, 169.1666666681], "policy_cop_policy_reward": [260.0, 267.5, 209.5, 0.0, 282.0, 178.5, 280.5, 343.5, 131.0, -109.0, 153.5, 207.5, 384.5, 171.0, 352.5, -562.5, -170.5, 40.5, 115.5, 267.0, 348.5, 256.0, 118.0, 342.0, 311.0, 226.0, -96.5, 225.5, 245.0, 294.0, 363.5, 402.0, -76.0, -107.0, 104.5, 11.0, 11.5, 220.0, 251.5, 172.0, -97.0, 112.0, 319.5, -55.0, 164.5, -348.5, 331.0, -33.0, -546.0, -6.5, -256.5, 413.5, 220.5, 232.5, 386.0, 225.0, -58.0, 5.5, 59.0, 192.5, 244.0, 89.5, 152.0, 141.5, 92.0, 141.0, 122.5, -93.5, 102.0, 10.5, 160.0, 197.0, 157.5, 202.0, 179.5, 269.0, 19.5, 106.5, 343.5, 187.5, 89.5, 239.0, 169.0, 167.5, 131.5, 0.0, 0.0, 0.0, 47.5, 95.0, 152.0, 367.5, 335.0, 73.0, 9.5, 9.0, 105.5, -3.0, 128.5, 248.5, 201.5, -79.0, 307.0, 74.5, 213.0, 247.0, -178.5, 168.0, 299.5, -1665.0, -65.5, 411.0, 0.0, 0.0, 0.0, -144.0, 299.0, 268.5, 0.0, 209.0, 246.5, 303.0, -116.5, 200.0, 340.5, 32.0, 109.5, 13.0, 32.5, 73.5, 56.0, 127.5, 323.0, 223.0, 111.0, 246.0, 200.5, 71.0, 275.0, 341.5, 247.0, 223.5, 256.5, -85.5, 120.0, 28.0, 10.0, -9.5, 144.5, 18.5, 122.0, 49.0, 372.5, 447.0, 165.5, 67.0, 162.0, 115.0, 386.0, 187.0, 52.0, 259.5, -52.0, 196.5, -434.5, 412.0, 225.5, 242.5, -124.0, 260.5, 261.5, 330.5, 277.5, 248.0, 117.5, -210.5, 171.0, 256.5, 288.0, 286.5, 233.0, 185.5, 211.0, 330.0, 380.5, 302.5, 263.0, 273.0, 399.5, -115.0, 179.0, 214.0, 73.5, 249.5, -323.5, 144.5, 277.0, 282.5, 263.0, 116.0, 239.0, 111.0, 46.0, 59.0, 362.5, 218.5, 53.5, 292.5, -133.5, -208.5, 51.0, 282.0, -100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 201.5, 16.5, 313.5, 335.5, 257.5, 102.0, 322.5, -115.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 252.0, 177.0, 196.5, 100.0, 4.0, 2.5, 454.5, 317.0, 171.5, 259.0, 296.0, 252.5, 84.0, 42.0, 118.0, -87.5, 309.0, 84.5, 245.5, -41.5, 133.5, 202.5, 229.5, 226.0, 0.0, 0.0, 0.0, 330.5, 224.0, 67.0, 116.0, 38.0, 28.0, 216.5, 144.0, 413.0, 298.5, 171.0, 188.5, 166.0, 107.5, 32.0, 301.5, 333.5, 203.0, 205.0, -340.5, 114.5, 0.0, 0.0, 0.0, 292.5, 179.0, 220.5, -562.0, 266.5, 185.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6522281029607145, "mean_inference_ms": 6.595361224332476, "mean_action_processing_ms": 0.14583381534855716, "mean_env_wait_ms": 0.18068261099799343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006555306791055082, "StateBufferConnector_ms": 0.007183142382689196, "ViewRequirementAgentConnector_ms": 0.3159018478008232}}, "episode_reward_max": 1272.6666666658998, "episode_reward_min": -805.6666666678997, "episode_reward_mean": 440.84333333327197, "episode_len_mean": 71.12, "episodes_this_iter": 57, "policy_reward_min": {"mr_x_policy": -439.00000000050005, "cop_policy": -1665.0}, "policy_reward_max": {"mr_x_policy": 513.8333333321, "cop_policy": 454.5}, "policy_reward_mean": {"mr_x_policy": 65.51333333327199, "cop_policy": 129.4241379310345}, "hist_stats": {"episode_reward": [950.8333333339999, -96.6666666665, 1016.3333333324999, -97.6666666667, 814.6666666661, 863.3333333332, 270.83333333280007, -113.16666666589998, 1259.9999999991999, 938.3333333346, 387.6666666667, 1189.8333333332998, 466.33333333390016, 17.333333333599995, 750.3333333329001, 489.499999999, -333.33333333300004, -6.333333334300025, 428.9999999988, 1132.1666666669998, 248.1666666666, 376.99999999880004, 289.9999999996, 324.5000000005, -78.1666666669, 523.1666666668, 755.3333333329, 855.8333333335999, 572.8333333327, 451.16666666689986, -105.3333333332, 183.16666666700007, 979.3333333330002, 9.000000000100002, 608.1666666673, 582.6666666658999, 735.3333333339999, 373.00000000040006, -805.6666666678997, -105.66666666660001, 668.9999999999, -102.6666666667, 1101.1666666667002, 569.9999999996002, -158.00000000010002, 42.50000000009999, 918.0000000000999, 619.9999999986999, 683.8333333332, 982.4999999999002, -66.83333333339999, 330.6666666661001, 106.3333333335, 1173.4999999991, 187.6666666666, 432.99999999989984, 462.5000000008, 422.6666666672999, 572.1666666671001, 1272.6666666658998, 26.166666665800065, 545.6666666666001, 798.1666666663, 1111.9999999998, 745.8333333332001, 726.3333333333, -97.0, 694.4999999994001, -90.16666666699987, 746.3333333336001, 372.0, 889.0000000011999, 199.3333333336, 466.1666666669001, -202.33333333349998, -99.3333333333, 348.16666666570006, 1025.6666666664, 615.8333333333999, -192.33333333320002, -104.9999999998, 668.8333333337999, 8.00000000019999, 790.4999999998001, 1079.8333333334, 183.00000000030002, 588.6666666662001, 374.9999999999999, 218.99999999950006, -106.33333333319999, 795.6666666676999, 95.00000000040001, 1148.666666667, 613.4999999996999, 209.50000000030002, 717.3333333324999, 143.99999999920004, -95.0, 741.6666666668998, 58.66666666809999], "episode_lengths": [96, 2, 94, 1, 100, 83, 103, 23, 95, 95, 97, 94, 102, 13, 93, 96, 38, 104, 102, 94, 98, 98, 55, 35, 12, 54, 94, 101, 62, 49, 6, 41, 97, 13, 98, 95, 96, 97, 117, 4, 98, 2, 95, 96, 19, 30, 95, 97, 96, 95, 20, 99, 19, 94, 34, 97, 97, 100, 97, 95, 90, 96, 79, 97, 97, 98, 1, 95, 104, 98, 51, 96, 101, 102, 6, 6, 52, 95, 100, 9, 4, 61, 9, 100, 94, 24, 99, 99, 100, 4, 94, 18, 95, 97, 41, 95, 101, 4, 76, 102], "policy_mr_x_policy_reward": [213.83333333400003, -96.6666666665, 275.3333333325, -97.6666666667, 449.1666666661, 117.83333333319999, 309.83333333279995, -98.6666666659, 388.4999999992, 167.3333333346, 32.666666666699996, 287.33333333330006, 247.33333333390001, -109.6666666664, 106.8333333329, 154.99999999900004, -94.333333333, 241.66666666569998, 278.4999999988, 293.166666667, 75.66666666660001, -118.50000000120002, -93.0000000004, -30.99999999949999, -97.1666666669, 8.666666666799998, 104.83333333290003, 386.3333333335999, 56.83333333269999, -16.8333333331, -105.3333333332, -111.333333333, 203.83333333300004, -114.9999999999, 234.16666666729998, 153.16666666589998, 200.833333334, 84.00000000040001, 513.8333333321, -105.66666666660001, 245.49999999989998, -102.6666666667, 342.6666666667, 145.99999999960002, -312.50000000010004, -119.49999999990001, 244.50000000010002, 62.49999999870001, -3.6666666668000194, 255.4999999999, -129.3333333334, 185.6666666661, -83.16666666649999, 188.4999999991, -156.33333333340002, -192.0000000001, 58.50000000079999, 219.66666666730003, 193.1666666671, 403.16666666589987, -128.8333333342, -169.8333333334, 93.16666666629995, 190.49999999980002, -92.66666666679994, 262.8333333332999, -97.0, 157.49999999939996, -188.16666666699993, 84.83333333360001, -24.0, 249.0000000012, -13.16666666639998, 341.6666666669, -102.3333333335, -99.3333333333, -51.833333334299994, 119.16666666640002, 306.83333333339993, -192.33333333320002, -104.9999999998, 43.3333333338, -98.49999999980001, -152.50000000020006, 272.3333333334, -60.9999999997, 282.6666666662, 37.50000000000003, -439.00000000050005, -106.33333333319999, 174.1666666677, -86.9999999996, 375.166666667, -44.5000000003, -95.9999999997, -120.66666666750001, 164.9999999992, -95.0, 49.666666666900014, 169.1666666681], "policy_cop_policy_reward": [260.0, 267.5, 209.5, 0.0, 282.0, 178.5, 280.5, 343.5, 131.0, -109.0, 153.5, 207.5, 384.5, 171.0, 352.5, -562.5, -170.5, 40.5, 115.5, 267.0, 348.5, 256.0, 118.0, 342.0, 311.0, 226.0, -96.5, 225.5, 245.0, 294.0, 363.5, 402.0, -76.0, -107.0, 104.5, 11.0, 11.5, 220.0, 251.5, 172.0, -97.0, 112.0, 319.5, -55.0, 164.5, -348.5, 331.0, -33.0, -546.0, -6.5, -256.5, 413.5, 220.5, 232.5, 386.0, 225.0, -58.0, 5.5, 59.0, 192.5, 244.0, 89.5, 152.0, 141.5, 92.0, 141.0, 122.5, -93.5, 102.0, 10.5, 160.0, 197.0, 157.5, 202.0, 179.5, 269.0, 19.5, 106.5, 343.5, 187.5, 89.5, 239.0, 169.0, 167.5, 131.5, 0.0, 0.0, 0.0, 47.5, 95.0, 152.0, 367.5, 335.0, 73.0, 9.5, 9.0, 105.5, -3.0, 128.5, 248.5, 201.5, -79.0, 307.0, 74.5, 213.0, 247.0, -178.5, 168.0, 299.5, -1665.0, -65.5, 411.0, 0.0, 0.0, 0.0, -144.0, 299.0, 268.5, 0.0, 209.0, 246.5, 303.0, -116.5, 200.0, 340.5, 32.0, 109.5, 13.0, 32.5, 73.5, 56.0, 127.5, 323.0, 223.0, 111.0, 246.0, 200.5, 71.0, 275.0, 341.5, 247.0, 223.5, 256.5, -85.5, 120.0, 28.0, 10.0, -9.5, 144.5, 18.5, 122.0, 49.0, 372.5, 447.0, 165.5, 67.0, 162.0, 115.0, 386.0, 187.0, 52.0, 259.5, -52.0, 196.5, -434.5, 412.0, 225.5, 242.5, -124.0, 260.5, 261.5, 330.5, 277.5, 248.0, 117.5, -210.5, 171.0, 256.5, 288.0, 286.5, 233.0, 185.5, 211.0, 330.0, 380.5, 302.5, 263.0, 273.0, 399.5, -115.0, 179.0, 214.0, 73.5, 249.5, -323.5, 144.5, 277.0, 282.5, 263.0, 116.0, 239.0, 111.0, 46.0, 59.0, 362.5, 218.5, 53.5, 292.5, -133.5, -208.5, 51.0, 282.0, -100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 201.5, 16.5, 313.5, 335.5, 257.5, 102.0, 322.5, -115.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 252.0, 177.0, 196.5, 100.0, 4.0, 2.5, 454.5, 317.0, 171.5, 259.0, 296.0, 252.5, 84.0, 42.0, 118.0, -87.5, 309.0, 84.5, 245.5, -41.5, 133.5, 202.5, 229.5, 226.0, 0.0, 0.0, 0.0, 330.5, 224.0, 67.0, 116.0, 38.0, 28.0, 216.5, 144.0, 413.0, 298.5, 171.0, 188.5, 166.0, 107.5, 32.0, 301.5, 333.5, 203.0, 205.0, -340.5, 114.5, 0.0, 0.0, 0.0, 292.5, 179.0, 220.5, -562.0, 266.5, 185.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6522281029607145, "mean_inference_ms": 6.595361224332476, "mean_action_processing_ms": 0.14583381534855716, "mean_env_wait_ms": 0.18068261099799343, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006555306791055082, "StateBufferConnector_ms": 0.007183142382689196, "ViewRequirementAgentConnector_ms": 0.3159018478008232}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.08087182368074, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 36000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 35997, "timers": {"training_iteration_time_ms": 36414.474, "sample_time_ms": 30341.293, "synch_weights_time_ms": 10.34}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 513, "training_iteration": 9, "trial_id": "96d6c_00000", "date": "2024-01-13_10-52-00", "timestamp": 1705139520, "time_this_iter_s": 34.7735755443573, "time_total_s": 327.86805987358093, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E51B0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 327.86805987358093, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 9.515217391304347, "ram_util_percent": 61.25652173913042, "gpu_util_percent0": 0.2334782608695652, "vram_util_percent0": 0.09333248414855073}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2978.0, "total_loss": 19.130605347951253}, "mr_x_policy": {"total_loss": 19.130605347951253, "policy_loss": -0.07340592360123992, "vf_loss": 9.555275217692058, "vf_loss_unclipped": 19615.876497395835, "vf_explained_var": 0.008586803078651428, "entropy": 1.1310990750789642, "mean_kl_loss": 0.017022912274114788, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.631500625610352, "policy_loss": -0.02528321915306151, "vf_loss": 9.652048778533935, "vf_loss_unclipped": 20951.268815104166, "vf_explained_var": -0.0026941438515981036, "entropy": 1.227737013498942, "mean_kl_loss": 0.01578397594736695, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1272.6666666658998, "episode_reward_min": -607.6666666676001, "episode_reward_mean": 447.77666666671195, "episode_len_mean": 69.8, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -686.6666666666999, "cop_policy": -690.0}, "policy_reward_max": {"mr_x_policy": 488.8333333327, "cop_policy": 454.5}, "policy_reward_mean": {"mr_x_policy": 58.23666666671199, "cop_policy": 133.4041095890411}, "custom_metrics": {}, "hist_stats": {"episode_reward": [572.1666666671001, 1272.6666666658998, 26.166666665800065, 545.6666666666001, 798.1666666663, 1111.9999999998, 745.8333333332001, 726.3333333333, -97.0, 694.4999999994001, -90.16666666699987, 746.3333333336001, 372.0, 889.0000000011999, 199.3333333336, 466.1666666669001, -202.33333333349998, -99.3333333333, 348.16666666570006, 1025.6666666664, 615.8333333333999, -192.33333333320002, -104.9999999998, 668.8333333337999, 8.00000000019999, 790.4999999998001, 1079.8333333334, 183.00000000030002, 588.6666666662001, 374.9999999999999, 218.99999999950006, -106.33333333319999, 795.6666666676999, 95.00000000040001, 1148.666666667, 613.4999999996999, 209.50000000030002, 717.3333333324999, 143.99999999920004, -95.0, 741.6666666668998, 58.66666666809999, 918.9999999987, 15.666666666799998, 858.3333333326998, 124.66666666680001, 1066.833333334, 8.99999999969998, 1022.0000000003002, 544.5000000004, -118.00000000069997, 433.1666666677, 970.1666666671003, -86.66666666670001, -205.66666666650002, 1022.9999999993998, 23.50000000060001, 1054.9999999999, 6.833333333300004, -607.6666666676001, -147.1666666667, 522.666666667, 161.16666666600003, 236.6666666666, 693.6666666669997, -212.33333333210007, 654.9999999997999, 644.5000000011, 1184.9999999999002, -106.6666666667, 109.83333333359997, 46.166666666699996, -108.3333333332, 584.8333333338999, 680.6666666663001, 624.9999999998001, 773.6666666669001, 622.9999999989999, -89.8333333335, 951.1666666669004, 726.3333333337999, 979.6666666662002, 591.6666666667999, -101.6666666667, 212.50000000079993, 799.3333333323, -538.1666666666999, -97.9999999999, 642.0000000013, 298.8333333336, 782.0000000006002, 13.333333333599995, 1163.8333333335001, 837.0000000003, 159.49999999980002, 908.333333333, 879.4999999997999, 1167.3333333337, 683.5000000012999, 1183.1666666667002], "episode_lengths": [97, 95, 90, 96, 79, 97, 97, 98, 1, 95, 104, 98, 51, 96, 101, 102, 6, 6, 52, 95, 100, 9, 4, 61, 9, 100, 94, 24, 99, 99, 100, 4, 94, 18, 95, 97, 41, 95, 101, 4, 76, 102, 93, 18, 102, 17, 95, 18, 95, 96, 37, 99, 97, 6, 4, 94, 70, 94, 18, 51, 29, 100, 31, 71, 94, 107, 100, 100, 95, 5, 36, 13, 3, 99, 96, 99, 101, 101, 16, 96, 93, 95, 96, 1, 98, 98, 20, 5, 95, 98, 98, 10, 94, 95, 33, 96, 94, 95, 99, 89], "policy_mr_x_policy_reward": [193.1666666671, 403.16666666589987, -128.8333333342, -169.8333333334, 93.16666666629995, 190.49999999980002, -92.66666666679994, 262.8333333332999, -97.0, 157.49999999939996, -188.16666666699993, 84.83333333360001, -24.0, 249.0000000012, -13.16666666639998, 341.6666666669, -102.3333333335, -99.3333333333, -51.833333334299994, 119.16666666640002, 306.83333333339993, -192.33333333320002, -104.9999999998, 43.3333333338, -98.49999999980001, -152.50000000020006, 272.3333333334, -60.9999999997, 282.6666666662, 37.50000000000003, -439.00000000050005, -106.33333333319999, 174.1666666677, -86.9999999996, 375.166666667, -44.5000000003, -95.9999999997, -120.66666666750001, 164.9999999992, -95.0, 49.666666666900014, 169.1666666681, 165.4999999987, -72.8333333332, 488.8333333327, -70.8333333332, 303.83333333400003, -181.50000000030002, 277.00000000029996, 57.00000000040001, -287.00000000069997, 167.1666666677, 32.166666667099975, -86.66666666670001, -105.6666666665, 297.9999999994, -126.99999999939999, 141.49999999989996, -175.1666666667, -108.1666666676, -132.1666666667, 279.666666667, -101.833333334, -48.83333333339999, 107.166666667, 281.16666666789996, 265.9999999998, 239.00000000110003, 359.4999999999, -106.6666666667, -254.66666666640003, -91.3333333333, -108.3333333332, 266.8333333339, 220.16666666630002, 170.49999999980002, -8.333333333099961, 253.999999999, -123.8333333335, 223.6666666669, 82.83333333380001, 248.6666666662, 211.66666666679998, -101.6666666667, 86.50000000080001, 185.33333333230001, -686.6666666666999, -97.9999999999, 159.00000000129998, 136.33333333360002, 297.00000000060004, -99.6666666664, 285.8333333335, 238.0000000003, -100.0000000002, 331.83333333300004, 189.4999999998, 346.3333333337, 71.5000000013, 225.6666666667], "policy_cop_policy_reward": [242.5, -124.0, 260.5, 261.5, 330.5, 277.5, 248.0, 117.5, -210.5, 171.0, 256.5, 288.0, 286.5, 233.0, 185.5, 211.0, 330.0, 380.5, 302.5, 263.0, 273.0, 399.5, -115.0, 179.0, 214.0, 73.5, 249.5, -323.5, 144.5, 277.0, 282.5, 263.0, 116.0, 239.0, 111.0, 46.0, 59.0, 362.5, 218.5, 53.5, 292.5, -133.5, -208.5, 51.0, 282.0, -100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 201.5, 16.5, 313.5, 335.5, 257.5, 102.0, 322.5, -115.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 252.0, 177.0, 196.5, 100.0, 4.0, 2.5, 454.5, 317.0, 171.5, 259.0, 296.0, 252.5, 84.0, 42.0, 118.0, -87.5, 309.0, 84.5, 245.5, -41.5, 133.5, 202.5, 229.5, 226.0, 0.0, 0.0, 0.0, 330.5, 224.0, 67.0, 116.0, 38.0, 28.0, 216.5, 144.0, 413.0, 298.5, 171.0, 188.5, 166.0, 107.5, 32.0, 301.5, 333.5, 203.0, 205.0, -340.5, 114.5, 0.0, 0.0, 0.0, 292.5, 179.0, 220.5, -562.0, 266.5, 185.0, 212.0, 214.5, 327.0, -70.5, 110.0, 49.0, 81.5, -31.0, 319.0, 115.0, 38.0, 42.5, 139.5, 365.0, 258.5, 115.5, 38.0, 37.0, 193.5, 317.0, 234.5, 112.0, 125.0, 250.5, 136.5, -22.0, 54.5, 260.0, 238.5, -232.5, 388.5, 449.0, 100.5, 0.0, 0.0, 0.0, -100.0, 0.0, 253.5, 284.0, 187.5, -14.0, -24.5, 189.0, 337.0, 281.0, 295.5, 110.0, 38.0, 34.0, -598.5, -54.0, 153.0, 42.5, -90.0, 32.5, 304.0, 214.0, -275.0, 49.0, 125.0, 89.0, -77.0, 160.0, 202.5, 114.5, 160.0, 312.0, 185.5, -690.0, 11.0, 285.5, -282.0, 385.5, 287.5, -198.0, 316.0, 140.0, 357.0, 328.5, 0.0, 0.0, 0.0, 165.5, 74.0, 125.0, 10.5, 21.5, 105.5, 0.0, 0.0, 357.5, 280.0, -319.5, 98.5, 193.0, 169.0, 102.0, 91.0, 261.5, 163.0, 339.0, 280.0, -48.5, 221.0, 196.5, 20.5, 104.5, -91.0, 239.0, 203.0, 285.5, 253.5, 155.5, 234.5, 114.5, 378.0, 238.5, -51.5, 186.0, 245.5, 54.0, 218.5, -146.5, 129.0, 44.0, 441.0, 107.0, 25.0, 16.5, 0.0, 0.0, 0.0, 257.0, 60.5, 165.5, 203.5, -132.5, 91.5, -161.5, 219.0, 427.5, 101.0, 4.0, 8.0, 295.5, 204.5, 378.0, 104.5, 164.0, 330.5, 147.0, 34.5, 78.0, -20.0, 261.0, 335.5, 243.5, 244.5, 202.0, 122.5, 347.0, 351.5, 168.5, 400.0, 43.5, 242.0, 365.5, 350.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6469455441485943, "mean_inference_ms": 6.532047971633818, "mean_action_processing_ms": 0.14425032500633217, "mean_env_wait_ms": 0.17855112853573143, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005563461419307824, "StateBufferConnector_ms": 0.009084470344312263, "ViewRequirementAgentConnector_ms": 0.31479886083891895}}, "episode_reward_max": 1272.6666666658998, "episode_reward_min": -607.6666666676001, "episode_reward_mean": 447.77666666671195, "episode_len_mean": 69.8, "episodes_this_iter": 58, "policy_reward_min": {"mr_x_policy": -686.6666666666999, "cop_policy": -690.0}, "policy_reward_max": {"mr_x_policy": 488.8333333327, "cop_policy": 454.5}, "policy_reward_mean": {"mr_x_policy": 58.23666666671199, "cop_policy": 133.4041095890411}, "hist_stats": {"episode_reward": [572.1666666671001, 1272.6666666658998, 26.166666665800065, 545.6666666666001, 798.1666666663, 1111.9999999998, 745.8333333332001, 726.3333333333, -97.0, 694.4999999994001, -90.16666666699987, 746.3333333336001, 372.0, 889.0000000011999, 199.3333333336, 466.1666666669001, -202.33333333349998, -99.3333333333, 348.16666666570006, 1025.6666666664, 615.8333333333999, -192.33333333320002, -104.9999999998, 668.8333333337999, 8.00000000019999, 790.4999999998001, 1079.8333333334, 183.00000000030002, 588.6666666662001, 374.9999999999999, 218.99999999950006, -106.33333333319999, 795.6666666676999, 95.00000000040001, 1148.666666667, 613.4999999996999, 209.50000000030002, 717.3333333324999, 143.99999999920004, -95.0, 741.6666666668998, 58.66666666809999, 918.9999999987, 15.666666666799998, 858.3333333326998, 124.66666666680001, 1066.833333334, 8.99999999969998, 1022.0000000003002, 544.5000000004, -118.00000000069997, 433.1666666677, 970.1666666671003, -86.66666666670001, -205.66666666650002, 1022.9999999993998, 23.50000000060001, 1054.9999999999, 6.833333333300004, -607.6666666676001, -147.1666666667, 522.666666667, 161.16666666600003, 236.6666666666, 693.6666666669997, -212.33333333210007, 654.9999999997999, 644.5000000011, 1184.9999999999002, -106.6666666667, 109.83333333359997, 46.166666666699996, -108.3333333332, 584.8333333338999, 680.6666666663001, 624.9999999998001, 773.6666666669001, 622.9999999989999, -89.8333333335, 951.1666666669004, 726.3333333337999, 979.6666666662002, 591.6666666667999, -101.6666666667, 212.50000000079993, 799.3333333323, -538.1666666666999, -97.9999999999, 642.0000000013, 298.8333333336, 782.0000000006002, 13.333333333599995, 1163.8333333335001, 837.0000000003, 159.49999999980002, 908.333333333, 879.4999999997999, 1167.3333333337, 683.5000000012999, 1183.1666666667002], "episode_lengths": [97, 95, 90, 96, 79, 97, 97, 98, 1, 95, 104, 98, 51, 96, 101, 102, 6, 6, 52, 95, 100, 9, 4, 61, 9, 100, 94, 24, 99, 99, 100, 4, 94, 18, 95, 97, 41, 95, 101, 4, 76, 102, 93, 18, 102, 17, 95, 18, 95, 96, 37, 99, 97, 6, 4, 94, 70, 94, 18, 51, 29, 100, 31, 71, 94, 107, 100, 100, 95, 5, 36, 13, 3, 99, 96, 99, 101, 101, 16, 96, 93, 95, 96, 1, 98, 98, 20, 5, 95, 98, 98, 10, 94, 95, 33, 96, 94, 95, 99, 89], "policy_mr_x_policy_reward": [193.1666666671, 403.16666666589987, -128.8333333342, -169.8333333334, 93.16666666629995, 190.49999999980002, -92.66666666679994, 262.8333333332999, -97.0, 157.49999999939996, -188.16666666699993, 84.83333333360001, -24.0, 249.0000000012, -13.16666666639998, 341.6666666669, -102.3333333335, -99.3333333333, -51.833333334299994, 119.16666666640002, 306.83333333339993, -192.33333333320002, -104.9999999998, 43.3333333338, -98.49999999980001, -152.50000000020006, 272.3333333334, -60.9999999997, 282.6666666662, 37.50000000000003, -439.00000000050005, -106.33333333319999, 174.1666666677, -86.9999999996, 375.166666667, -44.5000000003, -95.9999999997, -120.66666666750001, 164.9999999992, -95.0, 49.666666666900014, 169.1666666681, 165.4999999987, -72.8333333332, 488.8333333327, -70.8333333332, 303.83333333400003, -181.50000000030002, 277.00000000029996, 57.00000000040001, -287.00000000069997, 167.1666666677, 32.166666667099975, -86.66666666670001, -105.6666666665, 297.9999999994, -126.99999999939999, 141.49999999989996, -175.1666666667, -108.1666666676, -132.1666666667, 279.666666667, -101.833333334, -48.83333333339999, 107.166666667, 281.16666666789996, 265.9999999998, 239.00000000110003, 359.4999999999, -106.6666666667, -254.66666666640003, -91.3333333333, -108.3333333332, 266.8333333339, 220.16666666630002, 170.49999999980002, -8.333333333099961, 253.999999999, -123.8333333335, 223.6666666669, 82.83333333380001, 248.6666666662, 211.66666666679998, -101.6666666667, 86.50000000080001, 185.33333333230001, -686.6666666666999, -97.9999999999, 159.00000000129998, 136.33333333360002, 297.00000000060004, -99.6666666664, 285.8333333335, 238.0000000003, -100.0000000002, 331.83333333300004, 189.4999999998, 346.3333333337, 71.5000000013, 225.6666666667], "policy_cop_policy_reward": [242.5, -124.0, 260.5, 261.5, 330.5, 277.5, 248.0, 117.5, -210.5, 171.0, 256.5, 288.0, 286.5, 233.0, 185.5, 211.0, 330.0, 380.5, 302.5, 263.0, 273.0, 399.5, -115.0, 179.0, 214.0, 73.5, 249.5, -323.5, 144.5, 277.0, 282.5, 263.0, 116.0, 239.0, 111.0, 46.0, 59.0, 362.5, 218.5, 53.5, 292.5, -133.5, -208.5, 51.0, 282.0, -100.0, 0.0, 0.0, 0.0, 0.0, 0.0, 182.0, 201.5, 16.5, 313.5, 335.5, 257.5, 102.0, 322.5, -115.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 252.0, 177.0, 196.5, 100.0, 4.0, 2.5, 454.5, 317.0, 171.5, 259.0, 296.0, 252.5, 84.0, 42.0, 118.0, -87.5, 309.0, 84.5, 245.5, -41.5, 133.5, 202.5, 229.5, 226.0, 0.0, 0.0, 0.0, 330.5, 224.0, 67.0, 116.0, 38.0, 28.0, 216.5, 144.0, 413.0, 298.5, 171.0, 188.5, 166.0, 107.5, 32.0, 301.5, 333.5, 203.0, 205.0, -340.5, 114.5, 0.0, 0.0, 0.0, 292.5, 179.0, 220.5, -562.0, 266.5, 185.0, 212.0, 214.5, 327.0, -70.5, 110.0, 49.0, 81.5, -31.0, 319.0, 115.0, 38.0, 42.5, 139.5, 365.0, 258.5, 115.5, 38.0, 37.0, 193.5, 317.0, 234.5, 112.0, 125.0, 250.5, 136.5, -22.0, 54.5, 260.0, 238.5, -232.5, 388.5, 449.0, 100.5, 0.0, 0.0, 0.0, -100.0, 0.0, 253.5, 284.0, 187.5, -14.0, -24.5, 189.0, 337.0, 281.0, 295.5, 110.0, 38.0, 34.0, -598.5, -54.0, 153.0, 42.5, -90.0, 32.5, 304.0, 214.0, -275.0, 49.0, 125.0, 89.0, -77.0, 160.0, 202.5, 114.5, 160.0, 312.0, 185.5, -690.0, 11.0, 285.5, -282.0, 385.5, 287.5, -198.0, 316.0, 140.0, 357.0, 328.5, 0.0, 0.0, 0.0, 165.5, 74.0, 125.0, 10.5, 21.5, 105.5, 0.0, 0.0, 357.5, 280.0, -319.5, 98.5, 193.0, 169.0, 102.0, 91.0, 261.5, 163.0, 339.0, 280.0, -48.5, 221.0, 196.5, 20.5, 104.5, -91.0, 239.0, 203.0, 285.5, 253.5, 155.5, 234.5, 114.5, 378.0, 238.5, -51.5, 186.0, 245.5, 54.0, 218.5, -146.5, 129.0, 44.0, 441.0, 107.0, 25.0, 16.5, 0.0, 0.0, 0.0, 257.0, 60.5, 165.5, 203.5, -132.5, 91.5, -161.5, 219.0, 427.5, 101.0, 4.0, 8.0, 295.5, 204.5, 378.0, 104.5, 164.0, 330.5, 147.0, 34.5, 78.0, -20.0, 261.0, 335.5, 243.5, 244.5, 202.0, 122.5, 347.0, 351.5, 168.5, 400.0, 43.5, 242.0, 365.5, 350.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6469455441485943, "mean_inference_ms": 6.532047971633818, "mean_action_processing_ms": 0.14425032500633217, "mean_env_wait_ms": 0.17855112853573143, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005563461419307824, "StateBufferConnector_ms": 0.009084470344312263, "ViewRequirementAgentConnector_ms": 0.31479886083891895}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.6954081134459, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 40000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 39997, "timers": {"training_iteration_time_ms": 36033.033, "sample_time_ms": 29987.805, "synch_weights_time_ms": 10.409}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 571, "training_iteration": 10, "trial_id": "96d6c_00000", "date": "2024-01-13_10-52-33", "timestamp": 1705139553, "time_this_iter_s": 32.61508560180664, "time_total_s": 360.4831454753876, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E5090>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 360.4831454753876, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 6.252380952380953, "ram_util_percent": 56.95238095238095, "gpu_util_percent0": 0.23571428571428568, "vram_util_percent0": 0.08970424107142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2976.0, "total_loss": 19.24175936381022}, "mr_x_policy": {"total_loss": 19.24175936381022, "policy_loss": -0.08308001799032354, "vf_loss": 9.652333704630534, "vf_loss_unclipped": 16240.004703776041, "vf_explained_var": 0.007576293746630351, "entropy": 1.0727450609207154, "mean_kl_loss": 0.019200999820168364, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.653064839045207, "policy_loss": -0.02670225923260053, "vf_loss": 9.67569793065389, "vf_loss_unclipped": 20855.855712890625, "vf_explained_var": -0.001401542623837789, "entropy": 1.2306606829166413, "mean_kl_loss": 0.013564259291160851, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1319.5, "episode_reward_min": -607.6666666676001, "episode_reward_mean": 464.80333333348705, "episode_len_mean": 71.23, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"mr_x_policy": -686.6666666666999, "cop_policy": -690.0}, "policy_reward_max": {"mr_x_policy": 359.4999999999, "cop_policy": 483.0}, "policy_reward_mean": {"mr_x_policy": 76.568333333487, "cop_policy": 133.87413793103448}, "custom_metrics": {}, "hist_stats": {"episode_reward": [23.50000000060001, 1054.9999999999, 6.833333333300004, -607.6666666676001, -147.1666666667, 522.666666667, 161.16666666600003, 236.6666666666, 693.6666666669997, -212.33333333210007, 654.9999999997999, 644.5000000011, 1184.9999999999002, -106.6666666667, 109.83333333359997, 46.166666666699996, -108.3333333332, 584.8333333338999, 680.6666666663001, 624.9999999998001, 773.6666666669001, 622.9999999989999, -89.8333333335, 951.1666666669004, 726.3333333337999, 979.6666666662002, 591.6666666667999, -101.6666666667, 212.50000000079993, 799.3333333323, -538.1666666666999, -97.9999999999, 642.0000000013, 298.8333333336, 782.0000000006002, 13.333333333599995, 1163.8333333335001, 837.0000000003, 159.49999999980002, 908.333333333, 879.4999999997999, 1167.3333333337, 683.5000000012999, 1183.1666666667002, 839.1666666663001, 1240.5000000001996, -101.3333333333, 659.3333333327, 749.6666666674998, 619.9999999998001, 843.6666666671001, -36.66666666660001, 622.8333333337999, 30.333333333899958, 6.833333333399992, 831.1666666662999, 732.0000000001, 850.3333333339999, 1048.1666666662002, 1021.3333333321, 25.333333333100065, -82.00000000009999, 363.49999999989996, 796.0000000005999, 208.16666666720008, 538.6666666676999, 373.66666666700013, 1125.1666666662998, 1104.5000000004002, -346.3333333331999, 98.16666666720002, 6.333333334599999, -194.0, 975.1666666675, 904.1666666668002, 80.16666666649999, 1185.1666666675003, -90.66666666639998, 105.66666666629993, 335.00000000010004, 877.0000000004, 148.99999999969998, -7.500000000099988, 108.66666666670001, 606.3333333337999, 208.16666666690003, 118.6666666667, 717.6666666678001, 598.0000000002001, -268.33333333319996, 1201.6666666669998, 1319.5, 490.5000000006001, 899.8333333331999, 529.5000000001, -105.1666666669, 13.999999999899998, 613.6666666670001, 38.000000000100016, 1305.666666668], "episode_lengths": [70, 94, 18, 51, 29, 100, 31, 71, 94, 107, 100, 100, 95, 5, 36, 13, 3, 99, 96, 99, 101, 101, 16, 96, 93, 95, 96, 1, 98, 98, 20, 5, 95, 98, 98, 10, 94, 95, 33, 96, 94, 95, 99, 89, 97, 94, 1, 89, 93, 71, 95, 14, 97, 89, 9, 96, 84, 94, 94, 95, 106, 10, 102, 98, 101, 100, 102, 93, 95, 105, 84, 43, 2, 98, 96, 12, 93, 26, 96, 100, 94, 61, 13, 18, 97, 29, 21, 100, 95, 102, 93, 93, 47, 96, 58, 10, 9, 79, 13, 94], "policy_mr_x_policy_reward": [-126.99999999939999, 141.49999999989996, -175.1666666667, -108.1666666676, -132.1666666667, 279.666666667, -101.833333334, -48.83333333339999, 107.166666667, 281.16666666789996, 265.9999999998, 239.00000000110003, 359.4999999999, -106.6666666667, -254.66666666640003, -91.3333333333, -108.3333333332, 266.8333333339, 220.16666666630002, 170.49999999980002, -8.333333333099961, 253.999999999, -123.8333333335, 223.6666666669, 82.83333333380001, 248.6666666662, 211.66666666679998, -101.6666666667, 86.50000000080001, 185.33333333230001, -686.6666666666999, -97.9999999999, 159.00000000129998, 136.33333333360002, 297.00000000060004, -99.6666666664, 285.8333333335, 238.0000000003, -100.0000000002, 331.83333333300004, 189.4999999998, 346.3333333337, 71.5000000013, 225.6666666667, 297.6666666663, 317.50000000020003, -101.3333333333, -22.66666666730002, 112.1666666675, -19.000000000199975, 34.16666666710003, -183.6666666666, -67.6666666662, 21.3333333339, -100.16666666660001, 259.66666666630005, 19.000000000100002, 86.833333334, 271.66666666619994, 300.3333333321, 190.33333333309994, -190.5000000001, 96.49999999989997, 334.5000000006, 259.6666666672, 265.16666666770004, 345.666666667, 295.1666666663001, 347.00000000040006, -106.83333333319997, -142.33333333279998, -88.1666666654, -194.0, 250.6666666675, 292.16666666680004, -62.33333333350001, 247.1666666675, -147.1666666664, -1.8333333337000255, 224.00000000010002, 59.5000000004, -114.0000000003, -124.00000000009999, -70.3333333333, 208.8333333338, -58.83333333310001, -87.33333333329999, 345.1666666678, -51.499999999799996, -210.33333333320002, 270.16666666699996, 330.49999999999994, 70.50000000059995, 58.83333333320001, 44.00000000009999, -110.1666666669, -92.5000000001, 56.66666666699999, -92.9999999999, 351.166666668], "policy_cop_policy_reward": [-14.0, -24.5, 189.0, 337.0, 281.0, 295.5, 110.0, 38.0, 34.0, -598.5, -54.0, 153.0, 42.5, -90.0, 32.5, 304.0, 214.0, -275.0, 49.0, 125.0, 89.0, -77.0, 160.0, 202.5, 114.5, 160.0, 312.0, 185.5, -690.0, 11.0, 285.5, -282.0, 385.5, 287.5, -198.0, 316.0, 140.0, 357.0, 328.5, 0.0, 0.0, 0.0, 165.5, 74.0, 125.0, 10.5, 21.5, 105.5, 0.0, 0.0, 357.5, 280.0, -319.5, 98.5, 193.0, 169.0, 102.0, 91.0, 261.5, 163.0, 339.0, 280.0, -48.5, 221.0, 196.5, 20.5, 104.5, -91.0, 239.0, 203.0, 285.5, 253.5, 155.5, 234.5, 114.5, 378.0, 238.5, -51.5, 186.0, 245.5, 54.0, 218.5, -146.5, 129.0, 44.0, 441.0, 107.0, 25.0, 16.5, 0.0, 0.0, 0.0, 257.0, 60.5, 165.5, 203.5, -132.5, 91.5, -161.5, 219.0, 427.5, 101.0, 4.0, 8.0, 295.5, 204.5, 378.0, 104.5, 164.0, 330.5, 147.0, 34.5, 78.0, -20.0, 261.0, 335.5, 243.5, 244.5, 202.0, 122.5, 347.0, 351.5, 168.5, 400.0, 43.5, 242.0, 365.5, 350.0, 150.5, 370.0, 21.0, 266.5, 398.5, 258.0, 77.5, 312.0, 292.5, 251.0, 201.0, 185.5, 278.0, 256.5, 104.5, 219.5, 333.5, 256.5, 104.5, 26.0, 16.5, 55.0, 353.0, 282.5, 0.0, -240.5, 249.5, 2.0, 5.0, 100.0, 65.0, 222.0, 284.5, 153.5, 207.0, 352.5, 243.0, 342.5, 178.0, 205.0, 429.5, 142.0, 174.5, 306.0, 240.5, -299.5, -240.0, 374.5, 5.0, 100.0, 3.5, -183.0, 153.5, 296.5, 183.5, 347.5, -69.5, -365.0, -22.0, 335.5, 104.5, -158.0, 327.0, 65.0, -315.5, 278.5, 291.5, 394.0, 144.5, 149.0, 172.0, 436.5, -404.5, -54.0, 219.0, -183.5, 138.0, 286.0, 52.0, 53.0, -10.5, 483.0, -25.0, 266.5, 10.5, 277.5, 324.0, 16.5, 23.0, 103.0, 282.0, 363.5, 292.5, 13.0, 24.5, 19.0, 47.5, -243.5, 303.5, -204.0, 141.5, 173.5, 201.0, 266.0, 350.5, -107.5, 172.5, 198.0, 104.5, 6.0, 6.0, 121.0, 23.0, 35.0, 12.5, 163.5, 221.5, 59.0, 125.0, 83.0, 17.0, 127.0, 62.0, -266.0, 219.0, 419.5, 262.0, 77.0, 310.5, -366.5, -20.0, 328.5, 229.5, 327.5, 374.5, 397.5, 293.5, 298.0, 217.0, 172.5, 30.5, 411.0, 237.5, 192.5, 134.5, 236.0, 115.0, -98.5, 100.0, 3.5, 3.0, 100.0, 3.5, 206.5, 254.0, 96.5, 17.0, 105.0, 9.0, 404.5, 278.0, 272.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.640456881446892, "mean_inference_ms": 6.478791297781886, "mean_action_processing_ms": 0.14212002515498975, "mean_env_wait_ms": 0.1758598239101265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00355388912452659, "StateBufferConnector_ms": 0.007112498210771435, "ViewRequirementAgentConnector_ms": 0.31460457041783985}}, "episode_reward_max": 1319.5, "episode_reward_min": -607.6666666676001, "episode_reward_mean": 464.80333333348705, "episode_len_mean": 71.23, "episodes_this_iter": 56, "policy_reward_min": {"mr_x_policy": -686.6666666666999, "cop_policy": -690.0}, "policy_reward_max": {"mr_x_policy": 359.4999999999, "cop_policy": 483.0}, "policy_reward_mean": {"mr_x_policy": 76.568333333487, "cop_policy": 133.87413793103448}, "hist_stats": {"episode_reward": [23.50000000060001, 1054.9999999999, 6.833333333300004, -607.6666666676001, -147.1666666667, 522.666666667, 161.16666666600003, 236.6666666666, 693.6666666669997, -212.33333333210007, 654.9999999997999, 644.5000000011, 1184.9999999999002, -106.6666666667, 109.83333333359997, 46.166666666699996, -108.3333333332, 584.8333333338999, 680.6666666663001, 624.9999999998001, 773.6666666669001, 622.9999999989999, -89.8333333335, 951.1666666669004, 726.3333333337999, 979.6666666662002, 591.6666666667999, -101.6666666667, 212.50000000079993, 799.3333333323, -538.1666666666999, -97.9999999999, 642.0000000013, 298.8333333336, 782.0000000006002, 13.333333333599995, 1163.8333333335001, 837.0000000003, 159.49999999980002, 908.333333333, 879.4999999997999, 1167.3333333337, 683.5000000012999, 1183.1666666667002, 839.1666666663001, 1240.5000000001996, -101.3333333333, 659.3333333327, 749.6666666674998, 619.9999999998001, 843.6666666671001, -36.66666666660001, 622.8333333337999, 30.333333333899958, 6.833333333399992, 831.1666666662999, 732.0000000001, 850.3333333339999, 1048.1666666662002, 1021.3333333321, 25.333333333100065, -82.00000000009999, 363.49999999989996, 796.0000000005999, 208.16666666720008, 538.6666666676999, 373.66666666700013, 1125.1666666662998, 1104.5000000004002, -346.3333333331999, 98.16666666720002, 6.333333334599999, -194.0, 975.1666666675, 904.1666666668002, 80.16666666649999, 1185.1666666675003, -90.66666666639998, 105.66666666629993, 335.00000000010004, 877.0000000004, 148.99999999969998, -7.500000000099988, 108.66666666670001, 606.3333333337999, 208.16666666690003, 118.6666666667, 717.6666666678001, 598.0000000002001, -268.33333333319996, 1201.6666666669998, 1319.5, 490.5000000006001, 899.8333333331999, 529.5000000001, -105.1666666669, 13.999999999899998, 613.6666666670001, 38.000000000100016, 1305.666666668], "episode_lengths": [70, 94, 18, 51, 29, 100, 31, 71, 94, 107, 100, 100, 95, 5, 36, 13, 3, 99, 96, 99, 101, 101, 16, 96, 93, 95, 96, 1, 98, 98, 20, 5, 95, 98, 98, 10, 94, 95, 33, 96, 94, 95, 99, 89, 97, 94, 1, 89, 93, 71, 95, 14, 97, 89, 9, 96, 84, 94, 94, 95, 106, 10, 102, 98, 101, 100, 102, 93, 95, 105, 84, 43, 2, 98, 96, 12, 93, 26, 96, 100, 94, 61, 13, 18, 97, 29, 21, 100, 95, 102, 93, 93, 47, 96, 58, 10, 9, 79, 13, 94], "policy_mr_x_policy_reward": [-126.99999999939999, 141.49999999989996, -175.1666666667, -108.1666666676, -132.1666666667, 279.666666667, -101.833333334, -48.83333333339999, 107.166666667, 281.16666666789996, 265.9999999998, 239.00000000110003, 359.4999999999, -106.6666666667, -254.66666666640003, -91.3333333333, -108.3333333332, 266.8333333339, 220.16666666630002, 170.49999999980002, -8.333333333099961, 253.999999999, -123.8333333335, 223.6666666669, 82.83333333380001, 248.6666666662, 211.66666666679998, -101.6666666667, 86.50000000080001, 185.33333333230001, -686.6666666666999, -97.9999999999, 159.00000000129998, 136.33333333360002, 297.00000000060004, -99.6666666664, 285.8333333335, 238.0000000003, -100.0000000002, 331.83333333300004, 189.4999999998, 346.3333333337, 71.5000000013, 225.6666666667, 297.6666666663, 317.50000000020003, -101.3333333333, -22.66666666730002, 112.1666666675, -19.000000000199975, 34.16666666710003, -183.6666666666, -67.6666666662, 21.3333333339, -100.16666666660001, 259.66666666630005, 19.000000000100002, 86.833333334, 271.66666666619994, 300.3333333321, 190.33333333309994, -190.5000000001, 96.49999999989997, 334.5000000006, 259.6666666672, 265.16666666770004, 345.666666667, 295.1666666663001, 347.00000000040006, -106.83333333319997, -142.33333333279998, -88.1666666654, -194.0, 250.6666666675, 292.16666666680004, -62.33333333350001, 247.1666666675, -147.1666666664, -1.8333333337000255, 224.00000000010002, 59.5000000004, -114.0000000003, -124.00000000009999, -70.3333333333, 208.8333333338, -58.83333333310001, -87.33333333329999, 345.1666666678, -51.499999999799996, -210.33333333320002, 270.16666666699996, 330.49999999999994, 70.50000000059995, 58.83333333320001, 44.00000000009999, -110.1666666669, -92.5000000001, 56.66666666699999, -92.9999999999, 351.166666668], "policy_cop_policy_reward": [-14.0, -24.5, 189.0, 337.0, 281.0, 295.5, 110.0, 38.0, 34.0, -598.5, -54.0, 153.0, 42.5, -90.0, 32.5, 304.0, 214.0, -275.0, 49.0, 125.0, 89.0, -77.0, 160.0, 202.5, 114.5, 160.0, 312.0, 185.5, -690.0, 11.0, 285.5, -282.0, 385.5, 287.5, -198.0, 316.0, 140.0, 357.0, 328.5, 0.0, 0.0, 0.0, 165.5, 74.0, 125.0, 10.5, 21.5, 105.5, 0.0, 0.0, 357.5, 280.0, -319.5, 98.5, 193.0, 169.0, 102.0, 91.0, 261.5, 163.0, 339.0, 280.0, -48.5, 221.0, 196.5, 20.5, 104.5, -91.0, 239.0, 203.0, 285.5, 253.5, 155.5, 234.5, 114.5, 378.0, 238.5, -51.5, 186.0, 245.5, 54.0, 218.5, -146.5, 129.0, 44.0, 441.0, 107.0, 25.0, 16.5, 0.0, 0.0, 0.0, 257.0, 60.5, 165.5, 203.5, -132.5, 91.5, -161.5, 219.0, 427.5, 101.0, 4.0, 8.0, 295.5, 204.5, 378.0, 104.5, 164.0, 330.5, 147.0, 34.5, 78.0, -20.0, 261.0, 335.5, 243.5, 244.5, 202.0, 122.5, 347.0, 351.5, 168.5, 400.0, 43.5, 242.0, 365.5, 350.0, 150.5, 370.0, 21.0, 266.5, 398.5, 258.0, 77.5, 312.0, 292.5, 251.0, 201.0, 185.5, 278.0, 256.5, 104.5, 219.5, 333.5, 256.5, 104.5, 26.0, 16.5, 55.0, 353.0, 282.5, 0.0, -240.5, 249.5, 2.0, 5.0, 100.0, 65.0, 222.0, 284.5, 153.5, 207.0, 352.5, 243.0, 342.5, 178.0, 205.0, 429.5, 142.0, 174.5, 306.0, 240.5, -299.5, -240.0, 374.5, 5.0, 100.0, 3.5, -183.0, 153.5, 296.5, 183.5, 347.5, -69.5, -365.0, -22.0, 335.5, 104.5, -158.0, 327.0, 65.0, -315.5, 278.5, 291.5, 394.0, 144.5, 149.0, 172.0, 436.5, -404.5, -54.0, 219.0, -183.5, 138.0, 286.0, 52.0, 53.0, -10.5, 483.0, -25.0, 266.5, 10.5, 277.5, 324.0, 16.5, 23.0, 103.0, 282.0, 363.5, 292.5, 13.0, 24.5, 19.0, 47.5, -243.5, 303.5, -204.0, 141.5, 173.5, 201.0, 266.0, 350.5, -107.5, 172.5, 198.0, 104.5, 6.0, 6.0, 121.0, 23.0, 35.0, 12.5, 163.5, 221.5, 59.0, 125.0, 83.0, 17.0, 127.0, 62.0, -266.0, 219.0, 419.5, 262.0, 77.0, 310.5, -366.5, -20.0, 328.5, 229.5, 327.5, 374.5, 397.5, 293.5, 298.0, 217.0, 172.5, 30.5, 411.0, 237.5, 192.5, 134.5, 236.0, 115.0, -98.5, 100.0, 3.5, 3.0, 100.0, 3.5, 206.5, 254.0, 96.5, 17.0, 105.0, 9.0, 404.5, 278.0, 272.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.640456881446892, "mean_inference_ms": 6.478791297781886, "mean_action_processing_ms": 0.14212002515498975, "mean_env_wait_ms": 0.1758598239101265, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.00355388912452659, "StateBufferConnector_ms": 0.007112498210771435, "ViewRequirementAgentConnector_ms": 0.31460457041783985}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 118.4425989245943, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 44000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 43997, "timers": {"training_iteration_time_ms": 35175.252, "sample_time_ms": 29152.973, "synch_weights_time_ms": 10.258}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 627, "training_iteration": 11, "trial_id": "96d6c_00000", "date": "2024-01-13_10-53-07", "timestamp": 1705139587, "time_this_iter_s": 33.785353660583496, "time_total_s": 394.26849913597107, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E5C60>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 394.26849913597107, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 6.861363636363635, "ram_util_percent": 57.229545454545466, "gpu_util_percent0": 0.26318181818181824, "vram_util_percent0": 0.09045410156250001}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2965.0, "total_loss": 19.224159495035806}, "mr_x_policy": {"total_loss": 19.224159495035806, "policy_loss": -0.0796656927462512, "vf_loss": 9.654069964090983, "vf_loss_unclipped": 26677.741569010417, "vf_explained_var": 0.0026658634344736737, "entropy": 1.0741535981496175, "mean_kl_loss": 0.01557842908132443, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.633981895446777, "policy_loss": -0.03187301669580241, "vf_loss": 9.661270809173583, "vf_loss_unclipped": 21942.76482747396, "vf_explained_var": -0.004462571938832601, "entropy": 1.1973878860473632, "mean_kl_loss": 0.0152796658493268, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 47999, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1385.8333333340001, "episode_reward_min": -461.8333333336, "episode_reward_mean": 468.0950000001431, "episode_len_mean": 68.89, "episode_media": {}, "episodes_this_iter": 59, "policy_reward_min": {"cop_policy": -444.5, "mr_x_policy": -616.3333333336001}, "policy_reward_max": {"cop_policy": 483.0, "mr_x_policy": 403.8333333337}, "policy_reward_mean": {"cop_policy": 139.22222222222223, "mr_x_policy": 67.135000000143}, "custom_metrics": {}, "hist_stats": {"episode_reward": [1021.3333333321, 25.333333333100065, -82.00000000009999, 363.49999999989996, 796.0000000005999, 208.16666666720008, 538.6666666676999, 373.66666666700013, 1125.1666666662998, 1104.5000000004002, -346.3333333331999, 98.16666666720002, 6.333333334599999, -194.0, 975.1666666675, 904.1666666668002, 80.16666666649999, 1185.1666666675003, -90.66666666639998, 105.66666666629993, 335.00000000010004, 877.0000000004, 148.99999999969998, -7.500000000099988, 108.66666666670001, 606.3333333337999, 208.16666666690003, 118.6666666667, 717.6666666678001, 598.0000000002001, -268.33333333319996, 1201.6666666669998, 1319.5, 490.5000000006001, 899.8333333331999, 529.5000000001, -105.1666666669, 13.999999999899998, 613.6666666670001, 38.000000000100016, 1305.666666668, 1028.0000000004, 485.33333333280007, 1096.8333333345001, 515.8333333333998, 1196.8333333336996, 961.8333333338999, 750.1666666662, 1121.666666667, 802.5000000005, 720.8333333340001, -400.6666666667, 258.33333333390004, 20.499999999300144, 1051.8333333319, 151.16666666639998, -111.3333333334, 41.333333333300004, 58.49999999999997, 943.8333333339002, 635.1666666668, -461.8333333336, 187.33333333349998, -99.3333333335, 1025.3333333342, 863.0000000005001, 770.5000000004001, 0.8333333333000041, 1385.8333333340001, -98.6666666667, 155.66666666659998, -199.0, 1071.3333333337998, 856.5000000007001, 584.1666666668001, 930.5000000000001, -5.500000000100016, 530.9999999995001, 1163.666666666, 1022.8333333324002, 899.5000000000998, 120.3333333338, -175.50000000019998, 35.999999999800025, 89.16666666590002, 671.5000000000999, 505.1666666667, 229.83333333339996, 1048.4999999997, 32.33333333339999, 680.0000000008001, 574.8333333335999, 41.333333333300004, 283.00000000040006, 869.5000000000999, -203.0, 1040.6666666672, 6.666666666799998, 482.5000000006998, 616.5000000000999], "episode_lengths": [95, 106, 10, 102, 98, 101, 100, 102, 93, 95, 105, 84, 43, 2, 98, 96, 12, 93, 26, 96, 100, 94, 61, 13, 18, 97, 29, 21, 100, 95, 102, 93, 93, 47, 96, 58, 10, 9, 79, 13, 94, 94, 81, 96, 97, 96, 96, 96, 95, 95, 97, 3, 76, 104, 94, 22, 6, 10, 37, 94, 99, 108, 31, 6, 95, 97, 61, 9, 94, 1, 40, 2, 94, 95, 62, 97, 29, 99, 93, 95, 96, 25, 23, 15, 99, 96, 96, 100, 94, 9, 97, 99, 22, 44, 97, 5, 93, 9, 99, 96], "policy_cop_policy_reward": [174.5, 306.0, 240.5, -299.5, -240.0, 374.5, 5.0, 100.0, 3.5, -183.0, 153.5, 296.5, 183.5, 347.5, -69.5, -365.0, -22.0, 335.5, 104.5, -158.0, 327.0, 65.0, -315.5, 278.5, 291.5, 394.0, 144.5, 149.0, 172.0, 436.5, -404.5, -54.0, 219.0, -183.5, 138.0, 286.0, 52.0, 53.0, -10.5, 483.0, -25.0, 266.5, 10.5, 277.5, 324.0, 16.5, 23.0, 103.0, 282.0, 363.5, 292.5, 13.0, 24.5, 19.0, 47.5, -243.5, 303.5, -204.0, 141.5, 173.5, 201.0, 266.0, 350.5, -107.5, 172.5, 198.0, 104.5, 6.0, 6.0, 121.0, 23.0, 35.0, 12.5, 163.5, 221.5, 59.0, 125.0, 83.0, 17.0, 127.0, 62.0, -266.0, 219.0, 419.5, 262.0, 77.0, 310.5, -366.5, -20.0, 328.5, 229.5, 327.5, 374.5, 397.5, 293.5, 298.0, 217.0, 172.5, 30.5, 411.0, 237.5, 192.5, 134.5, 236.0, 115.0, -98.5, 100.0, 3.5, 3.0, 100.0, 3.5, 206.5, 254.0, 96.5, 17.0, 105.0, 9.0, 404.5, 278.0, 272.0, 148.0, 282.5, 337.5, 55.0, 313.5, 200.5, 158.5, 245.0, 459.5, 269.5, -106.0, 181.0, 143.5, 281.5, 368.0, 363.5, 350.0, -34.5, -87.0, 240.0, 357.5, 143.0, 288.5, 345.5, 119.0, 207.0, 269.5, 162.5, 272.5, 97.5, 195.5, 108.5, 195.0, 254.0, -426.5, 9.0, 238.0, 269.0, 260.5, 126.0, 54.0, 56.5, 0.0, 0.0, 0.0, 101.0, 10.0, 8.0, -25.0, -6.0, 132.5, 208.5, 333.0, 290.5, 200.5, 208.0, -83.5, -346.5, 200.0, 301.0, 78.0, 125.0, 64.5, 0.0, 0.0, 0.0, 326.0, 121.0, 291.0, 318.0, -19.5, 274.5, 178.5, 305.0, 190.0, 4.0, 100.0, 1.0, 308.5, 279.5, 442.0, 153.5, 105.0, 143.5, 350.5, 290.0, 196.0, 111.0, 264.5, 273.0, 186.0, 218.5, 222.0, 301.0, 290.5, 277.5, 37.5, -53.0, 130.0, -225.5, 290.0, 377.5, 351.5, 302.0, 252.0, 203.5, 401.0, 110.5, 255.0, 188.0, 314.5, 4.5, 156.0, 43.0, -56.5, -73.0, 29.0, 8.5, 110.0, 22.5, 177.5, 265.0, -441.5, -49.0, 356.0, 204.0, -5.0, 275.5, 138.0, -444.5, 288.5, 223.0, 241.0, 199.0, 353.5, 100.0, 6.5, 3.0, 253.0, 195.5, 322.0, -35.0, 153.5, 143.5, 111.5, 48.0, 53.5, 89.5, 195.0, 33.5, -70.5, 293.0, 360.0, 0.0, 0.0, 0.0, 335.0, 219.0, 196.5, 4.0, 100.0, 2.5, 385.5, 319.0, 148.5, 243.0, 316.5, -111.0], "policy_mr_x_policy_reward": [300.3333333321, 190.33333333309994, -190.5000000001, 96.49999999989997, 334.5000000006, 259.6666666672, 265.16666666770004, 345.666666667, 295.1666666663001, 347.00000000040006, -106.83333333319997, -142.33333333279998, -88.1666666654, -194.0, 250.6666666675, 292.16666666680004, -62.33333333350001, 247.1666666675, -147.1666666664, -1.8333333337000255, 224.00000000010002, 59.5000000004, -114.0000000003, -124.00000000009999, -70.3333333333, 208.8333333338, -58.83333333310001, -87.33333333329999, 345.1666666678, -51.499999999799996, -210.33333333320002, 270.16666666699996, 330.49999999999994, 70.50000000059995, 58.83333333320001, 44.00000000009999, -110.1666666669, -92.5000000001, 56.66666666699999, -92.9999999999, 351.166666668, 260.0000000004, -83.66666666720002, 233.8333333345, 171.33333333339996, 403.8333333337, 282.8333333339, 239.66666666620003, 344.666666667, 207.00000000050002, 188.33333333399995, -400.6666666667, -240.66666666609996, 183.99999999929997, 284.3333333319, -85.3333333336, -111.3333333334, -77.6666666667, -43.00000000000001, 111.83333333389999, 310.1666666668, -616.3333333336001, -80.1666666665, -99.3333333335, 287.3333333342, 290.0000000005, 97.00000000039998, -104.1666666667, 355.83333333400003, -98.6666666667, -246.3333333334, -199.0, 234.83333333380003, 208.00000000070008, -42.3333333332, 61.50000000000001, -120.0000000001, 88.9999999995, 258.166666666, 307.83333333240006, 142.00000000010002, -83.1666666662, -75.0000000002, -105.00000000019999, 88.16666666590001, 160.50000000009996, 96.6666666667, 162.8333333334, 254.99999999969998, -77.1666666666, -90.49999999920006, 312.8333333336, -171.6666666667, -34.99999999959999, 287.00000000010004, -203.0, 290.16666666720005, -99.8333333332, -370.4999999993, 168.00000000010002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6498551415597119, "mean_inference_ms": 6.536997632186589, "mean_action_processing_ms": 0.14363971857955746, "mean_env_wait_ms": 0.17856275999692578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006404458260049625, "StateBufferConnector_ms": 0.009526160298561563, "ViewRequirementAgentConnector_ms": 0.4284659210516482}}, "episode_reward_max": 1385.8333333340001, "episode_reward_min": -461.8333333336, "episode_reward_mean": 468.0950000001431, "episode_len_mean": 68.89, "episodes_this_iter": 59, "policy_reward_min": {"cop_policy": -444.5, "mr_x_policy": -616.3333333336001}, "policy_reward_max": {"cop_policy": 483.0, "mr_x_policy": 403.8333333337}, "policy_reward_mean": {"cop_policy": 139.22222222222223, "mr_x_policy": 67.135000000143}, "hist_stats": {"episode_reward": [1021.3333333321, 25.333333333100065, -82.00000000009999, 363.49999999989996, 796.0000000005999, 208.16666666720008, 538.6666666676999, 373.66666666700013, 1125.1666666662998, 1104.5000000004002, -346.3333333331999, 98.16666666720002, 6.333333334599999, -194.0, 975.1666666675, 904.1666666668002, 80.16666666649999, 1185.1666666675003, -90.66666666639998, 105.66666666629993, 335.00000000010004, 877.0000000004, 148.99999999969998, -7.500000000099988, 108.66666666670001, 606.3333333337999, 208.16666666690003, 118.6666666667, 717.6666666678001, 598.0000000002001, -268.33333333319996, 1201.6666666669998, 1319.5, 490.5000000006001, 899.8333333331999, 529.5000000001, -105.1666666669, 13.999999999899998, 613.6666666670001, 38.000000000100016, 1305.666666668, 1028.0000000004, 485.33333333280007, 1096.8333333345001, 515.8333333333998, 1196.8333333336996, 961.8333333338999, 750.1666666662, 1121.666666667, 802.5000000005, 720.8333333340001, -400.6666666667, 258.33333333390004, 20.499999999300144, 1051.8333333319, 151.16666666639998, -111.3333333334, 41.333333333300004, 58.49999999999997, 943.8333333339002, 635.1666666668, -461.8333333336, 187.33333333349998, -99.3333333335, 1025.3333333342, 863.0000000005001, 770.5000000004001, 0.8333333333000041, 1385.8333333340001, -98.6666666667, 155.66666666659998, -199.0, 1071.3333333337998, 856.5000000007001, 584.1666666668001, 930.5000000000001, -5.500000000100016, 530.9999999995001, 1163.666666666, 1022.8333333324002, 899.5000000000998, 120.3333333338, -175.50000000019998, 35.999999999800025, 89.16666666590002, 671.5000000000999, 505.1666666667, 229.83333333339996, 1048.4999999997, 32.33333333339999, 680.0000000008001, 574.8333333335999, 41.333333333300004, 283.00000000040006, 869.5000000000999, -203.0, 1040.6666666672, 6.666666666799998, 482.5000000006998, 616.5000000000999], "episode_lengths": [95, 106, 10, 102, 98, 101, 100, 102, 93, 95, 105, 84, 43, 2, 98, 96, 12, 93, 26, 96, 100, 94, 61, 13, 18, 97, 29, 21, 100, 95, 102, 93, 93, 47, 96, 58, 10, 9, 79, 13, 94, 94, 81, 96, 97, 96, 96, 96, 95, 95, 97, 3, 76, 104, 94, 22, 6, 10, 37, 94, 99, 108, 31, 6, 95, 97, 61, 9, 94, 1, 40, 2, 94, 95, 62, 97, 29, 99, 93, 95, 96, 25, 23, 15, 99, 96, 96, 100, 94, 9, 97, 99, 22, 44, 97, 5, 93, 9, 99, 96], "policy_cop_policy_reward": [174.5, 306.0, 240.5, -299.5, -240.0, 374.5, 5.0, 100.0, 3.5, -183.0, 153.5, 296.5, 183.5, 347.5, -69.5, -365.0, -22.0, 335.5, 104.5, -158.0, 327.0, 65.0, -315.5, 278.5, 291.5, 394.0, 144.5, 149.0, 172.0, 436.5, -404.5, -54.0, 219.0, -183.5, 138.0, 286.0, 52.0, 53.0, -10.5, 483.0, -25.0, 266.5, 10.5, 277.5, 324.0, 16.5, 23.0, 103.0, 282.0, 363.5, 292.5, 13.0, 24.5, 19.0, 47.5, -243.5, 303.5, -204.0, 141.5, 173.5, 201.0, 266.0, 350.5, -107.5, 172.5, 198.0, 104.5, 6.0, 6.0, 121.0, 23.0, 35.0, 12.5, 163.5, 221.5, 59.0, 125.0, 83.0, 17.0, 127.0, 62.0, -266.0, 219.0, 419.5, 262.0, 77.0, 310.5, -366.5, -20.0, 328.5, 229.5, 327.5, 374.5, 397.5, 293.5, 298.0, 217.0, 172.5, 30.5, 411.0, 237.5, 192.5, 134.5, 236.0, 115.0, -98.5, 100.0, 3.5, 3.0, 100.0, 3.5, 206.5, 254.0, 96.5, 17.0, 105.0, 9.0, 404.5, 278.0, 272.0, 148.0, 282.5, 337.5, 55.0, 313.5, 200.5, 158.5, 245.0, 459.5, 269.5, -106.0, 181.0, 143.5, 281.5, 368.0, 363.5, 350.0, -34.5, -87.0, 240.0, 357.5, 143.0, 288.5, 345.5, 119.0, 207.0, 269.5, 162.5, 272.5, 97.5, 195.5, 108.5, 195.0, 254.0, -426.5, 9.0, 238.0, 269.0, 260.5, 126.0, 54.0, 56.5, 0.0, 0.0, 0.0, 101.0, 10.0, 8.0, -25.0, -6.0, 132.5, 208.5, 333.0, 290.5, 200.5, 208.0, -83.5, -346.5, 200.0, 301.0, 78.0, 125.0, 64.5, 0.0, 0.0, 0.0, 326.0, 121.0, 291.0, 318.0, -19.5, 274.5, 178.5, 305.0, 190.0, 4.0, 100.0, 1.0, 308.5, 279.5, 442.0, 153.5, 105.0, 143.5, 350.5, 290.0, 196.0, 111.0, 264.5, 273.0, 186.0, 218.5, 222.0, 301.0, 290.5, 277.5, 37.5, -53.0, 130.0, -225.5, 290.0, 377.5, 351.5, 302.0, 252.0, 203.5, 401.0, 110.5, 255.0, 188.0, 314.5, 4.5, 156.0, 43.0, -56.5, -73.0, 29.0, 8.5, 110.0, 22.5, 177.5, 265.0, -441.5, -49.0, 356.0, 204.0, -5.0, 275.5, 138.0, -444.5, 288.5, 223.0, 241.0, 199.0, 353.5, 100.0, 6.5, 3.0, 253.0, 195.5, 322.0, -35.0, 153.5, 143.5, 111.5, 48.0, 53.5, 89.5, 195.0, 33.5, -70.5, 293.0, 360.0, 0.0, 0.0, 0.0, 335.0, 219.0, 196.5, 4.0, 100.0, 2.5, 385.5, 319.0, 148.5, 243.0, 316.5, -111.0], "policy_mr_x_policy_reward": [300.3333333321, 190.33333333309994, -190.5000000001, 96.49999999989997, 334.5000000006, 259.6666666672, 265.16666666770004, 345.666666667, 295.1666666663001, 347.00000000040006, -106.83333333319997, -142.33333333279998, -88.1666666654, -194.0, 250.6666666675, 292.16666666680004, -62.33333333350001, 247.1666666675, -147.1666666664, -1.8333333337000255, 224.00000000010002, 59.5000000004, -114.0000000003, -124.00000000009999, -70.3333333333, 208.8333333338, -58.83333333310001, -87.33333333329999, 345.1666666678, -51.499999999799996, -210.33333333320002, 270.16666666699996, 330.49999999999994, 70.50000000059995, 58.83333333320001, 44.00000000009999, -110.1666666669, -92.5000000001, 56.66666666699999, -92.9999999999, 351.166666668, 260.0000000004, -83.66666666720002, 233.8333333345, 171.33333333339996, 403.8333333337, 282.8333333339, 239.66666666620003, 344.666666667, 207.00000000050002, 188.33333333399995, -400.6666666667, -240.66666666609996, 183.99999999929997, 284.3333333319, -85.3333333336, -111.3333333334, -77.6666666667, -43.00000000000001, 111.83333333389999, 310.1666666668, -616.3333333336001, -80.1666666665, -99.3333333335, 287.3333333342, 290.0000000005, 97.00000000039998, -104.1666666667, 355.83333333400003, -98.6666666667, -246.3333333334, -199.0, 234.83333333380003, 208.00000000070008, -42.3333333332, 61.50000000000001, -120.0000000001, 88.9999999995, 258.166666666, 307.83333333240006, 142.00000000010002, -83.1666666662, -75.0000000002, -105.00000000019999, 88.16666666590001, 160.50000000009996, 96.6666666667, 162.8333333334, 254.99999999969998, -77.1666666666, -90.49999999920006, 312.8333333336, -171.6666666667, -34.99999999959999, 287.00000000010004, -203.0, 290.16666666720005, -99.8333333332, -370.4999999993, 168.00000000010002]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6498551415597119, "mean_inference_ms": 6.536997632186589, "mean_action_processing_ms": 0.14363971857955746, "mean_env_wait_ms": 0.17856275999692578, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006404458260049625, "StateBufferConnector_ms": 0.009526160298561563, "ViewRequirementAgentConnector_ms": 0.4284659210516482}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 47999, "num_agent_steps_trained": 0, "num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 82.33299080462702, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 48000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 47999, "timers": {"training_iteration_time_ms": 36385.377, "sample_time_ms": 29865.478, "synch_weights_time_ms": 10.67}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 47999, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 686, "training_iteration": 12, "trial_id": "96d6c_00000", "date": "2024-01-13_10-53-56", "timestamp": 1705139636, "time_this_iter_s": 48.609466314315796, "time_total_s": 442.87796545028687, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E56C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 442.87796545028687, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 24.549999999999994, "ram_util_percent": 66.39354838709677, "gpu_util_percent0": 0.25225806451612903, "vram_util_percent0": 0.09858818464381719}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2961.0, "total_loss": 19.16106678644816}, "mr_x_policy": {"total_loss": 19.16106678644816, "policy_loss": -0.07926014433226859, "vf_loss": 9.568098878860473, "vf_loss_unclipped": 24124.958268229166, "vf_explained_var": 0.007643268505732218, "entropy": 1.0211375226577124, "mean_kl_loss": 0.01628504441344679, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.655739561716716, "policy_loss": -0.030630709743127225, "vf_loss": 9.680723635355632, "vf_loss_unclipped": 23022.60947265625, "vf_explained_var": -0.006272507707277933, "entropy": 1.1955278674761454, "mean_kl_loss": 0.018821833912443253, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1385.8333333340001, "episode_reward_min": -613.1666666659999, "episode_reward_mean": 467.67666666674194, "episode_len_mean": 65.86, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"mr_x_policy": -616.3333333336001, "cop_policy": -521.5}, "policy_reward_max": {"mr_x_policy": 456.33333333419995, "cop_policy": 474.5}, "policy_reward_mean": {"mr_x_policy": 49.931666666742004, "cop_policy": 147.09330985915494}, "custom_metrics": {}, "hist_stats": {"episode_reward": [635.1666666668, -461.8333333336, 187.33333333349998, -99.3333333335, 1025.3333333342, 863.0000000005001, 770.5000000004001, 0.8333333333000041, 1385.8333333340001, -98.6666666667, 155.66666666659998, -199.0, 1071.3333333337998, 856.5000000007001, 584.1666666668001, 930.5000000000001, -5.500000000100016, 530.9999999995001, 1163.666666666, 1022.8333333324002, 899.5000000000998, 120.3333333338, -175.50000000019998, 35.999999999800025, 89.16666666590002, 671.5000000000999, 505.1666666667, 229.83333333339996, 1048.4999999997, 32.33333333339999, 680.0000000008001, 574.8333333335999, 41.333333333300004, 283.00000000040006, 869.5000000000999, -203.0, 1040.6666666672, 6.666666666799998, 482.5000000006998, 616.5000000000999, 912.1666666669, 938.6666666674998, 28.500000000100002, 958.0000000004, 334.66666666599997, 1027.4999999997, 595.8333333334998, 99.66666666650002, 1043.4999999999, -101.1666666667, -97.16666666639999, 1094.1666666674998, 552.3333333337, 785.8333333341998, 54.33333333300001, 1272.833333333, 1116.3333333339003, 731.8333333342999, 517.9999999990999, 1134.4999999994002, 813.3333333336, 958.3333333337, 52.666666666699996, 350.9999999998, -97.9999999999, -182.0000000001, 483.83333333340005, 1269.1666666666001, -44.33333333319998, 541.6666666676998, -12.499999999799996, 869.8333333340003, 669.0000000006997, -105.3333333332, -86.00000000009999, 868.8333333324, -613.1666666659999, 58.0000000001, 732.0000000000001, 164.99999999899993, 393.83333333260003, 566.5000000014, 871.3333333332998, 58.66666666639999, -105.9999999999, -200.3333333333, 1338.6666666668, 289.16666666580005, 164.3333333328, -100.0, 548.1666666673, 771.8333333341998, 41.99999999959999, 928.3333333322998, 883.8333333328999, 1080.4999999999002, 917.1666666669001, -9.666666666400005, 25.166666666799998, 444.3333333335999], "episode_lengths": [99, 108, 31, 6, 95, 97, 61, 9, 94, 1, 40, 2, 94, 95, 62, 97, 29, 99, 93, 95, 96, 25, 23, 15, 99, 96, 96, 100, 94, 9, 97, 99, 22, 44, 97, 5, 93, 9, 99, 96, 94, 96, 13, 93, 47, 96, 97, 15, 95, 22, 15, 95, 100, 98, 17, 94, 100, 97, 98, 95, 97, 79, 22, 41, 2, 7, 70, 95, 104, 99, 28, 96, 99, 3, 5, 96, 97, 13, 98, 107, 98, 95, 99, 15, 3, 1, 93, 98, 19, 1, 83, 102, 16, 97, 93, 96, 93, 14, 12, 102], "policy_mr_x_policy_reward": [310.1666666668, -616.3333333336001, -80.1666666665, -99.3333333335, 287.3333333342, 290.0000000005, 97.00000000039998, -104.1666666667, 355.83333333400003, -98.6666666667, -246.3333333334, -199.0, 234.83333333380003, 208.00000000070008, -42.3333333332, 61.50000000000001, -120.0000000001, 88.9999999995, 258.166666666, 307.83333333240006, 142.00000000010002, -83.1666666662, -75.0000000002, -105.00000000019999, 88.16666666590001, 160.50000000009996, 96.6666666667, 162.8333333334, 254.99999999969998, -77.1666666666, -90.49999999920006, 312.8333333336, -171.6666666667, -34.99999999959999, 287.00000000010004, -203.0, 290.16666666720005, -99.8333333332, -370.4999999993, 168.00000000010002, 232.1666666669, 281.6666666675, -99.9999999999, 157.50000000039998, 16.166666665999998, 254.99999999970004, 212.83333333349998, -66.3333333335, 259.99999999989996, -85.6666666667, -127.66666666639999, 288.16666666749995, -412.16666666629993, 236.33333333419995, -100.166666667, 316.333333333, 187.83333333390001, 240.3333333343, 253.4999999991, 241.99999999940002, 305.8333333336, 201.8333333337, -51.333333333300004, -29.00000000019999, -97.9999999999, -182.0000000001, -8.166666666599994, 380.1666666666, -519.8333333331998, 272.1666666677, -268.9999999998, 242.83333333399997, 284.0000000007001, -105.3333333332, -86.00000000009999, 259.3333333324, -36.666666666000005, -86.9999999999, -97.00000000000001, -197.000000001, 125.3333333326, 35.50000000139997, 215.3333333333, -93.33333333360001, -105.9999999999, -200.3333333333, 344.1666666667999, -319.3333333342, -59.16666666719998, -100.0, 1.6666666672999924, 456.33333333419995, -113.0000000004, 79.8333333323, 137.8333333329, 402.49999999989996, 165.16666666690003, -166.6666666664, -106.3333333332, 280.3333333336], "policy_cop_policy_reward": [200.5, 208.0, -83.5, -346.5, 200.0, 301.0, 78.0, 125.0, 64.5, 0.0, 0.0, 0.0, 326.0, 121.0, 291.0, 318.0, -19.5, 274.5, 178.5, 305.0, 190.0, 4.0, 100.0, 1.0, 308.5, 279.5, 442.0, 153.5, 105.0, 143.5, 350.5, 290.0, 196.0, 111.0, 264.5, 273.0, 186.0, 218.5, 222.0, 301.0, 290.5, 277.5, 37.5, -53.0, 130.0, -225.5, 290.0, 377.5, 351.5, 302.0, 252.0, 203.5, 401.0, 110.5, 255.0, 188.0, 314.5, 4.5, 156.0, 43.0, -56.5, -73.0, 29.0, 8.5, 110.0, 22.5, 177.5, 265.0, -441.5, -49.0, 356.0, 204.0, -5.0, 275.5, 138.0, -444.5, 288.5, 223.0, 241.0, 199.0, 353.5, 100.0, 6.5, 3.0, 253.0, 195.5, 322.0, -35.0, 153.5, 143.5, 111.5, 48.0, 53.5, 89.5, 195.0, 33.5, -70.5, 293.0, 360.0, 0.0, 0.0, 0.0, 335.0, 219.0, 196.5, 4.0, 100.0, 2.5, 385.5, 319.0, 148.5, 243.0, 316.5, -111.0, 166.5, 153.5, 360.0, 18.5, 314.0, 324.5, 7.0, 105.0, 16.5, 355.5, 231.5, 213.5, -28.5, 179.5, 167.5, 300.5, 120.0, 352.0, -102.5, 304.5, 181.0, 23.0, 110.0, 33.0, 275.0, 280.0, 228.5, 20.5, 37.0, -73.0, 7.0, 15.0, 8.5, 160.5, 384.5, 261.0, 330.5, 378.5, 255.5, 103.0, 95.0, 351.5, 115.0, 26.5, 13.0, 291.0, 291.5, 374.0, 240.0, 451.5, 237.0, 255.0, 200.0, 36.5, -52.0, 254.0, 62.5, 356.0, 191.0, 345.5, 249.5, 8.5, 249.5, 245.5, 166.0, 345.0, -71.5, 52.0, 123.5, 143.0, 142.0, 95.0, 0.0, 0.0, 0.0, 0.0, 132.0, 114.5, 245.5, 321.0, 246.0, 322.0, 363.0, -221.5, 334.0, -386.0, 410.5, 245.0, 106.0, 76.0, 74.5, 398.5, 0.5, 228.0, 293.5, -78.0, 169.5, 0.0, 0.0, 0.0, 0.0, 0.0, 45.5, 372.0, 192.0, -34.0, -113.5, -429.0, 18.0, 21.5, 105.5, 216.5, 366.0, 246.5, 387.5, -81.0, 55.5, -1.0, 112.0, 157.5, 226.5, 291.0, 13.5, 344.0, 25.0, 287.0, 25.0, 104.0, 23.0, 0.0, 0.0, 409.0, 320.5, 265.0, -143.5, 401.0, 351.0, 34.0, 112.0, 77.5, 298.0, -2.0, 250.5, 327.5, 46.5, -58.5, 29.0, 14.0, 112.0, 340.5, 474.5, 33.5, 339.0, 181.5, 225.5, 356.5, 298.0, 23.5, 308.5, 249.0, 194.5, 100.5, 34.0, 22.5, 15.5, 13.0, 103.0, 291.0, -521.5, 394.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6576002510650304, "mean_inference_ms": 6.595307745712285, "mean_action_processing_ms": 0.14618196633387992, "mean_env_wait_ms": 0.18170709815264174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006942846337143256, "StateBufferConnector_ms": 0.012568308382618184, "ViewRequirementAgentConnector_ms": 0.49439607834329413}}, "episode_reward_max": 1385.8333333340001, "episode_reward_min": -613.1666666659999, "episode_reward_mean": 467.67666666674194, "episode_len_mean": 65.86, "episodes_this_iter": 60, "policy_reward_min": {"mr_x_policy": -616.3333333336001, "cop_policy": -521.5}, "policy_reward_max": {"mr_x_policy": 456.33333333419995, "cop_policy": 474.5}, "policy_reward_mean": {"mr_x_policy": 49.931666666742004, "cop_policy": 147.09330985915494}, "hist_stats": {"episode_reward": [635.1666666668, -461.8333333336, 187.33333333349998, -99.3333333335, 1025.3333333342, 863.0000000005001, 770.5000000004001, 0.8333333333000041, 1385.8333333340001, -98.6666666667, 155.66666666659998, -199.0, 1071.3333333337998, 856.5000000007001, 584.1666666668001, 930.5000000000001, -5.500000000100016, 530.9999999995001, 1163.666666666, 1022.8333333324002, 899.5000000000998, 120.3333333338, -175.50000000019998, 35.999999999800025, 89.16666666590002, 671.5000000000999, 505.1666666667, 229.83333333339996, 1048.4999999997, 32.33333333339999, 680.0000000008001, 574.8333333335999, 41.333333333300004, 283.00000000040006, 869.5000000000999, -203.0, 1040.6666666672, 6.666666666799998, 482.5000000006998, 616.5000000000999, 912.1666666669, 938.6666666674998, 28.500000000100002, 958.0000000004, 334.66666666599997, 1027.4999999997, 595.8333333334998, 99.66666666650002, 1043.4999999999, -101.1666666667, -97.16666666639999, 1094.1666666674998, 552.3333333337, 785.8333333341998, 54.33333333300001, 1272.833333333, 1116.3333333339003, 731.8333333342999, 517.9999999990999, 1134.4999999994002, 813.3333333336, 958.3333333337, 52.666666666699996, 350.9999999998, -97.9999999999, -182.0000000001, 483.83333333340005, 1269.1666666666001, -44.33333333319998, 541.6666666676998, -12.499999999799996, 869.8333333340003, 669.0000000006997, -105.3333333332, -86.00000000009999, 868.8333333324, -613.1666666659999, 58.0000000001, 732.0000000000001, 164.99999999899993, 393.83333333260003, 566.5000000014, 871.3333333332998, 58.66666666639999, -105.9999999999, -200.3333333333, 1338.6666666668, 289.16666666580005, 164.3333333328, -100.0, 548.1666666673, 771.8333333341998, 41.99999999959999, 928.3333333322998, 883.8333333328999, 1080.4999999999002, 917.1666666669001, -9.666666666400005, 25.166666666799998, 444.3333333335999], "episode_lengths": [99, 108, 31, 6, 95, 97, 61, 9, 94, 1, 40, 2, 94, 95, 62, 97, 29, 99, 93, 95, 96, 25, 23, 15, 99, 96, 96, 100, 94, 9, 97, 99, 22, 44, 97, 5, 93, 9, 99, 96, 94, 96, 13, 93, 47, 96, 97, 15, 95, 22, 15, 95, 100, 98, 17, 94, 100, 97, 98, 95, 97, 79, 22, 41, 2, 7, 70, 95, 104, 99, 28, 96, 99, 3, 5, 96, 97, 13, 98, 107, 98, 95, 99, 15, 3, 1, 93, 98, 19, 1, 83, 102, 16, 97, 93, 96, 93, 14, 12, 102], "policy_mr_x_policy_reward": [310.1666666668, -616.3333333336001, -80.1666666665, -99.3333333335, 287.3333333342, 290.0000000005, 97.00000000039998, -104.1666666667, 355.83333333400003, -98.6666666667, -246.3333333334, -199.0, 234.83333333380003, 208.00000000070008, -42.3333333332, 61.50000000000001, -120.0000000001, 88.9999999995, 258.166666666, 307.83333333240006, 142.00000000010002, -83.1666666662, -75.0000000002, -105.00000000019999, 88.16666666590001, 160.50000000009996, 96.6666666667, 162.8333333334, 254.99999999969998, -77.1666666666, -90.49999999920006, 312.8333333336, -171.6666666667, -34.99999999959999, 287.00000000010004, -203.0, 290.16666666720005, -99.8333333332, -370.4999999993, 168.00000000010002, 232.1666666669, 281.6666666675, -99.9999999999, 157.50000000039998, 16.166666665999998, 254.99999999970004, 212.83333333349998, -66.3333333335, 259.99999999989996, -85.6666666667, -127.66666666639999, 288.16666666749995, -412.16666666629993, 236.33333333419995, -100.166666667, 316.333333333, 187.83333333390001, 240.3333333343, 253.4999999991, 241.99999999940002, 305.8333333336, 201.8333333337, -51.333333333300004, -29.00000000019999, -97.9999999999, -182.0000000001, -8.166666666599994, 380.1666666666, -519.8333333331998, 272.1666666677, -268.9999999998, 242.83333333399997, 284.0000000007001, -105.3333333332, -86.00000000009999, 259.3333333324, -36.666666666000005, -86.9999999999, -97.00000000000001, -197.000000001, 125.3333333326, 35.50000000139997, 215.3333333333, -93.33333333360001, -105.9999999999, -200.3333333333, 344.1666666667999, -319.3333333342, -59.16666666719998, -100.0, 1.6666666672999924, 456.33333333419995, -113.0000000004, 79.8333333323, 137.8333333329, 402.49999999989996, 165.16666666690003, -166.6666666664, -106.3333333332, 280.3333333336], "policy_cop_policy_reward": [200.5, 208.0, -83.5, -346.5, 200.0, 301.0, 78.0, 125.0, 64.5, 0.0, 0.0, 0.0, 326.0, 121.0, 291.0, 318.0, -19.5, 274.5, 178.5, 305.0, 190.0, 4.0, 100.0, 1.0, 308.5, 279.5, 442.0, 153.5, 105.0, 143.5, 350.5, 290.0, 196.0, 111.0, 264.5, 273.0, 186.0, 218.5, 222.0, 301.0, 290.5, 277.5, 37.5, -53.0, 130.0, -225.5, 290.0, 377.5, 351.5, 302.0, 252.0, 203.5, 401.0, 110.5, 255.0, 188.0, 314.5, 4.5, 156.0, 43.0, -56.5, -73.0, 29.0, 8.5, 110.0, 22.5, 177.5, 265.0, -441.5, -49.0, 356.0, 204.0, -5.0, 275.5, 138.0, -444.5, 288.5, 223.0, 241.0, 199.0, 353.5, 100.0, 6.5, 3.0, 253.0, 195.5, 322.0, -35.0, 153.5, 143.5, 111.5, 48.0, 53.5, 89.5, 195.0, 33.5, -70.5, 293.0, 360.0, 0.0, 0.0, 0.0, 335.0, 219.0, 196.5, 4.0, 100.0, 2.5, 385.5, 319.0, 148.5, 243.0, 316.5, -111.0, 166.5, 153.5, 360.0, 18.5, 314.0, 324.5, 7.0, 105.0, 16.5, 355.5, 231.5, 213.5, -28.5, 179.5, 167.5, 300.5, 120.0, 352.0, -102.5, 304.5, 181.0, 23.0, 110.0, 33.0, 275.0, 280.0, 228.5, 20.5, 37.0, -73.0, 7.0, 15.0, 8.5, 160.5, 384.5, 261.0, 330.5, 378.5, 255.5, 103.0, 95.0, 351.5, 115.0, 26.5, 13.0, 291.0, 291.5, 374.0, 240.0, 451.5, 237.0, 255.0, 200.0, 36.5, -52.0, 254.0, 62.5, 356.0, 191.0, 345.5, 249.5, 8.5, 249.5, 245.5, 166.0, 345.0, -71.5, 52.0, 123.5, 143.0, 142.0, 95.0, 0.0, 0.0, 0.0, 0.0, 132.0, 114.5, 245.5, 321.0, 246.0, 322.0, 363.0, -221.5, 334.0, -386.0, 410.5, 245.0, 106.0, 76.0, 74.5, 398.5, 0.5, 228.0, 293.5, -78.0, 169.5, 0.0, 0.0, 0.0, 0.0, 0.0, 45.5, 372.0, 192.0, -34.0, -113.5, -429.0, 18.0, 21.5, 105.5, 216.5, 366.0, 246.5, 387.5, -81.0, 55.5, -1.0, 112.0, 157.5, 226.5, 291.0, 13.5, 344.0, 25.0, 287.0, 25.0, 104.0, 23.0, 0.0, 0.0, 409.0, 320.5, 265.0, -143.5, 401.0, 351.0, 34.0, 112.0, 77.5, 298.0, -2.0, 250.5, 327.5, 46.5, -58.5, 29.0, 14.0, 112.0, 340.5, 474.5, 33.5, 339.0, 181.5, 225.5, 356.5, 298.0, 23.5, 308.5, 249.0, 194.5, 100.5, 34.0, 22.5, 15.5, 13.0, 103.0, 291.0, -521.5, 394.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6576002510650304, "mean_inference_ms": 6.595307745712285, "mean_action_processing_ms": 0.14618196633387992, "mean_env_wait_ms": 0.18170709815264174, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.006942846337143256, "StateBufferConnector_ms": 0.012568308382618184, "ViewRequirementAgentConnector_ms": 0.49439607834329413}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 105.46598581245846, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 52000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 51997, "timers": {"training_iteration_time_ms": 36543.848, "sample_time_ms": 29942.31, "synch_weights_time_ms": 11.017}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 746, "training_iteration": 13, "trial_id": "96d6c_00000", "date": "2024-01-13_10-54-34", "timestamp": 1705139674, "time_this_iter_s": 37.94197630882263, "time_total_s": 480.8199417591095, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F68C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 480.8199417591095, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 11.312000000000001, "ram_util_percent": 77.68599999999999, "gpu_util_percent0": 0.2184, "vram_util_percent0": 0.11707682291666664}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2961.0, "total_loss": 19.210820198059082}, "mr_x_policy": {"total_loss": 19.210820198059082, "policy_loss": -0.07255649698684769, "vf_loss": 9.588705889383952, "vf_loss_unclipped": 72127.33111979166, "vf_explained_var": 0.006596967577934265, "entropy": 1.0552894433339437, "mean_kl_loss": 0.014476830926711651, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.680013100306192, "policy_loss": -0.03205676052408914, "vf_loss": 9.705982096989949, "vf_loss_unclipped": 33144.028125, "vf_explained_var": -0.0027845064798990887, "entropy": 1.215573145945867, "mean_kl_loss": 0.020292333560428234, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.45000001788139343}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1338.6666666668, "episode_reward_min": -1198.8333333331002, "episode_reward_mean": 423.748333333367, "episode_len_mean": 71.49, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"mr_x_policy": -1449.3333333321, "cop_policy": -2007.5}, "policy_reward_max": {"mr_x_policy": 456.33333333419995, "cop_policy": 474.5}, "policy_reward_mean": {"mr_x_policy": 32.433333333367, "cop_policy": 136.8234265734266}, "custom_metrics": {}, "hist_stats": {"episode_reward": [552.3333333337, 785.8333333341998, 54.33333333300001, 1272.833333333, 1116.3333333339003, 731.8333333342999, 517.9999999990999, 1134.4999999994002, 813.3333333336, 958.3333333337, 52.666666666699996, 350.9999999998, -97.9999999999, -182.0000000001, 483.83333333340005, 1269.1666666666001, -44.33333333319998, 541.6666666676998, -12.499999999799996, 869.8333333340003, 669.0000000006997, -105.3333333332, -86.00000000009999, 868.8333333324, -613.1666666659999, 58.0000000001, 732.0000000000001, 164.99999999899993, 393.83333333260003, 566.5000000014, 871.3333333332998, 58.66666666639999, -105.9999999999, -200.3333333333, 1338.6666666668, 289.16666666580005, 164.3333333328, -100.0, 548.1666666673, 771.8333333341998, 41.99999999959999, 928.3333333322998, 883.8333333328999, 1080.4999999999002, 917.1666666669001, -9.666666666400005, 25.166666666799998, 444.3333333335999, -148.16666666800003, -305.66666666640003, 842.4999999989999, 30.999999999900012, 298.0000000008, 448.8333333341001, 704.6666666666001, 696.6666666671, 779.3333333333001, 636.0000000004001, 223.5000000005001, -49.00000000059999, 53.50000000060001, -294.6666666669, 810.1666666671, 177.00000000059998, 973.5000000008, 1046.8333333323, 810.3333333338002, 743.8333333333001, 935.1666666664001, -212.66666666679998, 715.8333333341001, 517.1666666663001, 436.66666666719993, -705.8333333321, 539.6666666668001, 89.99999999900007, 406.9999999991, 282.666666667, 817.3333333324002, 814.8333333341, 1020.1666666671999, 699.4999999994, 2.333333333300004, 515.4999999996002, -100.3333333333, -10.166666666699996, 586.8333333331001, 408.33333333229996, -198.3333333333, 635.8333333343, 979.1666666673002, 427.3333333337, -655.1666666677, 730.4999999996999, 1062.5000000011, 456.3333333322, 57.499999999500005, 839.9999999997999, -1198.8333333331002, 1234.6666666674998], "episode_lengths": [100, 98, 17, 94, 100, 97, 98, 95, 97, 79, 22, 41, 2, 7, 70, 95, 104, 99, 28, 96, 99, 3, 5, 96, 97, 13, 98, 107, 98, 95, 99, 15, 3, 1, 93, 98, 19, 1, 83, 102, 16, 97, 93, 96, 93, 14, 12, 102, 106, 5, 96, 13, 96, 59, 97, 58, 95, 70, 104, 85, 101, 7, 97, 81, 96, 96, 96, 97, 95, 7, 100, 101, 55, 112, 98, 89, 38, 33, 93, 95, 94, 96, 10, 100, 4, 13, 98, 99, 2, 92, 97, 42, 111, 96, 94, 103, 39, 89, 119, 93], "policy_mr_x_policy_reward": [-412.16666666629993, 236.33333333419995, -100.166666667, 316.333333333, 187.83333333390001, 240.3333333343, 253.4999999991, 241.99999999940002, 305.8333333336, 201.8333333337, -51.333333333300004, -29.00000000019999, -97.9999999999, -182.0000000001, -8.166666666599994, 380.1666666666, -519.8333333331998, 272.1666666677, -268.9999999998, 242.83333333399997, 284.0000000007001, -105.3333333332, -86.00000000009999, 259.3333333324, -36.666666666000005, -86.9999999999, -97.00000000000001, -197.000000001, 125.3333333326, 35.50000000139997, 215.3333333333, -93.33333333360001, -105.9999999999, -200.3333333333, 344.1666666667999, -319.3333333342, -59.16666666719998, -100.0, 1.6666666672999924, 456.33333333419995, -113.0000000004, 79.8333333323, 137.8333333329, 402.49999999989996, 165.16666666690003, -166.6666666664, -106.3333333332, 280.3333333336, -924.1666666680001, -205.6666666664, 130.99999999899998, -103.0000000001, 16.000000000800004, -151.16666666589998, 244.66666666659998, 75.66666666709999, 191.8333333333, 139.50000000039995, 346.5000000005, -2.500000000599954, 127.00000000059998, -94.6666666669, 152.66666666709997, 127.00000000059998, 110.50000000080001, 326.33333333230007, 173.8333333338, 293.33333333329995, 216.16666666639998, -112.6666666668, -419.1666666659, 298.6666666663, 27.66666666719999, -1449.3333333321, 53.16666666679998, -21.000000001000018, -11.000000000900016, -60.33333333299999, 120.83333333239999, 175.83333333410005, 196.6666666672, 218.99999999940005, -107.6666666667, -227.50000000039998, -100.3333333333, -126.6666666667, 240.33333333309997, 233.8333333323, -198.3333333333, 214.8333333343, 118.66666666730003, -71.66666666629999, -491.1666666677, 189.49999999970004, 248.50000000110003, 299.3333333322, -70.0000000005, 46.99999999980001, 405.66666666689997, 306.1666666675], "policy_cop_policy_reward": [330.5, 378.5, 255.5, 103.0, 95.0, 351.5, 115.0, 26.5, 13.0, 291.0, 291.5, 374.0, 240.0, 451.5, 237.0, 255.0, 200.0, 36.5, -52.0, 254.0, 62.5, 356.0, 191.0, 345.5, 249.5, 8.5, 249.5, 245.5, 166.0, 345.0, -71.5, 52.0, 123.5, 143.0, 142.0, 95.0, 0.0, 0.0, 0.0, 0.0, 132.0, 114.5, 245.5, 321.0, 246.0, 322.0, 363.0, -221.5, 334.0, -386.0, 410.5, 245.0, 106.0, 76.0, 74.5, 398.5, 0.5, 228.0, 293.5, -78.0, 169.5, 0.0, 0.0, 0.0, 0.0, 0.0, 45.5, 372.0, 192.0, -34.0, -113.5, -429.0, 18.0, 21.5, 105.5, 216.5, 366.0, 246.5, 387.5, -81.0, 55.5, -1.0, 112.0, 157.5, 226.5, 291.0, 13.5, 344.0, 25.0, 287.0, 25.0, 104.0, 23.0, 0.0, 0.0, 409.0, 320.5, 265.0, -143.5, 401.0, 351.0, 34.0, 112.0, 77.5, 298.0, -2.0, 250.5, 327.5, 46.5, -58.5, 29.0, 14.0, 112.0, 340.5, 474.5, 33.5, 339.0, 181.5, 225.5, 356.5, 298.0, 23.5, 308.5, 249.0, 194.5, 100.5, 34.0, 22.5, 15.5, 13.0, 103.0, 291.0, -521.5, 394.5, 181.0, 231.0, 364.0, -100.0, 0.0, 453.5, 165.0, 93.0, 15.5, 105.0, 13.5, 44.0, -3.5, 241.5, 230.0, 177.5, 192.5, 244.5, 169.0, 46.5, 174.0, 200.0, 247.0, 275.5, 119.5, 192.5, 15.0, 181.5, 300.0, 374.5, -812.0, 314.5, 181.5, -285.0, 57.0, 27.0, -257.5, 157.0, -200.0, 0.0, 0.0, 144.0, 361.0, 152.5, 77.5, 273.0, -300.5, 242.5, 326.0, 294.5, 217.5, 399.0, 104.0, 246.5, 212.0, 178.0, 235.5, -115.5, 330.5, 170.5, 283.5, 265.0, -100.0, 0.0, 0.0, 379.5, 443.0, 312.5, -92.0, 198.5, 112.0, 79.5, 205.5, 124.0, 258.0, 408.5, 77.0, 149.5, 118.5, 218.5, 259.5, 240.0, -388.5, 187.5, 80.0, 150.5, 95.0, 104.0, 144.0, 325.0, 201.0, 170.5, 184.5, 296.5, 158.0, 152.0, 443.0, 228.5, 160.0, 132.5, 188.0, 101.0, 5.0, 4.0, 173.5, 172.0, 397.5, 0.0, 0.0, 0.0, 104.5, 6.0, 6.0, 206.5, -115.5, 255.5, 124.5, -176.0, 226.0, -159.0, 317.0, 263.0, 272.5, 405.0, 183.0, 176.0, 225.0, 98.0, 303.0, -584.5, 117.5, -49.5, 255.5, 335.0, 263.5, 266.5, 284.0, 80.0, 461.0, -384.0, 167.5, -162.5, 122.5, 284.5, 358.5, 150.0, 110.0, -2007.5, 293.0, 425.5, 172.5, 330.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6568680572474672, "mean_inference_ms": 6.605848016808489, "mean_action_processing_ms": 0.1466233575203297, "mean_env_wait_ms": 0.18203047867486993, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005109661121658868, "StateBufferConnector_ms": 0.006100732057832825, "ViewRequirementAgentConnector_ms": 0.36629178197250756}}, "episode_reward_max": 1338.6666666668, "episode_reward_min": -1198.8333333331002, "episode_reward_mean": 423.748333333367, "episode_len_mean": 71.49, "episodes_this_iter": 52, "policy_reward_min": {"mr_x_policy": -1449.3333333321, "cop_policy": -2007.5}, "policy_reward_max": {"mr_x_policy": 456.33333333419995, "cop_policy": 474.5}, "policy_reward_mean": {"mr_x_policy": 32.433333333367, "cop_policy": 136.8234265734266}, "hist_stats": {"episode_reward": [552.3333333337, 785.8333333341998, 54.33333333300001, 1272.833333333, 1116.3333333339003, 731.8333333342999, 517.9999999990999, 1134.4999999994002, 813.3333333336, 958.3333333337, 52.666666666699996, 350.9999999998, -97.9999999999, -182.0000000001, 483.83333333340005, 1269.1666666666001, -44.33333333319998, 541.6666666676998, -12.499999999799996, 869.8333333340003, 669.0000000006997, -105.3333333332, -86.00000000009999, 868.8333333324, -613.1666666659999, 58.0000000001, 732.0000000000001, 164.99999999899993, 393.83333333260003, 566.5000000014, 871.3333333332998, 58.66666666639999, -105.9999999999, -200.3333333333, 1338.6666666668, 289.16666666580005, 164.3333333328, -100.0, 548.1666666673, 771.8333333341998, 41.99999999959999, 928.3333333322998, 883.8333333328999, 1080.4999999999002, 917.1666666669001, -9.666666666400005, 25.166666666799998, 444.3333333335999, -148.16666666800003, -305.66666666640003, 842.4999999989999, 30.999999999900012, 298.0000000008, 448.8333333341001, 704.6666666666001, 696.6666666671, 779.3333333333001, 636.0000000004001, 223.5000000005001, -49.00000000059999, 53.50000000060001, -294.6666666669, 810.1666666671, 177.00000000059998, 973.5000000008, 1046.8333333323, 810.3333333338002, 743.8333333333001, 935.1666666664001, -212.66666666679998, 715.8333333341001, 517.1666666663001, 436.66666666719993, -705.8333333321, 539.6666666668001, 89.99999999900007, 406.9999999991, 282.666666667, 817.3333333324002, 814.8333333341, 1020.1666666671999, 699.4999999994, 2.333333333300004, 515.4999999996002, -100.3333333333, -10.166666666699996, 586.8333333331001, 408.33333333229996, -198.3333333333, 635.8333333343, 979.1666666673002, 427.3333333337, -655.1666666677, 730.4999999996999, 1062.5000000011, 456.3333333322, 57.499999999500005, 839.9999999997999, -1198.8333333331002, 1234.6666666674998], "episode_lengths": [100, 98, 17, 94, 100, 97, 98, 95, 97, 79, 22, 41, 2, 7, 70, 95, 104, 99, 28, 96, 99, 3, 5, 96, 97, 13, 98, 107, 98, 95, 99, 15, 3, 1, 93, 98, 19, 1, 83, 102, 16, 97, 93, 96, 93, 14, 12, 102, 106, 5, 96, 13, 96, 59, 97, 58, 95, 70, 104, 85, 101, 7, 97, 81, 96, 96, 96, 97, 95, 7, 100, 101, 55, 112, 98, 89, 38, 33, 93, 95, 94, 96, 10, 100, 4, 13, 98, 99, 2, 92, 97, 42, 111, 96, 94, 103, 39, 89, 119, 93], "policy_mr_x_policy_reward": [-412.16666666629993, 236.33333333419995, -100.166666667, 316.333333333, 187.83333333390001, 240.3333333343, 253.4999999991, 241.99999999940002, 305.8333333336, 201.8333333337, -51.333333333300004, -29.00000000019999, -97.9999999999, -182.0000000001, -8.166666666599994, 380.1666666666, -519.8333333331998, 272.1666666677, -268.9999999998, 242.83333333399997, 284.0000000007001, -105.3333333332, -86.00000000009999, 259.3333333324, -36.666666666000005, -86.9999999999, -97.00000000000001, -197.000000001, 125.3333333326, 35.50000000139997, 215.3333333333, -93.33333333360001, -105.9999999999, -200.3333333333, 344.1666666667999, -319.3333333342, -59.16666666719998, -100.0, 1.6666666672999924, 456.33333333419995, -113.0000000004, 79.8333333323, 137.8333333329, 402.49999999989996, 165.16666666690003, -166.6666666664, -106.3333333332, 280.3333333336, -924.1666666680001, -205.6666666664, 130.99999999899998, -103.0000000001, 16.000000000800004, -151.16666666589998, 244.66666666659998, 75.66666666709999, 191.8333333333, 139.50000000039995, 346.5000000005, -2.500000000599954, 127.00000000059998, -94.6666666669, 152.66666666709997, 127.00000000059998, 110.50000000080001, 326.33333333230007, 173.8333333338, 293.33333333329995, 216.16666666639998, -112.6666666668, -419.1666666659, 298.6666666663, 27.66666666719999, -1449.3333333321, 53.16666666679998, -21.000000001000018, -11.000000000900016, -60.33333333299999, 120.83333333239999, 175.83333333410005, 196.6666666672, 218.99999999940005, -107.6666666667, -227.50000000039998, -100.3333333333, -126.6666666667, 240.33333333309997, 233.8333333323, -198.3333333333, 214.8333333343, 118.66666666730003, -71.66666666629999, -491.1666666677, 189.49999999970004, 248.50000000110003, 299.3333333322, -70.0000000005, 46.99999999980001, 405.66666666689997, 306.1666666675], "policy_cop_policy_reward": [330.5, 378.5, 255.5, 103.0, 95.0, 351.5, 115.0, 26.5, 13.0, 291.0, 291.5, 374.0, 240.0, 451.5, 237.0, 255.0, 200.0, 36.5, -52.0, 254.0, 62.5, 356.0, 191.0, 345.5, 249.5, 8.5, 249.5, 245.5, 166.0, 345.0, -71.5, 52.0, 123.5, 143.0, 142.0, 95.0, 0.0, 0.0, 0.0, 0.0, 132.0, 114.5, 245.5, 321.0, 246.0, 322.0, 363.0, -221.5, 334.0, -386.0, 410.5, 245.0, 106.0, 76.0, 74.5, 398.5, 0.5, 228.0, 293.5, -78.0, 169.5, 0.0, 0.0, 0.0, 0.0, 0.0, 45.5, 372.0, 192.0, -34.0, -113.5, -429.0, 18.0, 21.5, 105.5, 216.5, 366.0, 246.5, 387.5, -81.0, 55.5, -1.0, 112.0, 157.5, 226.5, 291.0, 13.5, 344.0, 25.0, 287.0, 25.0, 104.0, 23.0, 0.0, 0.0, 409.0, 320.5, 265.0, -143.5, 401.0, 351.0, 34.0, 112.0, 77.5, 298.0, -2.0, 250.5, 327.5, 46.5, -58.5, 29.0, 14.0, 112.0, 340.5, 474.5, 33.5, 339.0, 181.5, 225.5, 356.5, 298.0, 23.5, 308.5, 249.0, 194.5, 100.5, 34.0, 22.5, 15.5, 13.0, 103.0, 291.0, -521.5, 394.5, 181.0, 231.0, 364.0, -100.0, 0.0, 453.5, 165.0, 93.0, 15.5, 105.0, 13.5, 44.0, -3.5, 241.5, 230.0, 177.5, 192.5, 244.5, 169.0, 46.5, 174.0, 200.0, 247.0, 275.5, 119.5, 192.5, 15.0, 181.5, 300.0, 374.5, -812.0, 314.5, 181.5, -285.0, 57.0, 27.0, -257.5, 157.0, -200.0, 0.0, 0.0, 144.0, 361.0, 152.5, 77.5, 273.0, -300.5, 242.5, 326.0, 294.5, 217.5, 399.0, 104.0, 246.5, 212.0, 178.0, 235.5, -115.5, 330.5, 170.5, 283.5, 265.0, -100.0, 0.0, 0.0, 379.5, 443.0, 312.5, -92.0, 198.5, 112.0, 79.5, 205.5, 124.0, 258.0, 408.5, 77.0, 149.5, 118.5, 218.5, 259.5, 240.0, -388.5, 187.5, 80.0, 150.5, 95.0, 104.0, 144.0, 325.0, 201.0, 170.5, 184.5, 296.5, 158.0, 152.0, 443.0, 228.5, 160.0, 132.5, 188.0, 101.0, 5.0, 4.0, 173.5, 172.0, 397.5, 0.0, 0.0, 0.0, 104.5, 6.0, 6.0, 206.5, -115.5, 255.5, 124.5, -176.0, 226.0, -159.0, 317.0, 263.0, 272.5, 405.0, 183.0, 176.0, 225.0, 98.0, 303.0, -584.5, 117.5, -49.5, 255.5, 335.0, 263.5, 266.5, 284.0, 80.0, 461.0, -384.0, 167.5, -162.5, 122.5, 284.5, 358.5, 150.0, 110.0, -2007.5, 293.0, 425.5, 172.5, 330.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6568680572474672, "mean_inference_ms": 6.605848016808489, "mean_action_processing_ms": 0.1466233575203297, "mean_env_wait_ms": 0.18203047867486993, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005109661121658868, "StateBufferConnector_ms": 0.006100732057832825, "ViewRequirementAgentConnector_ms": 0.36629178197250756}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 105.5125029165401, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 56000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 55997, "timers": {"training_iteration_time_ms": 36695.534, "sample_time_ms": 30018.879, "synch_weights_time_ms": 10.938}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 798, "training_iteration": 14, "trial_id": "96d6c_00000", "date": "2024-01-13_10-55-12", "timestamp": 1705139712, "time_this_iter_s": 37.92331290245056, "time_total_s": 518.7432546615601, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F3E5900>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 518.7432546615601, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 10.622448979591837, "ram_util_percent": 77.82857142857142, "gpu_util_percent0": 0.23204081632653062, "vram_util_percent0": 0.13916015625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2986.0, "total_loss": 19.114921029408773}, "mr_x_policy": {"total_loss": 19.114921029408773, "policy_loss": -0.07851172996064028, "vf_loss": 9.481478548049926, "vf_loss_unclipped": 13892.47421875, "vf_explained_var": 0.022164071599642437, "entropy": 1.0360905985037485, "mean_kl_loss": 0.014838380621025255, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.696930344899496, "policy_loss": -0.03287364613885681, "vf_loss": 9.72424521446228, "vf_loss_unclipped": 24179.359505208333, "vf_explained_var": -0.011249324679374695, "entropy": 1.197758001089096, "mean_kl_loss": 0.01235280453474843, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.45000001788139343}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1234.6666666674998, "episode_reward_min": -1198.8333333331002, "episode_reward_mean": 470.618333333339, "episode_len_mean": 77.24, "episode_media": {}, "episodes_this_iter": 52, "policy_reward_min": {"mr_x_policy": -1449.3333333321, "cop_policy": -2007.5}, "policy_reward_max": {"mr_x_policy": 410.66666666509997, "cop_policy": 476.5}, "policy_reward_mean": {"mr_x_policy": 71.398333333339, "cop_policy": 140.07719298245615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [298.0000000008, 448.8333333341001, 704.6666666666001, 696.6666666671, 779.3333333333001, 636.0000000004001, 223.5000000005001, -49.00000000059999, 53.50000000060001, -294.6666666669, 810.1666666671, 177.00000000059998, 973.5000000008, 1046.8333333323, 810.3333333338002, 743.8333333333001, 935.1666666664001, -212.66666666679998, 715.8333333341001, 517.1666666663001, 436.66666666719993, -705.8333333321, 539.6666666668001, 89.99999999900007, 406.9999999991, 282.666666667, 817.3333333324002, 814.8333333341, 1020.1666666671999, 699.4999999994, 2.333333333300004, 515.4999999996002, -100.3333333333, -10.166666666699996, 586.8333333331001, 408.33333333229996, -198.3333333333, 635.8333333343, 979.1666666673002, 427.3333333337, -655.1666666677, 730.4999999996999, 1062.5000000011, 456.3333333322, 57.499999999500005, 839.9999999997999, -1198.8333333331002, 1234.6666666674998, 1088.9999999998, 902.8333333346001, -98.6666666667, 729.3333333330997, -199.6666666667, 915.6666666647, 658.4999999998998, 372.16666666659995, -191.3333333333, 249.4999999995, -93.66666666639999, 482.83333333350004, 467.166666666, 626.6666666673001, 768.6666666679, 674.6666666673999, -102.9999999999, 547.4999999998, 342.66666666680004, 1108.9999999991999, 1052.3333333324001, 577.1666666665999, 884.5000000004, 793.4999999990999, 486.5000000003001, 171.49999999980008, 413.50000000139994, 163.49999999930003, 865.6666666666001, 777.1666666666, 929.3333333333997, 629.3333333331, 739.8333333326, -99.3333333333, 825.6666666665, 427.66666666669994, 570.5000000004, 67.5, 894.6666666673001, 985.1666666671999, 757.6666666651001, 9.0, 166.50000000060004, 1147.9999999998001, -225.99999999970015, 1033.9999999996, -100.3333333333, 1162.666666666, 237.49999999969998, 483.3333333339, 993.3333333328002, -199.3333333333], "episode_lengths": [96, 59, 97, 58, 95, 70, 104, 85, 101, 7, 97, 81, 96, 96, 96, 97, 95, 7, 100, 101, 55, 112, 98, 89, 38, 33, 93, 95, 94, 96, 10, 100, 4, 13, 98, 99, 2, 92, 97, 42, 111, 96, 94, 103, 39, 89, 119, 93, 95, 95, 1, 96, 1, 100, 96, 91, 7, 100, 4, 98, 100, 98, 98, 97, 5, 74, 101, 93, 93, 90, 94, 96, 101, 98, 96, 38, 97, 97, 95, 88, 94, 1, 96, 101, 98, 20, 89, 95, 101, 11, 104, 93, 106, 94, 8, 97, 50, 96, 94, 1], "policy_mr_x_policy_reward": [16.000000000800004, -151.16666666589998, 244.66666666659998, 75.66666666709999, 191.8333333333, 139.50000000039995, 346.5000000005, -2.500000000599954, 127.00000000059998, -94.6666666669, 152.66666666709997, 127.00000000059998, 110.50000000080001, 326.33333333230007, 173.8333333338, 293.33333333329995, 216.16666666639998, -112.6666666668, -419.1666666659, 298.6666666663, 27.66666666719999, -1449.3333333321, 53.16666666679998, -21.000000001000018, -11.000000000900016, -60.33333333299999, 120.83333333239999, 175.83333333410005, 196.6666666672, 218.99999999940005, -107.6666666667, -227.50000000039998, -100.3333333333, -126.6666666667, 240.33333333309997, 233.8333333323, -198.3333333333, 214.8333333343, 118.66666666730003, -71.66666666629999, -491.1666666677, 189.49999999970004, 248.50000000110003, 299.3333333322, -70.0000000005, 46.99999999980001, 405.66666666689997, 306.1666666675, 194.49999999980002, 198.83333333460004, -98.6666666667, 194.83333333310003, -199.6666666667, 259.1666666647, 158.4999999999, 248.16666666659995, -191.3333333333, 58.99999999950002, -93.66666666639999, 167.33333333349998, 292.6666666660001, 246.16666666729998, -40.8333333321, 212.6666666674, -102.9999999999, -34.00000000019999, -35.83333333319995, 241.4999999992, 226.8333333324, -65.33333333339998, 244.5000000004, 5.499999999099993, 222.50000000030002, 63.9999999998, 70.50000000140001, -180.50000000070003, 300.6666666666, 21.166666666599994, 246.33333333340002, 70.3333333331, 76.83333333260002, -99.3333333333, 223.6666666665, 191.66666666670002, 52.00000000039999, -97.0, 95.66666666730003, 300.16666666720005, 410.66666666509997, -107.5, -157.49999999939996, 273.4999999998, 243.5000000003, 223.99999999960002, -100.3333333333, 399.666666666, -8.000000000300005, 75.83333333389999, 217.33333333279995, -199.3333333333], "policy_cop_policy_reward": [44.0, -3.5, 241.5, 230.0, 177.5, 192.5, 244.5, 169.0, 46.5, 174.0, 200.0, 247.0, 275.5, 119.5, 192.5, 15.0, 181.5, 300.0, 374.5, -812.0, 314.5, 181.5, -285.0, 57.0, 27.0, -257.5, 157.0, -200.0, 0.0, 0.0, 144.0, 361.0, 152.5, 77.5, 273.0, -300.5, 242.5, 326.0, 294.5, 217.5, 399.0, 104.0, 246.5, 212.0, 178.0, 235.5, -115.5, 330.5, 170.5, 283.5, 265.0, -100.0, 0.0, 0.0, 379.5, 443.0, 312.5, -92.0, 198.5, 112.0, 79.5, 205.5, 124.0, 258.0, 408.5, 77.0, 149.5, 118.5, 218.5, 259.5, 240.0, -388.5, 187.5, 80.0, 150.5, 95.0, 104.0, 144.0, 325.0, 201.0, 170.5, 184.5, 296.5, 158.0, 152.0, 443.0, 228.5, 160.0, 132.5, 188.0, 101.0, 5.0, 4.0, 173.5, 172.0, 397.5, 0.0, 0.0, 0.0, 104.5, 6.0, 6.0, 206.5, -115.5, 255.5, 124.5, -176.0, 226.0, -159.0, 317.0, 263.0, 272.5, 405.0, 183.0, 176.0, 225.0, 98.0, 303.0, -584.5, 117.5, -49.5, 255.5, 335.0, 263.5, 266.5, 284.0, 80.0, 461.0, -384.0, 167.5, -162.5, 122.5, 284.5, 358.5, 150.0, 110.0, -2007.5, 293.0, 425.5, 172.5, 330.5, 268.0, 342.0, 284.5, 258.0, 260.0, 186.0, 248.0, 146.0, 140.5, -11.0, 395.0, 272.5, 81.0, 290.5, 128.5, 219.0, -316.0, 221.0, 0.0, 0.0, 0.0, -398.0, 231.5, 357.0, 0.0, 0.0, 0.0, 79.5, -20.5, 256.5, -335.5, 219.5, 290.5, 180.5, 194.0, 6.0, 78.0, 408.0, 323.5, 66.0, 408.0, -12.0, 0.0, 0.0, 0.0, 245.5, 171.0, 165.0, 246.5, -86.5, 218.5, 184.0, 313.0, 370.5, 328.5, 343.5, 153.5, 95.5, 283.0, 264.0, 156.5, 239.5, 244.0, 422.0, 199.5, 166.5, -308.0, 255.5, 316.5, 71.5, -126.5, 162.5, -148.0, 244.5, 246.5, 146.5, 122.0, 75.5, 60.0, 286.0, 219.0, 396.5, 117.0, 242.5, 132.5, 246.0, 304.5, 378.5, 197.5, -17.0, 256.0, 219.0, 188.0, 0.5, 321.0, 280.5, 132.5, 127.0, -23.5, 291.0, 167.5, 60.0, 19.5, 25.0, 120.0, 267.0, 253.0, 279.0, 56.5, 290.5, 338.0, 215.0, 476.5, -344.5, 7.0, 102.0, 7.5, -315.5, 369.5, 270.0, 199.5, 305.0, 370.0, 179.5, -863.0, 214.0, 254.5, 234.0, 321.5, 0.0, 0.0, 0.0, 282.0, 243.0, 238.0, 145.0, 135.0, -34.5, 212.0, 373.5, -178.0, 275.0, 253.5, 247.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6536676075729808, "mean_inference_ms": 6.583171366298749, "mean_action_processing_ms": 0.14608370772642748, "mean_env_wait_ms": 0.18128027366182706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005648686335637019, "StateBufferConnector_ms": 0.006223825307992788, "ViewRequirementAgentConnector_ms": 0.33353512103740984}}, "episode_reward_max": 1234.6666666674998, "episode_reward_min": -1198.8333333331002, "episode_reward_mean": 470.618333333339, "episode_len_mean": 77.24, "episodes_this_iter": 52, "policy_reward_min": {"mr_x_policy": -1449.3333333321, "cop_policy": -2007.5}, "policy_reward_max": {"mr_x_policy": 410.66666666509997, "cop_policy": 476.5}, "policy_reward_mean": {"mr_x_policy": 71.398333333339, "cop_policy": 140.07719298245615}, "hist_stats": {"episode_reward": [298.0000000008, 448.8333333341001, 704.6666666666001, 696.6666666671, 779.3333333333001, 636.0000000004001, 223.5000000005001, -49.00000000059999, 53.50000000060001, -294.6666666669, 810.1666666671, 177.00000000059998, 973.5000000008, 1046.8333333323, 810.3333333338002, 743.8333333333001, 935.1666666664001, -212.66666666679998, 715.8333333341001, 517.1666666663001, 436.66666666719993, -705.8333333321, 539.6666666668001, 89.99999999900007, 406.9999999991, 282.666666667, 817.3333333324002, 814.8333333341, 1020.1666666671999, 699.4999999994, 2.333333333300004, 515.4999999996002, -100.3333333333, -10.166666666699996, 586.8333333331001, 408.33333333229996, -198.3333333333, 635.8333333343, 979.1666666673002, 427.3333333337, -655.1666666677, 730.4999999996999, 1062.5000000011, 456.3333333322, 57.499999999500005, 839.9999999997999, -1198.8333333331002, 1234.6666666674998, 1088.9999999998, 902.8333333346001, -98.6666666667, 729.3333333330997, -199.6666666667, 915.6666666647, 658.4999999998998, 372.16666666659995, -191.3333333333, 249.4999999995, -93.66666666639999, 482.83333333350004, 467.166666666, 626.6666666673001, 768.6666666679, 674.6666666673999, -102.9999999999, 547.4999999998, 342.66666666680004, 1108.9999999991999, 1052.3333333324001, 577.1666666665999, 884.5000000004, 793.4999999990999, 486.5000000003001, 171.49999999980008, 413.50000000139994, 163.49999999930003, 865.6666666666001, 777.1666666666, 929.3333333333997, 629.3333333331, 739.8333333326, -99.3333333333, 825.6666666665, 427.66666666669994, 570.5000000004, 67.5, 894.6666666673001, 985.1666666671999, 757.6666666651001, 9.0, 166.50000000060004, 1147.9999999998001, -225.99999999970015, 1033.9999999996, -100.3333333333, 1162.666666666, 237.49999999969998, 483.3333333339, 993.3333333328002, -199.3333333333], "episode_lengths": [96, 59, 97, 58, 95, 70, 104, 85, 101, 7, 97, 81, 96, 96, 96, 97, 95, 7, 100, 101, 55, 112, 98, 89, 38, 33, 93, 95, 94, 96, 10, 100, 4, 13, 98, 99, 2, 92, 97, 42, 111, 96, 94, 103, 39, 89, 119, 93, 95, 95, 1, 96, 1, 100, 96, 91, 7, 100, 4, 98, 100, 98, 98, 97, 5, 74, 101, 93, 93, 90, 94, 96, 101, 98, 96, 38, 97, 97, 95, 88, 94, 1, 96, 101, 98, 20, 89, 95, 101, 11, 104, 93, 106, 94, 8, 97, 50, 96, 94, 1], "policy_mr_x_policy_reward": [16.000000000800004, -151.16666666589998, 244.66666666659998, 75.66666666709999, 191.8333333333, 139.50000000039995, 346.5000000005, -2.500000000599954, 127.00000000059998, -94.6666666669, 152.66666666709997, 127.00000000059998, 110.50000000080001, 326.33333333230007, 173.8333333338, 293.33333333329995, 216.16666666639998, -112.6666666668, -419.1666666659, 298.6666666663, 27.66666666719999, -1449.3333333321, 53.16666666679998, -21.000000001000018, -11.000000000900016, -60.33333333299999, 120.83333333239999, 175.83333333410005, 196.6666666672, 218.99999999940005, -107.6666666667, -227.50000000039998, -100.3333333333, -126.6666666667, 240.33333333309997, 233.8333333323, -198.3333333333, 214.8333333343, 118.66666666730003, -71.66666666629999, -491.1666666677, 189.49999999970004, 248.50000000110003, 299.3333333322, -70.0000000005, 46.99999999980001, 405.66666666689997, 306.1666666675, 194.49999999980002, 198.83333333460004, -98.6666666667, 194.83333333310003, -199.6666666667, 259.1666666647, 158.4999999999, 248.16666666659995, -191.3333333333, 58.99999999950002, -93.66666666639999, 167.33333333349998, 292.6666666660001, 246.16666666729998, -40.8333333321, 212.6666666674, -102.9999999999, -34.00000000019999, -35.83333333319995, 241.4999999992, 226.8333333324, -65.33333333339998, 244.5000000004, 5.499999999099993, 222.50000000030002, 63.9999999998, 70.50000000140001, -180.50000000070003, 300.6666666666, 21.166666666599994, 246.33333333340002, 70.3333333331, 76.83333333260002, -99.3333333333, 223.6666666665, 191.66666666670002, 52.00000000039999, -97.0, 95.66666666730003, 300.16666666720005, 410.66666666509997, -107.5, -157.49999999939996, 273.4999999998, 243.5000000003, 223.99999999960002, -100.3333333333, 399.666666666, -8.000000000300005, 75.83333333389999, 217.33333333279995, -199.3333333333], "policy_cop_policy_reward": [44.0, -3.5, 241.5, 230.0, 177.5, 192.5, 244.5, 169.0, 46.5, 174.0, 200.0, 247.0, 275.5, 119.5, 192.5, 15.0, 181.5, 300.0, 374.5, -812.0, 314.5, 181.5, -285.0, 57.0, 27.0, -257.5, 157.0, -200.0, 0.0, 0.0, 144.0, 361.0, 152.5, 77.5, 273.0, -300.5, 242.5, 326.0, 294.5, 217.5, 399.0, 104.0, 246.5, 212.0, 178.0, 235.5, -115.5, 330.5, 170.5, 283.5, 265.0, -100.0, 0.0, 0.0, 379.5, 443.0, 312.5, -92.0, 198.5, 112.0, 79.5, 205.5, 124.0, 258.0, 408.5, 77.0, 149.5, 118.5, 218.5, 259.5, 240.0, -388.5, 187.5, 80.0, 150.5, 95.0, 104.0, 144.0, 325.0, 201.0, 170.5, 184.5, 296.5, 158.0, 152.0, 443.0, 228.5, 160.0, 132.5, 188.0, 101.0, 5.0, 4.0, 173.5, 172.0, 397.5, 0.0, 0.0, 0.0, 104.5, 6.0, 6.0, 206.5, -115.5, 255.5, 124.5, -176.0, 226.0, -159.0, 317.0, 263.0, 272.5, 405.0, 183.0, 176.0, 225.0, 98.0, 303.0, -584.5, 117.5, -49.5, 255.5, 335.0, 263.5, 266.5, 284.0, 80.0, 461.0, -384.0, 167.5, -162.5, 122.5, 284.5, 358.5, 150.0, 110.0, -2007.5, 293.0, 425.5, 172.5, 330.5, 268.0, 342.0, 284.5, 258.0, 260.0, 186.0, 248.0, 146.0, 140.5, -11.0, 395.0, 272.5, 81.0, 290.5, 128.5, 219.0, -316.0, 221.0, 0.0, 0.0, 0.0, -398.0, 231.5, 357.0, 0.0, 0.0, 0.0, 79.5, -20.5, 256.5, -335.5, 219.5, 290.5, 180.5, 194.0, 6.0, 78.0, 408.0, 323.5, 66.0, 408.0, -12.0, 0.0, 0.0, 0.0, 245.5, 171.0, 165.0, 246.5, -86.5, 218.5, 184.0, 313.0, 370.5, 328.5, 343.5, 153.5, 95.5, 283.0, 264.0, 156.5, 239.5, 244.0, 422.0, 199.5, 166.5, -308.0, 255.5, 316.5, 71.5, -126.5, 162.5, -148.0, 244.5, 246.5, 146.5, 122.0, 75.5, 60.0, 286.0, 219.0, 396.5, 117.0, 242.5, 132.5, 246.0, 304.5, 378.5, 197.5, -17.0, 256.0, 219.0, 188.0, 0.5, 321.0, 280.5, 132.5, 127.0, -23.5, 291.0, 167.5, 60.0, 19.5, 25.0, 120.0, 267.0, 253.0, 279.0, 56.5, 290.5, 338.0, 215.0, 476.5, -344.5, 7.0, 102.0, 7.5, -315.5, 369.5, 270.0, 199.5, 305.0, 370.0, 179.5, -863.0, 214.0, 254.5, 234.0, 321.5, 0.0, 0.0, 0.0, 282.0, 243.0, 238.0, 145.0, 135.0, -34.5, 212.0, 373.5, -178.0, 275.0, 253.5, 247.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6536676075729808, "mean_inference_ms": 6.583171366298749, "mean_action_processing_ms": 0.14608370772642748, "mean_env_wait_ms": 0.18128027366182706, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005648686335637019, "StateBufferConnector_ms": 0.006223825307992788, "ViewRequirementAgentConnector_ms": 0.33353512103740984}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.70651112626551, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 60000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 59997, "timers": {"training_iteration_time_ms": 36369.638, "sample_time_ms": 29656.62, "synch_weights_time_ms": 10.714}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 850, "training_iteration": 15, "trial_id": "96d6c_00000", "date": "2024-01-13_10-55-46", "timestamp": 1705139746, "time_this_iter_s": 33.429194688797, "time_total_s": 552.172449350357, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F27B9A0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 552.172449350357, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 7.247727272727272, "ram_util_percent": 78.62727272727273, "gpu_util_percent0": 0.1875, "vram_util_percent0": 0.162039092092803}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2977.0, "total_loss": 19.252509371439615}, "mr_x_policy": {"total_loss": 19.252509371439615, "policy_loss": -0.07548328817744429, "vf_loss": 9.576303799947103, "vf_loss_unclipped": 27724.99873046875, "vf_explained_var": 0.010125799973805746, "entropy": 1.0223193496465683, "mean_kl_loss": 0.014631185068659154, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.736874961853028, "policy_loss": -0.024858425937903425, "vf_loss": 9.752768150965373, "vf_loss_unclipped": 67544.99007161458, "vf_explained_var": -0.0036664416392644247, "entropy": 1.1808602591355641, "mean_kl_loss": 0.019923151864835138, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.45000001788139343}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1338.3333333346002, "episode_reward_min": -2662.5000000004998, "episode_reward_mean": 481.00500000000596, "episode_len_mean": 79.26, "episode_media": {}, "episodes_this_iter": 49, "policy_reward_min": {"mr_x_policy": -961.4999999993998, "cop_policy": -3161.0}, "policy_reward_max": {"mr_x_policy": 410.66666666509997, "cop_policy": 562.5}, "policy_reward_mean": {"mr_x_policy": 75.79500000000601, "cop_policy": 142.67957746478874}, "custom_metrics": {}, "hist_stats": {"episode_reward": [902.8333333346001, -98.6666666667, 729.3333333330997, -199.6666666667, 915.6666666647, 658.4999999998998, 372.16666666659995, -191.3333333333, 249.4999999995, -93.66666666639999, 482.83333333350004, 467.166666666, 626.6666666673001, 768.6666666679, 674.6666666673999, -102.9999999999, 547.4999999998, 342.66666666680004, 1108.9999999991999, 1052.3333333324001, 577.1666666665999, 884.5000000004, 793.4999999990999, 486.5000000003001, 171.49999999980008, 413.50000000139994, 163.49999999930003, 865.6666666666001, 777.1666666666, 929.3333333333997, 629.3333333331, 739.8333333326, -99.3333333333, 825.6666666665, 427.66666666669994, 570.5000000004, 67.5, 894.6666666673001, 985.1666666671999, 757.6666666651001, 9.0, 166.50000000060004, 1147.9999999998001, -225.99999999970015, 1033.9999999996, -100.3333333333, 1162.666666666, 237.49999999969998, 483.3333333339, 993.3333333328002, -199.3333333333, 993.3333333338002, 95.33333333319999, -99.6666666667, 1018.0000000004, 741.499999999, 217.6666666666, 125.50000000009999, 252.66666666689997, 863.1666666662002, -86.99999999940002, 920.1666666660001, 218.99999999919999, 820.5000000001002, 13.333333333699997, 1021.6666666662999, 1338.3333333346002, 1005.3333333351001, 401.5000000005, 760.8333333336999, 1102.4999999993, 889.6666666671999, 737.1666666673998, 711.0000000008, 1001.8333333339999, 454.66666666689986, 268.99999999900007, 393.3333333331998, 163.83333333350004, 623.666666667, 69.83333333330003, 484.8333333335, 266.3333333337, 483.8333333313001, 824.8333333339001, -698.1666666687001, 295.83333333300004, 1190.8333333340001, 707.8333333334999, 823.8333333342999, 777.3333333349, 452.833333333, -204.33333333320002, -2662.5000000004998, 594.8333333332998, 733.5000000001, -603.8333333339001, 774.5000000003, 735.8333333335999, 301.83333333269997], "episode_lengths": [95, 1, 96, 1, 100, 96, 91, 7, 100, 4, 98, 100, 98, 98, 97, 5, 74, 101, 93, 93, 90, 94, 96, 101, 98, 96, 38, 97, 97, 95, 88, 94, 1, 96, 101, 98, 20, 89, 95, 101, 11, 104, 93, 106, 94, 8, 97, 50, 96, 94, 1, 95, 23, 1, 96, 95, 41, 21, 103, 95, 105, 86, 33, 94, 9, 97, 95, 94, 98, 95, 93, 96, 96, 97, 100, 46, 103, 104, 33, 98, 105, 71, 36, 98, 98, 113, 103, 93, 95, 88, 98, 91, 4, 130, 97, 94, 91, 96, 94, 102], "policy_mr_x_policy_reward": [198.83333333460004, -98.6666666667, 194.83333333310003, -199.6666666667, 259.1666666647, 158.4999999999, 248.16666666659995, -191.3333333333, 58.99999999950002, -93.66666666639999, 167.33333333349998, 292.6666666660001, 246.16666666729998, -40.8333333321, 212.6666666674, -102.9999999999, -34.00000000019999, -35.83333333319995, 241.4999999992, 226.8333333324, -65.33333333339998, 244.5000000004, 5.499999999099993, 222.50000000030002, 63.9999999998, 70.50000000140001, -180.50000000070003, 300.6666666666, 21.166666666599994, 246.33333333340002, 70.3333333331, 76.83333333260002, -99.3333333333, 223.6666666665, 191.66666666670002, 52.00000000039999, -97.0, 95.66666666730003, 300.16666666720005, 410.66666666509997, -107.5, -157.49999999939996, 273.4999999998, 243.5000000003, 223.99999999960002, -100.3333333333, 399.666666666, -8.000000000300005, 75.83333333389999, 217.33333333279995, -199.3333333333, 141.3333333338, -102.6666666668, -99.6666666667, 204.50000000039998, 192.99999999900004, -103.33333333339999, -83.9999999999, 283.1666666669, 261.16666666619994, -961.4999999993998, -6.833333334000002, -75.00000000080001, 145.5000000001, -93.1666666663, 268.6666666663, 367.33333333459996, 235.33333333509998, -32.499999999499984, -2.1666666663000096, 228.49999999930003, 261.16666666720005, 188.6666666674, -167.4999999992, 23.833333334000013, -16.3333333331, 263.499999999, 239.3333333332, -101.6666666665, 268.166666667, 298.33333333330006, 24.83333333349998, -117.66666666630002, -14.666666668700003, 333.83333333389993, -46.66666666870001, 341.83333333300004, 241.833333334, 130.3333333335, 58.83333333430001, -6.166666665099978, -251.166666667, -104.3333333332, 219.4999999995, 74.83333333330002, 163.5000000001, 9.166666666099971, 206.00000000029996, 109.33333333360001, -542.6666666673], "policy_cop_policy_reward": [258.0, 260.0, 186.0, 248.0, 146.0, 140.5, -11.0, 395.0, 272.5, 81.0, 290.5, 128.5, 219.0, -316.0, 221.0, 0.0, 0.0, 0.0, -398.0, 231.5, 357.0, 0.0, 0.0, 0.0, 79.5, -20.5, 256.5, -335.5, 219.5, 290.5, 180.5, 194.0, 6.0, 78.0, 408.0, 323.5, 66.0, 408.0, -12.0, 0.0, 0.0, 0.0, 245.5, 171.0, 165.0, 246.5, -86.5, 218.5, 184.0, 313.0, 370.5, 328.5, 343.5, 153.5, 95.5, 283.0, 264.0, 156.5, 239.5, 244.0, 422.0, 199.5, 166.5, -308.0, 255.5, 316.5, 71.5, -126.5, 162.5, -148.0, 244.5, 246.5, 146.5, 122.0, 75.5, 60.0, 286.0, 219.0, 396.5, 117.0, 242.5, 132.5, 246.0, 304.5, 378.5, 197.5, -17.0, 256.0, 219.0, 188.0, 0.5, 321.0, 280.5, 132.5, 127.0, -23.5, 291.0, 167.5, 60.0, 19.5, 25.0, 120.0, 267.0, 253.0, 279.0, 56.5, 290.5, 338.0, 215.0, 476.5, -344.5, 7.0, 102.0, 7.5, -315.5, 369.5, 270.0, 199.5, 305.0, 370.0, 179.5, -863.0, 214.0, 254.5, 234.0, 321.5, 0.0, 0.0, 0.0, 282.0, 243.0, 238.0, 145.0, 135.0, -34.5, 212.0, 373.5, -178.0, 275.0, 253.5, 247.5, 145.5, 288.0, 418.5, 28.5, 132.0, 37.5, 243.0, 113.5, 457.0, 253.0, 166.5, 129.0, 121.5, 61.5, 138.0, 58.5, 31.5, 119.5, 77.0, -442.0, 334.5, 60.0, 332.5, 209.5, 364.0, 272.0, 238.5, 167.5, 363.0, 396.5, 98.5, 48.5, 147.0, 103.5, 316.5, 255.0, 2.0, 4.5, 100.0, 172.5, 152.0, 428.5, 272.5, 306.5, 392.0, 381.0, 69.5, 319.5, -9.0, 323.0, 120.0, 221.5, 253.0, 288.5, 451.5, 174.0, 248.5, -33.0, 431.5, 230.0, -113.0, 247.0, 414.5, 426.0, 172.5, 280.0, 145.5, 562.5, 270.0, 151.5, 159.0, 160.5, -615.0, 240.5, 380.0, -498.5, 361.0, 291.5, 122.0, 58.5, 85.0, 237.5, 110.0, 8.0, -6.5, -467.5, 245.5, 42.0, 148.5, 269.5, 97.5, 152.0, 134.5, 117.5, 97.0, 284.0, 342.5, -79.5, 228.0, -1315.0, 422.0, 241.5, 254.0, -531.5, 231.5, 223.5, 343.5, 382.0, 340.5, -39.0, 276.0, 347.5, 293.0, 124.5, 314.5, 289.5, 179.5, 203.0, 235.0, 266.0, -100.0, 0.0, 76.0, -3161.0, 203.0, 269.0, -20.5, 271.5, 325.5, 24.5, 220.0, 216.5, -1185.0, 355.5, 346.0, 112.5, 110.0, 219.0, 146.0, 261.5, 360.0, 203.5, 281.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.655200573879735, "mean_inference_ms": 6.594006654878556, "mean_action_processing_ms": 0.14755303694234714, "mean_env_wait_ms": 0.18123777045907652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005142994416065705, "StateBufferConnector_ms": 0.005736840076935597, "ViewRequirementAgentConnector_ms": 0.35084039737016726}}, "episode_reward_max": 1338.3333333346002, "episode_reward_min": -2662.5000000004998, "episode_reward_mean": 481.00500000000596, "episode_len_mean": 79.26, "episodes_this_iter": 49, "policy_reward_min": {"mr_x_policy": -961.4999999993998, "cop_policy": -3161.0}, "policy_reward_max": {"mr_x_policy": 410.66666666509997, "cop_policy": 562.5}, "policy_reward_mean": {"mr_x_policy": 75.79500000000601, "cop_policy": 142.67957746478874}, "hist_stats": {"episode_reward": [902.8333333346001, -98.6666666667, 729.3333333330997, -199.6666666667, 915.6666666647, 658.4999999998998, 372.16666666659995, -191.3333333333, 249.4999999995, -93.66666666639999, 482.83333333350004, 467.166666666, 626.6666666673001, 768.6666666679, 674.6666666673999, -102.9999999999, 547.4999999998, 342.66666666680004, 1108.9999999991999, 1052.3333333324001, 577.1666666665999, 884.5000000004, 793.4999999990999, 486.5000000003001, 171.49999999980008, 413.50000000139994, 163.49999999930003, 865.6666666666001, 777.1666666666, 929.3333333333997, 629.3333333331, 739.8333333326, -99.3333333333, 825.6666666665, 427.66666666669994, 570.5000000004, 67.5, 894.6666666673001, 985.1666666671999, 757.6666666651001, 9.0, 166.50000000060004, 1147.9999999998001, -225.99999999970015, 1033.9999999996, -100.3333333333, 1162.666666666, 237.49999999969998, 483.3333333339, 993.3333333328002, -199.3333333333, 993.3333333338002, 95.33333333319999, -99.6666666667, 1018.0000000004, 741.499999999, 217.6666666666, 125.50000000009999, 252.66666666689997, 863.1666666662002, -86.99999999940002, 920.1666666660001, 218.99999999919999, 820.5000000001002, 13.333333333699997, 1021.6666666662999, 1338.3333333346002, 1005.3333333351001, 401.5000000005, 760.8333333336999, 1102.4999999993, 889.6666666671999, 737.1666666673998, 711.0000000008, 1001.8333333339999, 454.66666666689986, 268.99999999900007, 393.3333333331998, 163.83333333350004, 623.666666667, 69.83333333330003, 484.8333333335, 266.3333333337, 483.8333333313001, 824.8333333339001, -698.1666666687001, 295.83333333300004, 1190.8333333340001, 707.8333333334999, 823.8333333342999, 777.3333333349, 452.833333333, -204.33333333320002, -2662.5000000004998, 594.8333333332998, 733.5000000001, -603.8333333339001, 774.5000000003, 735.8333333335999, 301.83333333269997], "episode_lengths": [95, 1, 96, 1, 100, 96, 91, 7, 100, 4, 98, 100, 98, 98, 97, 5, 74, 101, 93, 93, 90, 94, 96, 101, 98, 96, 38, 97, 97, 95, 88, 94, 1, 96, 101, 98, 20, 89, 95, 101, 11, 104, 93, 106, 94, 8, 97, 50, 96, 94, 1, 95, 23, 1, 96, 95, 41, 21, 103, 95, 105, 86, 33, 94, 9, 97, 95, 94, 98, 95, 93, 96, 96, 97, 100, 46, 103, 104, 33, 98, 105, 71, 36, 98, 98, 113, 103, 93, 95, 88, 98, 91, 4, 130, 97, 94, 91, 96, 94, 102], "policy_mr_x_policy_reward": [198.83333333460004, -98.6666666667, 194.83333333310003, -199.6666666667, 259.1666666647, 158.4999999999, 248.16666666659995, -191.3333333333, 58.99999999950002, -93.66666666639999, 167.33333333349998, 292.6666666660001, 246.16666666729998, -40.8333333321, 212.6666666674, -102.9999999999, -34.00000000019999, -35.83333333319995, 241.4999999992, 226.8333333324, -65.33333333339998, 244.5000000004, 5.499999999099993, 222.50000000030002, 63.9999999998, 70.50000000140001, -180.50000000070003, 300.6666666666, 21.166666666599994, 246.33333333340002, 70.3333333331, 76.83333333260002, -99.3333333333, 223.6666666665, 191.66666666670002, 52.00000000039999, -97.0, 95.66666666730003, 300.16666666720005, 410.66666666509997, -107.5, -157.49999999939996, 273.4999999998, 243.5000000003, 223.99999999960002, -100.3333333333, 399.666666666, -8.000000000300005, 75.83333333389999, 217.33333333279995, -199.3333333333, 141.3333333338, -102.6666666668, -99.6666666667, 204.50000000039998, 192.99999999900004, -103.33333333339999, -83.9999999999, 283.1666666669, 261.16666666619994, -961.4999999993998, -6.833333334000002, -75.00000000080001, 145.5000000001, -93.1666666663, 268.6666666663, 367.33333333459996, 235.33333333509998, -32.499999999499984, -2.1666666663000096, 228.49999999930003, 261.16666666720005, 188.6666666674, -167.4999999992, 23.833333334000013, -16.3333333331, 263.499999999, 239.3333333332, -101.6666666665, 268.166666667, 298.33333333330006, 24.83333333349998, -117.66666666630002, -14.666666668700003, 333.83333333389993, -46.66666666870001, 341.83333333300004, 241.833333334, 130.3333333335, 58.83333333430001, -6.166666665099978, -251.166666667, -104.3333333332, 219.4999999995, 74.83333333330002, 163.5000000001, 9.166666666099971, 206.00000000029996, 109.33333333360001, -542.6666666673], "policy_cop_policy_reward": [258.0, 260.0, 186.0, 248.0, 146.0, 140.5, -11.0, 395.0, 272.5, 81.0, 290.5, 128.5, 219.0, -316.0, 221.0, 0.0, 0.0, 0.0, -398.0, 231.5, 357.0, 0.0, 0.0, 0.0, 79.5, -20.5, 256.5, -335.5, 219.5, 290.5, 180.5, 194.0, 6.0, 78.0, 408.0, 323.5, 66.0, 408.0, -12.0, 0.0, 0.0, 0.0, 245.5, 171.0, 165.0, 246.5, -86.5, 218.5, 184.0, 313.0, 370.5, 328.5, 343.5, 153.5, 95.5, 283.0, 264.0, 156.5, 239.5, 244.0, 422.0, 199.5, 166.5, -308.0, 255.5, 316.5, 71.5, -126.5, 162.5, -148.0, 244.5, 246.5, 146.5, 122.0, 75.5, 60.0, 286.0, 219.0, 396.5, 117.0, 242.5, 132.5, 246.0, 304.5, 378.5, 197.5, -17.0, 256.0, 219.0, 188.0, 0.5, 321.0, 280.5, 132.5, 127.0, -23.5, 291.0, 167.5, 60.0, 19.5, 25.0, 120.0, 267.0, 253.0, 279.0, 56.5, 290.5, 338.0, 215.0, 476.5, -344.5, 7.0, 102.0, 7.5, -315.5, 369.5, 270.0, 199.5, 305.0, 370.0, 179.5, -863.0, 214.0, 254.5, 234.0, 321.5, 0.0, 0.0, 0.0, 282.0, 243.0, 238.0, 145.0, 135.0, -34.5, 212.0, 373.5, -178.0, 275.0, 253.5, 247.5, 145.5, 288.0, 418.5, 28.5, 132.0, 37.5, 243.0, 113.5, 457.0, 253.0, 166.5, 129.0, 121.5, 61.5, 138.0, 58.5, 31.5, 119.5, 77.0, -442.0, 334.5, 60.0, 332.5, 209.5, 364.0, 272.0, 238.5, 167.5, 363.0, 396.5, 98.5, 48.5, 147.0, 103.5, 316.5, 255.0, 2.0, 4.5, 100.0, 172.5, 152.0, 428.5, 272.5, 306.5, 392.0, 381.0, 69.5, 319.5, -9.0, 323.0, 120.0, 221.5, 253.0, 288.5, 451.5, 174.0, 248.5, -33.0, 431.5, 230.0, -113.0, 247.0, 414.5, 426.0, 172.5, 280.0, 145.5, 562.5, 270.0, 151.5, 159.0, 160.5, -615.0, 240.5, 380.0, -498.5, 361.0, 291.5, 122.0, 58.5, 85.0, 237.5, 110.0, 8.0, -6.5, -467.5, 245.5, 42.0, 148.5, 269.5, 97.5, 152.0, 134.5, 117.5, 97.0, 284.0, 342.5, -79.5, 228.0, -1315.0, 422.0, 241.5, 254.0, -531.5, 231.5, 223.5, 343.5, 382.0, 340.5, -39.0, 276.0, 347.5, 293.0, 124.5, 314.5, 289.5, 179.5, 203.0, 235.0, 266.0, -100.0, 0.0, 76.0, -3161.0, 203.0, 269.0, -20.5, 271.5, 325.5, 24.5, 220.0, 216.5, -1185.0, 355.5, 346.0, 112.5, 110.0, 219.0, 146.0, 261.5, 360.0, 203.5, 281.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.655200573879735, "mean_inference_ms": 6.594006654878556, "mean_action_processing_ms": 0.14755303694234714, "mean_env_wait_ms": 0.18123777045907652, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005142994416065705, "StateBufferConnector_ms": 0.005736840076935597, "ViewRequirementAgentConnector_ms": 0.35084039737016726}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 89.77112243519588, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 64000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 63997, "timers": {"training_iteration_time_ms": 37186.777, "sample_time_ms": 30356.431, "synch_weights_time_ms": 11.614}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 899, "training_iteration": 16, "trial_id": "96d6c_00000", "date": "2024-01-13_10-56-30", "timestamp": 1705139790, "time_this_iter_s": 44.58631658554077, "time_total_s": 596.7587659358978, "pid": 12296, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E46F2F6950>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 1, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 596.7587659358978, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 18.425, "ram_util_percent": 79.69285714285715, "gpu_util_percent0": 0.23160714285714287, "vram_util_percent0": 0.16250174386160715}}
