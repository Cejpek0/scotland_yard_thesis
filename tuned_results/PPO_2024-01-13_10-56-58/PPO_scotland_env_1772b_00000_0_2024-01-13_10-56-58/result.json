{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2946.0, "total_loss": 19.335164409572794}, "mr_x_policy": {"total_loss": 19.335164409572794, "policy_loss": -0.0630038460574539, "vf_loss": 9.66696272058002, "vf_loss_unclipped": 43780.24778204449, "vf_explained_var": 0.0006502169673725711, "entropy": 1.3215507774029749, "mean_kl_loss": 0.030559773261285953, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}, "cop_policy": {"total_loss": 9.725093663749048, "policy_loss": -0.03495803106007939, "vf_loss": 9.754985340570999, "vf_loss_unclipped": 35525.66876324153, "vf_explained_var": -0.00038047766281386553, "entropy": 1.3520322250107588, "mean_kl_loss": 0.025331882418756918, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1518.3333333337, "episode_reward_min": -1868.8333333341006, "episode_reward_mean": -40.75617283945926, "episode_len_mean": 72.48148148148148, "episode_media": {}, "episodes_this_iter": 54, "policy_reward_min": {"mr_x_policy": -1322.3333333341002, "cop_policy": -1228.5}, "policy_reward_max": {"mr_x_policy": 317.6666666652, "cop_policy": 575.5}, "policy_reward_mean": {"mr_x_policy": -104.9043209876074, "cop_policy": 22.348387096774193}, "custom_metrics": {}, "hist_stats": {"episode_reward": [521.8333333332, 3.4999999987999786, -1868.8333333341006, 0.16666666640000471, -582.1666666656998, -424.33333333340005, -1317.1666666667, 11.50000000019999, -80.8333333337, -313.8333333333, 14.499999999699938, 662.3333333329002, -591.8333333331, -513.3333333333, 434.6666666654001, -99.6666666667, 279.33333333419995, -9.8333333331, -110.50000000150007, -212.0000000005, 1518.3333333337, 900.3333333333999, -133.1666666662, 41.49999999890002, 283.83333333310003, -808.6666666664, -446.1666666661001, -738.1666666653999, -247.0000000005, 511.66666666689997, 35.33333333429994, -612.9999999995998, 96.49999999909997, 782.8333333334999, -739.5000000004, -296.8333333318001, -39.83333333109994, -42.00000000050007, 303.6666666678, -455.9999999993001, -97.0, -185.16666666679998, 333.50000000069997, 579.333333333, 571.3333333341001, 239.66666666690003, 105.83333333360011, -243.33333333349998, 251.66666666669994, 19.16666666520003, -17.833333332799995, 152.16666666729998, -99.0, 471.6666666657002], "episode_lengths": [85, 102, 133, 19, 107, 48, 131, 76, 28, 12, 36, 102, 37, 11, 92, 1, 107, 13, 90, 107, 97, 101, 25, 74, 69, 12, 36, 118, 109, 100, 92, 28, 100, 97, 106, 111, 111, 99, 109, 113, 1, 16, 99, 102, 104, 108, 99, 18, 31, 109, 34, 41, 3, 105], "policy_mr_x_policy_reward": [-104.16666666680003, 165.49999999879998, -1322.3333333341002, -24.83333333360001, -221.1666666657, -359.3333333334, -807.6666666666999, 65.00000000019999, -160.83333333369998, -117.8333333333, -254.0000000003, 211.8333333329, -782.8333333331, -113.3333333333, 8.16666666540003, -99.6666666667, -162.66666666580008, -64.8333333331, 1.4999999985000017, 44.4999999995, 246.83333333369995, -34.16666666659998, -116.6666666662, -74.00000000109999, -376.16666666689997, -108.6666666664, -460.1666666661, 199.8333333346, 25.499999999499998, 96.16666666690003, -38.166666665699985, -610.4999999996, -418.50000000089995, 143.33333333349998, -19.000000000399996, -186.83333333180002, 246.66666666889995, 22.4999999995, -18.3333333322, -972.9999999992999, -97.0, -112.66666666680001, 142.00000000069997, 176.33333333300007, 260.33333333409996, 194.66666666689997, 143.3333333336, -94.3333333335, -56.83333333330002, 317.6666666652, -97.8333333328, -46.33333333269999, -99.0, 257.16666666569995], "policy_cop_policy_reward": [337.5, -9.0, 297.5, -50.5, -284.0, 172.5, 176.5, -697.0, -26.0, 8.0, -25.0, 42.0, -79.0, 120.5, -402.5, 211.5, -344.0, 67.5, -298.0, -326.0, 114.5, -131.0, 301.5, -224.0, 80.0, 122.0, -122.0, -97.5, -198.5, 100.0, -44.5, 205.5, 107.5, 154.0, -115.5, 412.0, 143.5, 86.0, -38.5, -300.0, -100.0, 0.0, 156.0, -77.5, 348.0, 55.0, 28.5, 358.5, 18.0, 34.0, 3.0, -709.0, 317.5, 279.5, -578.0, 260.5, 61.0, 402.5, 575.5, 293.5, 263.5, 370.0, 301.0, -155.5, 15.0, 124.0, 220.5, 9.0, -114.0, 225.0, 151.0, 284.0, -300.0, -400.0, 0.0, 36.5, 62.0, -84.5, -1228.5, -135.0, 425.5, -211.5, 132.0, -193.0, -295.5, 523.0, 188.0, -230.0, 52.0, 251.5, 114.5, -76.0, -41.0, 157.5, 223.5, 134.0, 242.0, 408.0, -10.5, 202.5, -518.5, -404.5, 279.0, -393.5, 4.5, 167.0, -670.5, 217.0, -58.5, -198.5, 192.5, 320.5, 24.5, -23.0, 260.0, 155.0, 102.0, -192.5, 103.0, 17.0, 75.0, 7.0, 109.5, 38.5, 36.5, 328.0, -265.0, 404.0, 172.0, 6.5, -230.5, 269.0, -167.0, 10.0, 119.5, 38.0, 108.0, -295.0, 119.0, 121.0, 68.5, 519.5, 57.5, -875.5, 130.0, -174.0, 124.0, 133.0, 11.0, 54.5, 0.0, 0.0, 109.0, 331.5, -226.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7049501672204627, "mean_inference_ms": 6.491271891137478, "mean_action_processing_ms": 0.1612649920939565, "mean_env_wait_ms": 0.1978684711146433, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005657268020341981, "StateBufferConnector_ms": 0.004735982642983491, "ViewRequirementAgentConnector_ms": 0.37911005739895803}}, "episode_reward_max": 1518.3333333337, "episode_reward_min": -1868.8333333341006, "episode_reward_mean": -40.75617283945926, "episode_len_mean": 72.48148148148148, "episodes_this_iter": 54, "policy_reward_min": {"mr_x_policy": -1322.3333333341002, "cop_policy": -1228.5}, "policy_reward_max": {"mr_x_policy": 317.6666666652, "cop_policy": 575.5}, "policy_reward_mean": {"mr_x_policy": -104.9043209876074, "cop_policy": 22.348387096774193}, "hist_stats": {"episode_reward": [521.8333333332, 3.4999999987999786, -1868.8333333341006, 0.16666666640000471, -582.1666666656998, -424.33333333340005, -1317.1666666667, 11.50000000019999, -80.8333333337, -313.8333333333, 14.499999999699938, 662.3333333329002, -591.8333333331, -513.3333333333, 434.6666666654001, -99.6666666667, 279.33333333419995, -9.8333333331, -110.50000000150007, -212.0000000005, 1518.3333333337, 900.3333333333999, -133.1666666662, 41.49999999890002, 283.83333333310003, -808.6666666664, -446.1666666661001, -738.1666666653999, -247.0000000005, 511.66666666689997, 35.33333333429994, -612.9999999995998, 96.49999999909997, 782.8333333334999, -739.5000000004, -296.8333333318001, -39.83333333109994, -42.00000000050007, 303.6666666678, -455.9999999993001, -97.0, -185.16666666679998, 333.50000000069997, 579.333333333, 571.3333333341001, 239.66666666690003, 105.83333333360011, -243.33333333349998, 251.66666666669994, 19.16666666520003, -17.833333332799995, 152.16666666729998, -99.0, 471.6666666657002], "episode_lengths": [85, 102, 133, 19, 107, 48, 131, 76, 28, 12, 36, 102, 37, 11, 92, 1, 107, 13, 90, 107, 97, 101, 25, 74, 69, 12, 36, 118, 109, 100, 92, 28, 100, 97, 106, 111, 111, 99, 109, 113, 1, 16, 99, 102, 104, 108, 99, 18, 31, 109, 34, 41, 3, 105], "policy_mr_x_policy_reward": [-104.16666666680003, 165.49999999879998, -1322.3333333341002, -24.83333333360001, -221.1666666657, -359.3333333334, -807.6666666666999, 65.00000000019999, -160.83333333369998, -117.8333333333, -254.0000000003, 211.8333333329, -782.8333333331, -113.3333333333, 8.16666666540003, -99.6666666667, -162.66666666580008, -64.8333333331, 1.4999999985000017, 44.4999999995, 246.83333333369995, -34.16666666659998, -116.6666666662, -74.00000000109999, -376.16666666689997, -108.6666666664, -460.1666666661, 199.8333333346, 25.499999999499998, 96.16666666690003, -38.166666665699985, -610.4999999996, -418.50000000089995, 143.33333333349998, -19.000000000399996, -186.83333333180002, 246.66666666889995, 22.4999999995, -18.3333333322, -972.9999999992999, -97.0, -112.66666666680001, 142.00000000069997, 176.33333333300007, 260.33333333409996, 194.66666666689997, 143.3333333336, -94.3333333335, -56.83333333330002, 317.6666666652, -97.8333333328, -46.33333333269999, -99.0, 257.16666666569995], "policy_cop_policy_reward": [337.5, -9.0, 297.5, -50.5, -284.0, 172.5, 176.5, -697.0, -26.0, 8.0, -25.0, 42.0, -79.0, 120.5, -402.5, 211.5, -344.0, 67.5, -298.0, -326.0, 114.5, -131.0, 301.5, -224.0, 80.0, 122.0, -122.0, -97.5, -198.5, 100.0, -44.5, 205.5, 107.5, 154.0, -115.5, 412.0, 143.5, 86.0, -38.5, -300.0, -100.0, 0.0, 156.0, -77.5, 348.0, 55.0, 28.5, 358.5, 18.0, 34.0, 3.0, -709.0, 317.5, 279.5, -578.0, 260.5, 61.0, 402.5, 575.5, 293.5, 263.5, 370.0, 301.0, -155.5, 15.0, 124.0, 220.5, 9.0, -114.0, 225.0, 151.0, 284.0, -300.0, -400.0, 0.0, 36.5, 62.0, -84.5, -1228.5, -135.0, 425.5, -211.5, 132.0, -193.0, -295.5, 523.0, 188.0, -230.0, 52.0, 251.5, 114.5, -76.0, -41.0, 157.5, 223.5, 134.0, 242.0, 408.0, -10.5, 202.5, -518.5, -404.5, 279.0, -393.5, 4.5, 167.0, -670.5, 217.0, -58.5, -198.5, 192.5, 320.5, 24.5, -23.0, 260.0, 155.0, 102.0, -192.5, 103.0, 17.0, 75.0, 7.0, 109.5, 38.5, 36.5, 328.0, -265.0, 404.0, 172.0, 6.5, -230.5, 269.0, -167.0, 10.0, 119.5, 38.0, 108.0, -295.0, 119.0, 121.0, 68.5, 519.5, 57.5, -875.5, 130.0, -174.0, 124.0, 133.0, 11.0, 54.5, 0.0, 0.0, 109.0, 331.5, -226.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.7049501672204627, "mean_inference_ms": 6.491271891137478, "mean_action_processing_ms": 0.1612649920939565, "mean_env_wait_ms": 0.1978684711146433, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.005657268020341981, "StateBufferConnector_ms": 0.004735982642983491, "ViewRequirementAgentConnector_ms": 0.37911005739895803}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 110.5541513976021, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 4000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 3997, "timers": {"training_iteration_time_ms": 36181.364, "sample_time_ms": 30390.991, "synch_weights_time_ms": 15.006}, "counters": {"num_env_steps_sampled": 4000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 3997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 54, "training_iteration": 1, "trial_id": "1772b_00000", "date": "2024-01-13_10-57-52", "timestamp": 1705139872, "time_this_iter_s": 36.19759154319763, "time_total_s": 36.19759154319763, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C24670>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 36.19759154319763, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 12.649999999999999, "ram_util_percent": 69.2, "gpu_util_percent0": 0.16604166666666667, "vram_util_percent0": 0.14744737413194445}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2942.0, "total_loss": 19.26499324733928}, "mr_x_policy": {"total_loss": 19.26499324733928, "policy_loss": -0.06967185405319777, "vf_loss": 9.6276342262656, "vf_loss_unclipped": 38642.234027409955, "vf_explained_var": 0.0007475604445247326, "entropy": 1.278996075614024, "mean_kl_loss": 0.022032991407190453, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.45000001788139343}, "cop_policy": {"total_loss": 9.700421058525473, "policy_loss": -0.02405007826993084, "vf_loss": 9.719588651495465, "vf_loss_unclipped": 31990.99131024894, "vf_explained_var": -0.0027397790197598733, "entropy": 1.3390539298623294, "mean_kl_loss": 0.016275280650869858, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1518.3333333337, "episode_reward_min": -977.5000000004004, "episode_reward_mean": 112.965000000072, "episode_len_mean": 70.58, "episode_media": {}, "episodes_this_iter": 60, "policy_reward_min": {"mr_x_policy": -1157.3333333342, "cop_policy": -1602.0}, "policy_reward_max": {"mr_x_policy": 435.1666666663, "cop_policy": 575.5}, "policy_reward_mean": {"mr_x_policy": -70.26999999992799, "cop_policy": 63.18448275862069}, "custom_metrics": {}, "hist_stats": {"episode_reward": [434.6666666654001, -99.6666666667, 279.33333333419995, -9.8333333331, -110.50000000150007, -212.0000000005, 1518.3333333337, 900.3333333333999, -133.1666666662, 41.49999999890002, 283.83333333310003, -808.6666666664, -446.1666666661001, -738.1666666653999, -247.0000000005, 511.66666666689997, 35.33333333429994, -612.9999999995998, 96.49999999909997, 782.8333333334999, -739.5000000004, -296.8333333318001, -39.83333333109994, -42.00000000050007, 303.6666666678, -455.9999999993001, -97.0, -185.16666666679998, 333.50000000069997, 579.333333333, 571.3333333341001, 239.66666666690003, 105.83333333360011, -243.33333333349998, 251.66666666669994, 19.16666666520003, -17.833333332799995, 152.16666666729998, -99.0, 471.6666666657002, -762.3333333322, 263.8333333328, 379.83333333339993, 67.4999999998, 607.1666666669001, -315.33333333289994, -209.83333333319996, -147.6666666666, 369.9999999995, -4.333333333300004, 314.4999999996, 484.6666666668001, 150.3333333334, 105.66666666679998, 650.3333333344999, 293.16666666579994, 832.5000000005999, -252.5, 1.0000000004000071, -263.4999999999, 419.33333333250005, 408.66666666630005, 1127.1666666674, 1326.6666666663, -364.00000000010004, 297.83333333369995, -98.6666666667, -106.66666666649999, 31.500000000099988, 436.50000000060004, 474.66666666629993, 627.3333333324, -24.166666667699992, 711.8333333331001, 650.1666666660001, 14.5, -513.8333333323999, -977.5000000004004, 244.83333333350004, 28.166666666899985, -114.33333333290003, -66.4999999999, 7.666666666799983, 95.99999999970001, 67.83333333439998, 270.3333333334, 753.0000000002, 504.1666666671, -271.6666666671, -370.3333333339, -20.833333333599924, 119.50000000140001, -76.33333333309999, -8.500000000100009, 828.1666666672002, -409.83333333419995, 830.8333333334999, -214.1666666667, -98.3333333331, -87.1666666667], "episode_lengths": [92, 1, 107, 13, 90, 107, 97, 101, 25, 74, 69, 12, 36, 118, 109, 100, 92, 28, 100, 97, 106, 111, 111, 99, 109, 113, 1, 16, 99, 102, 104, 108, 99, 18, 31, 109, 34, 41, 3, 105, 110, 104, 98, 17, 102, 21, 102, 62, 98, 27, 99, 93, 37, 25, 96, 46, 97, 12, 19, 16, 100, 102, 96, 100, 22, 102, 1, 5, 62, 99, 100, 98, 104, 97, 102, 30, 112, 113, 30, 34, 39, 27, 22, 39, 106, 98, 98, 46, 44, 54, 103, 80, 27, 102, 98, 109, 101, 11, 7, 70], "policy_mr_x_policy_reward": [8.16666666540003, -99.6666666667, -162.66666666580008, -64.8333333331, 1.4999999985000017, 44.4999999995, 246.83333333369995, -34.16666666659998, -116.6666666662, -74.00000000109999, -376.16666666689997, -108.6666666664, -460.1666666661, 199.8333333346, 25.499999999499998, 96.16666666690003, -38.166666665699985, -610.4999999996, -418.50000000089995, 143.33333333349998, -19.000000000399996, -186.83333333180002, 246.66666666889995, 22.4999999995, -18.3333333322, -972.9999999992999, -97.0, -112.66666666680001, 142.00000000069997, 176.33333333300007, 260.33333333409996, 194.66666666689997, 143.3333333336, -94.3333333335, -56.83333333330002, 317.6666666652, -97.8333333328, -46.33333333269999, -99.0, 257.16666666569995, -490.3333333321999, -77.1666666672, 71.33333333340002, -98.5000000002, 47.666666666900014, -500.83333333289994, -53.33333333319999, -67.16666666660001, -41.50000000050003, -71.3333333333, 175.4999999996, 106.66666666679998, -118.16666666660001, -108.8333333332, -270.1666666655, -125.8333333342, -131.49999999940007, -163.5, -22.999999999599993, -95.9999999999, -147.66666666750004, 30.666666666299985, 44.16666666739996, 435.1666666663, -128.0000000001, 281.83333333369995, -98.6666666667, -106.66666666649999, -100.4999999999, 59.5000000006, 54.666666666299996, -242.66666666759994, 106.33333333229999, 154.83333333309997, -68.33333333400003, -108.5, -1012.3333333323998, 213.9999999996, 8.833333333499994, -70.3333333331, -225.3333333329, -84.99999999990001, -86.3333333332, -140.5000000003, -63.16666666559998, 89.3333333334, 82.50000000019998, -3.333333332899997, -91.6666666671, -381.3333333339001, 153.16666666640003, -46.499999998599975, -195.83333333309997, 152.49999999989998, -21.833333332800024, -1157.3333333342, 57.333333333499986, -118.1666666667, -98.3333333331, -278.6666666667], "policy_cop_policy_reward": [156.0, -77.5, 348.0, 55.0, 28.5, 358.5, 18.0, 34.0, 3.0, -709.0, 317.5, 279.5, -578.0, 260.5, 61.0, 402.5, 575.5, 293.5, 263.5, 370.0, 301.0, -155.5, 15.0, 124.0, 220.5, 9.0, -114.0, 225.0, 151.0, 284.0, -300.0, -400.0, 0.0, 36.5, 62.0, -84.5, -1228.5, -135.0, 425.5, -211.5, 132.0, -193.0, -295.5, 523.0, 188.0, -230.0, 52.0, 251.5, 114.5, -76.0, -41.0, 157.5, 223.5, 134.0, 242.0, 408.0, -10.5, 202.5, -518.5, -404.5, 279.0, -393.5, 4.5, 167.0, -670.5, 217.0, -58.5, -198.5, 192.5, 320.5, 24.5, -23.0, 260.0, 155.0, 102.0, -192.5, 103.0, 17.0, 75.0, 7.0, 109.5, 38.5, 36.5, 328.0, -265.0, 404.0, 172.0, 6.5, -230.5, 269.0, -167.0, 10.0, 119.5, 38.0, 108.0, -295.0, 119.0, 121.0, 68.5, 519.5, 57.5, -875.5, 130.0, -174.0, 124.0, 133.0, 11.0, 54.5, 0.0, 0.0, 109.0, 331.5, -226.0, -364.0, -73.5, 165.5, -294.0, 356.0, 279.0, -46.5, 271.0, 84.0, 30.0, 114.0, 22.0, 309.5, 422.0, -172.0, 45.0, 110.5, 30.0, -180.0, 188.5, -165.0, -56.0, -118.0, 93.5, 7.5, 146.0, 258.0, -32.5, 46.5, 53.0, -151.5, 75.5, 215.0, 31.0, 305.5, 41.5, 81.0, 44.0, 143.5, 132.0, 25.5, 57.0, 221.0, 437.5, 262.0, 116.0, 111.5, 191.5, 248.5, 264.5, 451.0, 6.0, 5.0, -100.0, 112.5, 52.5, -141.0, -279.5, 6.5, 105.5, 246.5, 261.5, 59.0, -271.5, 400.0, 249.5, 365.5, 345.0, 372.5, 188.5, 477.0, 226.0, 115.0, 31.0, -382.0, -308.5, 152.0, 172.5, 0.0, 0.0, 0.0, 72.0, 169.0, -109.0, -69.0, 236.5, 209.5, 25.0, 116.0, 279.0, 339.5, 266.0, 264.5, 108.5, 53.5, -292.5, 360.0, 134.5, 62.5, 431.5, 326.0, -39.0, -58.5, 135.0, 46.5, -39.5, 226.5, 311.5, 226.5, -1602.0, 184.0, -22.0, 128.5, 129.5, -108.0, 52.0, 154.5, -36.0, 45.0, 102.0, 62.0, 128.5, -172.0, -60.5, 119.5, 35.0, 131.0, 45.0, 60.5, -9.5, 288.5, -148.0, 166.0, -194.5, 209.5, 258.5, 28.0, 384.0, 246.0, 56.5, 205.0, 78.0, 175.5, -433.5, 156.5, 78.5, -224.0, 270.0, 211.5, -655.5, 205.0, 47.0, -86.0, -62.0, 62.5, 119.0, -333.5, -31.5, 204.0, 248.0, 354.0, 248.0, 201.5, 263.0, 283.0, 316.0, 326.0, 131.5, -198.0, 2.0, 100.0, 0.0, 0.0, 0.0, -176.0, 103.0, 264.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6710888963650216, "mean_inference_ms": 6.4204933867407705, "mean_action_processing_ms": 0.15473131096610218, "mean_env_wait_ms": 0.18585385394778917, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061070253401238304, "StateBufferConnector_ms": 0.005132413757634042, "ViewRequirementAgentConnector_ms": 0.3455382313220029}}, "episode_reward_max": 1518.3333333337, "episode_reward_min": -977.5000000004004, "episode_reward_mean": 112.965000000072, "episode_len_mean": 70.58, "episodes_this_iter": 60, "policy_reward_min": {"mr_x_policy": -1157.3333333342, "cop_policy": -1602.0}, "policy_reward_max": {"mr_x_policy": 435.1666666663, "cop_policy": 575.5}, "policy_reward_mean": {"mr_x_policy": -70.26999999992799, "cop_policy": 63.18448275862069}, "hist_stats": {"episode_reward": [434.6666666654001, -99.6666666667, 279.33333333419995, -9.8333333331, -110.50000000150007, -212.0000000005, 1518.3333333337, 900.3333333333999, -133.1666666662, 41.49999999890002, 283.83333333310003, -808.6666666664, -446.1666666661001, -738.1666666653999, -247.0000000005, 511.66666666689997, 35.33333333429994, -612.9999999995998, 96.49999999909997, 782.8333333334999, -739.5000000004, -296.8333333318001, -39.83333333109994, -42.00000000050007, 303.6666666678, -455.9999999993001, -97.0, -185.16666666679998, 333.50000000069997, 579.333333333, 571.3333333341001, 239.66666666690003, 105.83333333360011, -243.33333333349998, 251.66666666669994, 19.16666666520003, -17.833333332799995, 152.16666666729998, -99.0, 471.6666666657002, -762.3333333322, 263.8333333328, 379.83333333339993, 67.4999999998, 607.1666666669001, -315.33333333289994, -209.83333333319996, -147.6666666666, 369.9999999995, -4.333333333300004, 314.4999999996, 484.6666666668001, 150.3333333334, 105.66666666679998, 650.3333333344999, 293.16666666579994, 832.5000000005999, -252.5, 1.0000000004000071, -263.4999999999, 419.33333333250005, 408.66666666630005, 1127.1666666674, 1326.6666666663, -364.00000000010004, 297.83333333369995, -98.6666666667, -106.66666666649999, 31.500000000099988, 436.50000000060004, 474.66666666629993, 627.3333333324, -24.166666667699992, 711.8333333331001, 650.1666666660001, 14.5, -513.8333333323999, -977.5000000004004, 244.83333333350004, 28.166666666899985, -114.33333333290003, -66.4999999999, 7.666666666799983, 95.99999999970001, 67.83333333439998, 270.3333333334, 753.0000000002, 504.1666666671, -271.6666666671, -370.3333333339, -20.833333333599924, 119.50000000140001, -76.33333333309999, -8.500000000100009, 828.1666666672002, -409.83333333419995, 830.8333333334999, -214.1666666667, -98.3333333331, -87.1666666667], "episode_lengths": [92, 1, 107, 13, 90, 107, 97, 101, 25, 74, 69, 12, 36, 118, 109, 100, 92, 28, 100, 97, 106, 111, 111, 99, 109, 113, 1, 16, 99, 102, 104, 108, 99, 18, 31, 109, 34, 41, 3, 105, 110, 104, 98, 17, 102, 21, 102, 62, 98, 27, 99, 93, 37, 25, 96, 46, 97, 12, 19, 16, 100, 102, 96, 100, 22, 102, 1, 5, 62, 99, 100, 98, 104, 97, 102, 30, 112, 113, 30, 34, 39, 27, 22, 39, 106, 98, 98, 46, 44, 54, 103, 80, 27, 102, 98, 109, 101, 11, 7, 70], "policy_mr_x_policy_reward": [8.16666666540003, -99.6666666667, -162.66666666580008, -64.8333333331, 1.4999999985000017, 44.4999999995, 246.83333333369995, -34.16666666659998, -116.6666666662, -74.00000000109999, -376.16666666689997, -108.6666666664, -460.1666666661, 199.8333333346, 25.499999999499998, 96.16666666690003, -38.166666665699985, -610.4999999996, -418.50000000089995, 143.33333333349998, -19.000000000399996, -186.83333333180002, 246.66666666889995, 22.4999999995, -18.3333333322, -972.9999999992999, -97.0, -112.66666666680001, 142.00000000069997, 176.33333333300007, 260.33333333409996, 194.66666666689997, 143.3333333336, -94.3333333335, -56.83333333330002, 317.6666666652, -97.8333333328, -46.33333333269999, -99.0, 257.16666666569995, -490.3333333321999, -77.1666666672, 71.33333333340002, -98.5000000002, 47.666666666900014, -500.83333333289994, -53.33333333319999, -67.16666666660001, -41.50000000050003, -71.3333333333, 175.4999999996, 106.66666666679998, -118.16666666660001, -108.8333333332, -270.1666666655, -125.8333333342, -131.49999999940007, -163.5, -22.999999999599993, -95.9999999999, -147.66666666750004, 30.666666666299985, 44.16666666739996, 435.1666666663, -128.0000000001, 281.83333333369995, -98.6666666667, -106.66666666649999, -100.4999999999, 59.5000000006, 54.666666666299996, -242.66666666759994, 106.33333333229999, 154.83333333309997, -68.33333333400003, -108.5, -1012.3333333323998, 213.9999999996, 8.833333333499994, -70.3333333331, -225.3333333329, -84.99999999990001, -86.3333333332, -140.5000000003, -63.16666666559998, 89.3333333334, 82.50000000019998, -3.333333332899997, -91.6666666671, -381.3333333339001, 153.16666666640003, -46.499999998599975, -195.83333333309997, 152.49999999989998, -21.833333332800024, -1157.3333333342, 57.333333333499986, -118.1666666667, -98.3333333331, -278.6666666667], "policy_cop_policy_reward": [156.0, -77.5, 348.0, 55.0, 28.5, 358.5, 18.0, 34.0, 3.0, -709.0, 317.5, 279.5, -578.0, 260.5, 61.0, 402.5, 575.5, 293.5, 263.5, 370.0, 301.0, -155.5, 15.0, 124.0, 220.5, 9.0, -114.0, 225.0, 151.0, 284.0, -300.0, -400.0, 0.0, 36.5, 62.0, -84.5, -1228.5, -135.0, 425.5, -211.5, 132.0, -193.0, -295.5, 523.0, 188.0, -230.0, 52.0, 251.5, 114.5, -76.0, -41.0, 157.5, 223.5, 134.0, 242.0, 408.0, -10.5, 202.5, -518.5, -404.5, 279.0, -393.5, 4.5, 167.0, -670.5, 217.0, -58.5, -198.5, 192.5, 320.5, 24.5, -23.0, 260.0, 155.0, 102.0, -192.5, 103.0, 17.0, 75.0, 7.0, 109.5, 38.5, 36.5, 328.0, -265.0, 404.0, 172.0, 6.5, -230.5, 269.0, -167.0, 10.0, 119.5, 38.0, 108.0, -295.0, 119.0, 121.0, 68.5, 519.5, 57.5, -875.5, 130.0, -174.0, 124.0, 133.0, 11.0, 54.5, 0.0, 0.0, 109.0, 331.5, -226.0, -364.0, -73.5, 165.5, -294.0, 356.0, 279.0, -46.5, 271.0, 84.0, 30.0, 114.0, 22.0, 309.5, 422.0, -172.0, 45.0, 110.5, 30.0, -180.0, 188.5, -165.0, -56.0, -118.0, 93.5, 7.5, 146.0, 258.0, -32.5, 46.5, 53.0, -151.5, 75.5, 215.0, 31.0, 305.5, 41.5, 81.0, 44.0, 143.5, 132.0, 25.5, 57.0, 221.0, 437.5, 262.0, 116.0, 111.5, 191.5, 248.5, 264.5, 451.0, 6.0, 5.0, -100.0, 112.5, 52.5, -141.0, -279.5, 6.5, 105.5, 246.5, 261.5, 59.0, -271.5, 400.0, 249.5, 365.5, 345.0, 372.5, 188.5, 477.0, 226.0, 115.0, 31.0, -382.0, -308.5, 152.0, 172.5, 0.0, 0.0, 0.0, 72.0, 169.0, -109.0, -69.0, 236.5, 209.5, 25.0, 116.0, 279.0, 339.5, 266.0, 264.5, 108.5, 53.5, -292.5, 360.0, 134.5, 62.5, 431.5, 326.0, -39.0, -58.5, 135.0, 46.5, -39.5, 226.5, 311.5, 226.5, -1602.0, 184.0, -22.0, 128.5, 129.5, -108.0, 52.0, 154.5, -36.0, 45.0, 102.0, 62.0, 128.5, -172.0, -60.5, 119.5, 35.0, 131.0, 45.0, 60.5, -9.5, 288.5, -148.0, 166.0, -194.5, 209.5, 258.5, 28.0, 384.0, 246.0, 56.5, 205.0, 78.0, 175.5, -433.5, 156.5, 78.5, -224.0, 270.0, 211.5, -655.5, 205.0, 47.0, -86.0, -62.0, 62.5, 119.0, -333.5, -31.5, 204.0, 248.0, 354.0, 248.0, 201.5, 263.0, 283.0, 316.0, 326.0, 131.5, -198.0, 2.0, 100.0, 0.0, 0.0, 0.0, -176.0, 103.0, 264.5]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6710888963650216, "mean_inference_ms": 6.4204933867407705, "mean_action_processing_ms": 0.15473131096610218, "mean_env_wait_ms": 0.18585385394778917, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0061070253401238304, "StateBufferConnector_ms": 0.005132413757634042, "ViewRequirementAgentConnector_ms": 0.3455382313220029}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 116.42680176674443, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 8000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 7997, "timers": {"training_iteration_time_ms": 35268.857, "sample_time_ms": 29541.948, "synch_weights_time_ms": 12.131}, "counters": {"num_env_steps_sampled": 8000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 7997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 114, "training_iteration": 2, "trial_id": "1772b_00000", "date": "2024-01-13_10-58-27", "timestamp": 1705139907, "time_this_iter_s": 34.372416973114014, "time_total_s": 70.57000851631165, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BABE20>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 70.57000851631165, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 6.920000000000001, "ram_util_percent": 59.048888888888875, "gpu_util_percent0": 0.31666666666666665, "vram_util_percent0": 0.14729817708333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 2959.0, "total_loss": 19.078687699635825}, "mr_x_policy": {"total_loss": 19.078687699635825, "policy_loss": -0.0754417602729518, "vf_loss": 9.538293409347535, "vf_loss_unclipped": 14628.27109375, "vf_explained_var": -5.8468182881673174e-05, "entropy": 1.2822809020678203, "mean_kl_loss": 0.021206596305273707, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.675000011920929}, "cop_policy": {"total_loss": 9.60629301071167, "policy_loss": -0.03487601050486167, "vf_loss": 9.636030737559, "vf_loss_unclipped": 19129.639274088542, "vf_explained_var": -0.004655584692955017, "entropy": 1.3248882015546164, "mean_kl_loss": 0.017127894337681936, "default_optimizer_lr": 0.0003000000000000001, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1326.6666666663, "episode_reward_min": -977.5000000004004, "episode_reward_mean": 173.41333333333205, "episode_len_mean": 66.41, "episode_media": {}, "episodes_this_iter": 61, "policy_reward_min": {"cop_policy": -1602.0, "mr_x_policy": -1157.3333333342}, "policy_reward_max": {"cop_policy": 477.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 81.87244897959184, "mr_x_policy": -67.29166666666802}, "custom_metrics": {}, "hist_stats": {"episode_reward": [408.66666666630005, 1127.1666666674, 1326.6666666663, -364.00000000010004, 297.83333333369995, -98.6666666667, -106.66666666649999, 31.500000000099988, 436.50000000060004, 474.66666666629993, 627.3333333324, -24.166666667699992, 711.8333333331001, 650.1666666660001, 14.5, -513.8333333323999, -977.5000000004004, 244.83333333350004, 28.166666666899985, -114.33333333290003, -66.4999999999, 7.666666666799983, 95.99999999970001, 67.83333333439998, 270.3333333334, 753.0000000002, 504.1666666671, -271.6666666671, -370.3333333339, -20.833333333599924, 119.50000000140001, -76.33333333309999, -8.500000000100009, 828.1666666672002, -409.83333333419995, 830.8333333334999, -214.1666666667, -98.3333333331, -87.1666666667, -549.6666666666, 29.833333333699983, 336.333333334, 456.66666666670005, 691.9999999995999, -96.0, -15.500000000199943, 485.0000000000999, -105.33333333329999, 361.6666666665, 177.16666666730003, 133.99999999989998, -62.49999999900002, 59.166666666100014, 64.99999999990001, 770.5000000002, -96.66666666639998, -294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322], "episode_lengths": [102, 96, 100, 22, 102, 1, 5, 62, 99, 100, 98, 104, 97, 102, 30, 112, 113, 30, 34, 39, 27, 22, 39, 106, 98, 98, 46, 44, 54, 103, 80, 27, 102, 98, 109, 101, 11, 7, 70, 30, 30, 72, 102, 96, 1, 101, 99, 5, 47, 25, 24, 106, 66, 13, 94, 17, 7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102], "policy_cop_policy_reward": [-271.5, 400.0, 249.5, 365.5, 345.0, 372.5, 188.5, 477.0, 226.0, 115.0, 31.0, -382.0, -308.5, 152.0, 172.5, 0.0, 0.0, 0.0, 72.0, 169.0, -109.0, -69.0, 236.5, 209.5, 25.0, 116.0, 279.0, 339.5, 266.0, 264.5, 108.5, 53.5, -292.5, 360.0, 134.5, 62.5, 431.5, 326.0, -39.0, -58.5, 135.0, 46.5, -39.5, 226.5, 311.5, 226.5, -1602.0, 184.0, -22.0, 128.5, 129.5, -108.0, 52.0, 154.5, -36.0, 45.0, 102.0, 62.0, 128.5, -172.0, -60.5, 119.5, 35.0, 131.0, 45.0, 60.5, -9.5, 288.5, -148.0, 166.0, -194.5, 209.5, 258.5, 28.0, 384.0, 246.0, 56.5, 205.0, 78.0, 175.5, -433.5, 156.5, 78.5, -224.0, 270.0, 211.5, -655.5, 205.0, 47.0, -86.0, -62.0, 62.5, 119.0, -333.5, -31.5, 204.0, 248.0, 354.0, 248.0, 201.5, 263.0, 283.0, 316.0, 326.0, 131.5, -198.0, 2.0, 100.0, 0.0, 0.0, 0.0, -176.0, 103.0, 264.5, -485.0, 42.0, 30.0, 7.0, 30.5, 45.0, 249.5, 179.0, 189.0, 40.0, 235.0, 111.0, 150.5, 156.0, 213.5, 112.0, 56.0, -308.5, 271.0, 172.5, 275.0, 0.0, 0.0, 0.0, 157.5, 201.0, 61.0, 123.0, 94.5, 39.5, 72.0, 30.0, 123.0, -148.0, 437.5, -17.5, -201.0, 173.0, 106.0, 19.5, 105.0, 23.5, 220.5, 48.5, 323.0, -82.0, 11.5, 106.0, -200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5], "policy_mr_x_policy_reward": [30.666666666299985, 44.16666666739996, 435.1666666663, -128.0000000001, 281.83333333369995, -98.6666666667, -106.66666666649999, -100.4999999999, 59.5000000006, 54.666666666299996, -242.66666666759994, 106.33333333229999, 154.83333333309997, -68.33333333400003, -108.5, -1012.3333333323998, 213.9999999996, 8.833333333499994, -70.3333333331, -225.3333333329, -84.99999999990001, -86.3333333332, -140.5000000003, -63.16666666559998, 89.3333333334, 82.50000000019998, -3.333333332899997, -91.6666666671, -381.3333333339001, 153.16666666640003, -46.499999998599975, -195.83333333309997, 152.49999999989998, -21.833333332800024, -1157.3333333342, 57.333333333499986, -118.1666666667, -98.3333333331, -278.6666666667, -136.6666666666, -52.666666666299996, -281.166666666, 70.6666666667, 171.99999999960002, -96.0, 124.99999999980001, -233.4999999999, -105.33333333329999, -57.83333333349999, -79.8333333327, -91.0000000001, -334.49999999900007, -18.833333333900015, -83.0000000001, 178.50000000020003, -132.1666666664, -94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6393642694483842, "mean_inference_ms": 6.274036617339846, "mean_action_processing_ms": 0.1448578318295447, "mean_env_wait_ms": 0.1738630634281478, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035382280446062185, "StateBufferConnector_ms": 0.003603251293452099, "ViewRequirementAgentConnector_ms": 0.31532265923239966}}, "episode_reward_max": 1326.6666666663, "episode_reward_min": -977.5000000004004, "episode_reward_mean": 173.41333333333205, "episode_len_mean": 66.41, "episodes_this_iter": 61, "policy_reward_min": {"cop_policy": -1602.0, "mr_x_policy": -1157.3333333342}, "policy_reward_max": {"cop_policy": 477.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 81.87244897959184, "mr_x_policy": -67.29166666666802}, "hist_stats": {"episode_reward": [408.66666666630005, 1127.1666666674, 1326.6666666663, -364.00000000010004, 297.83333333369995, -98.6666666667, -106.66666666649999, 31.500000000099988, 436.50000000060004, 474.66666666629993, 627.3333333324, -24.166666667699992, 711.8333333331001, 650.1666666660001, 14.5, -513.8333333323999, -977.5000000004004, 244.83333333350004, 28.166666666899985, -114.33333333290003, -66.4999999999, 7.666666666799983, 95.99999999970001, 67.83333333439998, 270.3333333334, 753.0000000002, 504.1666666671, -271.6666666671, -370.3333333339, -20.833333333599924, 119.50000000140001, -76.33333333309999, -8.500000000100009, 828.1666666672002, -409.83333333419995, 830.8333333334999, -214.1666666667, -98.3333333331, -87.1666666667, -549.6666666666, 29.833333333699983, 336.333333334, 456.66666666670005, 691.9999999995999, -96.0, -15.500000000199943, 485.0000000000999, -105.33333333329999, 361.6666666665, 177.16666666730003, 133.99999999989998, -62.49999999900002, 59.166666666100014, 64.99999999990001, 770.5000000002, -96.66666666639998, -294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322], "episode_lengths": [102, 96, 100, 22, 102, 1, 5, 62, 99, 100, 98, 104, 97, 102, 30, 112, 113, 30, 34, 39, 27, 22, 39, 106, 98, 98, 46, 44, 54, 103, 80, 27, 102, 98, 109, 101, 11, 7, 70, 30, 30, 72, 102, 96, 1, 101, 99, 5, 47, 25, 24, 106, 66, 13, 94, 17, 7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102], "policy_cop_policy_reward": [-271.5, 400.0, 249.5, 365.5, 345.0, 372.5, 188.5, 477.0, 226.0, 115.0, 31.0, -382.0, -308.5, 152.0, 172.5, 0.0, 0.0, 0.0, 72.0, 169.0, -109.0, -69.0, 236.5, 209.5, 25.0, 116.0, 279.0, 339.5, 266.0, 264.5, 108.5, 53.5, -292.5, 360.0, 134.5, 62.5, 431.5, 326.0, -39.0, -58.5, 135.0, 46.5, -39.5, 226.5, 311.5, 226.5, -1602.0, 184.0, -22.0, 128.5, 129.5, -108.0, 52.0, 154.5, -36.0, 45.0, 102.0, 62.0, 128.5, -172.0, -60.5, 119.5, 35.0, 131.0, 45.0, 60.5, -9.5, 288.5, -148.0, 166.0, -194.5, 209.5, 258.5, 28.0, 384.0, 246.0, 56.5, 205.0, 78.0, 175.5, -433.5, 156.5, 78.5, -224.0, 270.0, 211.5, -655.5, 205.0, 47.0, -86.0, -62.0, 62.5, 119.0, -333.5, -31.5, 204.0, 248.0, 354.0, 248.0, 201.5, 263.0, 283.0, 316.0, 326.0, 131.5, -198.0, 2.0, 100.0, 0.0, 0.0, 0.0, -176.0, 103.0, 264.5, -485.0, 42.0, 30.0, 7.0, 30.5, 45.0, 249.5, 179.0, 189.0, 40.0, 235.0, 111.0, 150.5, 156.0, 213.5, 112.0, 56.0, -308.5, 271.0, 172.5, 275.0, 0.0, 0.0, 0.0, 157.5, 201.0, 61.0, 123.0, 94.5, 39.5, 72.0, 30.0, 123.0, -148.0, 437.5, -17.5, -201.0, 173.0, 106.0, 19.5, 105.0, 23.5, 220.5, 48.5, 323.0, -82.0, 11.5, 106.0, -200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5], "policy_mr_x_policy_reward": [30.666666666299985, 44.16666666739996, 435.1666666663, -128.0000000001, 281.83333333369995, -98.6666666667, -106.66666666649999, -100.4999999999, 59.5000000006, 54.666666666299996, -242.66666666759994, 106.33333333229999, 154.83333333309997, -68.33333333400003, -108.5, -1012.3333333323998, 213.9999999996, 8.833333333499994, -70.3333333331, -225.3333333329, -84.99999999990001, -86.3333333332, -140.5000000003, -63.16666666559998, 89.3333333334, 82.50000000019998, -3.333333332899997, -91.6666666671, -381.3333333339001, 153.16666666640003, -46.499999998599975, -195.83333333309997, 152.49999999989998, -21.833333332800024, -1157.3333333342, 57.333333333499986, -118.1666666667, -98.3333333331, -278.6666666667, -136.6666666666, -52.666666666299996, -281.166666666, 70.6666666667, 171.99999999960002, -96.0, 124.99999999980001, -233.4999999999, -105.33333333329999, -57.83333333349999, -79.8333333327, -91.0000000001, -334.49999999900007, -18.833333333900015, -83.0000000001, 178.50000000020003, -132.1666666664, -94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.6393642694483842, "mean_inference_ms": 6.274036617339846, "mean_action_processing_ms": 0.1448578318295447, "mean_env_wait_ms": 0.1738630634281478, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0035382280446062185, "StateBufferConnector_ms": 0.003603251293452099, "ViewRequirementAgentConnector_ms": 0.31532265923239966}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 121.78765335468363, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 12000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 11997, "timers": {"training_iteration_time_ms": 34460.589, "sample_time_ms": 28753.946, "synch_weights_time_ms": 11.148}, "counters": {"num_env_steps_sampled": 12000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 11997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 175, "training_iteration": 3, "trial_id": "1772b_00000", "date": "2024-01-13_10-58-59", "timestamp": 1705139939, "time_this_iter_s": 32.85714244842529, "time_total_s": 103.42715096473694, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C255A0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 103.42715096473694, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 7.3860465116279075, "ram_util_percent": 60.17209302325582, "gpu_util_percent0": 0.22093023255813954, "vram_util_percent0": 0.14729817708333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 1000.0, "num_env_steps_trained": 3015.0, "total_loss": 19.185678388251635}, "mr_x_policy": {"total_loss": 19.185678388251635, "policy_loss": -0.07849070734390226, "vf_loss": 9.533878107539943, "vf_loss_unclipped": 20905.762343109633, "vf_explained_var": -0.007286048326335969, "entropy": 1.2340468520023784, "mean_kl_loss": 0.020772656939646025, "default_optimizer_lr": 0.00030000000000000014, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0125000476837158}, "cop_policy": {"total_loss": 9.716269727613104, "policy_loss": -0.003031056412480405, "vf_loss": 9.715458916836097, "vf_loss_unclipped": 3312019.238633453, "vf_explained_var": 0.00020019245929405336, "entropy": 1.3249664990628351, "mean_kl_loss": 0.012806617842842137, "default_optimizer_lr": 0.00030000000000000014, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.30000001192092896}}, "num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 56, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 56, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 121.89478362577654, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 16000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 15997, "timers": {"training_iteration_time_ms": 34048.988, "sample_time_ms": 28332.368, "synch_weights_time_ms": 10.404}, "counters": {"num_env_steps_sampled": 16000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 15997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 4, "trial_id": "1772b_00000", "date": "2024-01-13_10-59-32", "timestamp": 1705139972, "time_this_iter_s": 32.82939386367798, "time_total_s": 136.25654482841492, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27A30>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 136.25654482841492, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 6.630232558139534, "ram_util_percent": 59.96976744186045, "gpu_util_percent0": 0.24720930232558141, "vram_util_percent0": 0.14729817708333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 10.000932478904724}, "cop_policy": {"total_loss": 10.000932478904724, "policy_loss": 0.0007915731540151683, "vf_loss": 10.0, "vf_loss_unclipped": 70497339.9, "vf_explained_var": -9.864568710327149e-07, "entropy": 1.338139459490776, "mean_kl_loss": 0.0004698761818417552, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 134.45907450903556, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 20000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 19997, "timers": {"training_iteration_time_ms": 33188.956, "sample_time_ms": 27846.464, "synch_weights_time_ms": 9.326}, "counters": {"num_env_steps_sampled": 20000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 19997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 5, "trial_id": "1772b_00000", "date": "2024-01-13_11-00-02", "timestamp": 1705140002, "time_this_iter_s": 29.756826639175415, "time_total_s": 166.01337146759033, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27EB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 166.01337146759033, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 5.897435897435897, "ram_util_percent": 59.81282051282053, "gpu_util_percent0": 0.24025641025641029, "vram_util_percent0": 0.1472981770833333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997252595424651}, "cop_policy": {"total_loss": 9.997252595424651, "policy_loss": -0.004615693397909126, "vf_loss": 10.0, "vf_loss_unclipped": 70497706.4, "vf_explained_var": -8.672475814819336e-07, "entropy": 1.3729297637939453, "mean_kl_loss": 0.012455421529013222, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.86154998576318, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 24000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 23997, "timers": {"training_iteration_time_ms": 33411.458, "sample_time_ms": 28293.991, "synch_weights_time_ms": 8.603}, "counters": {"num_env_steps_sampled": 24000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 23997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 6, "trial_id": "1772b_00000", "date": "2024-01-13_11-00-37", "timestamp": 1705140037, "time_this_iter_s": 34.53298211097717, "time_total_s": 200.5463535785675, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C251B0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 200.5463535785675, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 10.435555555555556, "ram_util_percent": 62.14222222222224, "gpu_util_percent0": 0.3226666666666667, "vram_util_percent0": 0.1470015914351852}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999148416519166}, "cop_policy": {"total_loss": 9.999148416519166, "policy_loss": -0.002255981352300296, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3598980501294136, "mean_kl_loss": 0.009362333440935799, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.98019828834184, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 28000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 27997, "timers": {"training_iteration_time_ms": 33174.252, "sample_time_ms": 28259.019, "synch_weights_time_ms": 7.968}, "counters": {"num_env_steps_sampled": 28000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 27997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 7, "trial_id": "1772b_00000", "date": "2024-01-13_11-01-09", "timestamp": 1705140069, "time_this_iter_s": 31.760152339935303, "time_total_s": 232.3065059185028, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BA93F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 232.3065059185028, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 9.558536585365854, "ram_util_percent": 67.12926829268292, "gpu_util_percent0": 0.29219512195121955, "vram_util_percent0": 0.14615885416666666}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998909485340118}, "cop_policy": {"total_loss": 9.998909485340118, "policy_loss": -0.002763630190565891, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.372436448931694, "mean_kl_loss": 0.0111536307233564, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.19052885636553, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 32000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 31997, "timers": {"training_iteration_time_ms": 33086.224, "sample_time_ms": 28310.527, "synch_weights_time_ms": 7.592}, "counters": {"num_env_steps_sampled": 32000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 31997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 8, "trial_id": "1772b_00000", "date": "2024-01-13_11-01-41", "timestamp": 1705140101, "time_this_iter_s": 32.478029012680054, "time_total_s": 264.78453493118286, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9360>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 264.78453493118286, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 6.9581395348837205, "ram_util_percent": 67.02093023255816, "gpu_util_percent0": 0.28906976744186047, "vram_util_percent0": 0.14615885416666669}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996377694606782}, "cop_policy": {"total_loss": 9.996377694606782, "policy_loss": -0.005870060360030039, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.355484952032566, "mean_kl_loss": 0.014985308592576985, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.8434092038717, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 36000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 35997, "timers": {"training_iteration_time_ms": 32998.739, "sample_time_ms": 28303.524, "synch_weights_time_ms": 7.576}, "counters": {"num_env_steps_sampled": 36000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 35997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 9, "trial_id": "1772b_00000", "date": "2024-01-13_11-02-13", "timestamp": 1705140133, "time_this_iter_s": 32.30684947967529, "time_total_s": 297.09138441085815, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C25000>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 297.09138441085815, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 9.823809523809524, "ram_util_percent": 67.60714285714285, "gpu_util_percent0": 0.24547619047619046, "vram_util_percent0": 0.1482669890873016}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99906940460205}, "cop_policy": {"total_loss": 9.99906940460205, "policy_loss": -0.0024582058794294427, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3757221072912216, "mean_kl_loss": 0.010182590861904827, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.26020443528152, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 40000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 39997, "timers": {"training_iteration_time_ms": 32892.217, "sample_time_ms": 28233.881, "synch_weights_time_ms": 7.619}, "counters": {"num_env_steps_sampled": 40000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 39997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 10, "trial_id": "1772b_00000", "date": "2024-01-13_11-02-45", "timestamp": 1705140165, "time_this_iter_s": 31.943526029586792, "time_total_s": 329.03491044044495, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC92D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 329.03491044044495, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 9.085714285714285, "ram_util_percent": 57.38333333333333, "gpu_util_percent0": 0.2219047619047619, "vram_util_percent0": 0.14876302083333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.995447158813477}, "cop_policy": {"total_loss": 9.995447158813477, "policy_loss": -0.006781651963228797, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3504102751612663, "mean_kl_loss": 0.014858798924245775, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.64973489947342, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 44000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 43997, "timers": {"training_iteration_time_ms": 32457.534, "sample_time_ms": 27914.724, "synch_weights_time_ms": 6.615}, "counters": {"num_env_steps_sampled": 44000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 43997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 11, "trial_id": "1772b_00000", "date": "2024-01-13_11-03-17", "timestamp": 1705140197, "time_this_iter_s": 31.843555450439453, "time_total_s": 360.8784658908844, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9FC0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 360.8784658908844, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 7.7785714285714285, "ram_util_percent": 56.4952380952381, "gpu_util_percent0": 0.2473809523809524, "vram_util_percent0": 0.14876302083333334}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997475814819335}, "cop_policy": {"total_loss": 9.997475814819335, "policy_loss": -0.004927736156764695, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.37306796759367, "mean_kl_loss": 0.016024060747668045, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 47997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 47997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.20946255453632, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 48000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 47997, "timers": {"training_iteration_time_ms": 32493.836, "sample_time_ms": 28005.961, "synch_weights_time_ms": 6.289}, "counters": {"num_env_steps_sampled": 48000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 47997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 12, "trial_id": "1772b_00000", "date": "2024-01-13_11-03-52", "timestamp": 1705140232, "time_this_iter_s": 34.72736954689026, "time_total_s": 395.60583543777466, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BAB7F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 395.60583543777466, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 10.473333333333333, "ram_util_percent": 61.731111111111126, "gpu_util_percent0": 0.20733333333333334, "vram_util_percent0": 0.14876302083333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998758447170257}, "cop_policy": {"total_loss": 9.998758447170257, "policy_loss": -0.002887140998063842, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3507005795836449, "mean_kl_loss": 0.010971248174769244, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.19261495277075, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 52000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 51997, "timers": {"training_iteration_time_ms": 32565.343, "sample_time_ms": 28089.271, "synch_weights_time_ms": 5.968}, "counters": {"num_env_steps_sampled": 52000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 51997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 13, "trial_id": "1772b_00000", "date": "2024-01-13_11-04-26", "timestamp": 1705140266, "time_this_iter_s": 33.569103479385376, "time_total_s": 429.17493891716003, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9990>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 429.17493891716003, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 10.893181818181818, "ram_util_percent": 68.47727272727272, "gpu_util_percent0": 0.24000000000000002, "vram_util_percent0": 0.15222537878787878}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999505639076233}, "cop_policy": {"total_loss": 9.999505639076233, "policy_loss": -0.0013122828299856337, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3327416956424714, "mean_kl_loss": 0.005452644230445003, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 121.61368121439305, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 56000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 55997, "timers": {"training_iteration_time_ms": 32573.028, "sample_time_ms": 28094.981, "synch_weights_time_ms": 5.648}, "counters": {"num_env_steps_sampled": 56000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 55997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 14, "trial_id": "1772b_00000", "date": "2024-01-13_11-04-59", "timestamp": 1705140299, "time_this_iter_s": 32.89903235435486, "time_total_s": 462.0739712715149, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA560>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 462.0739712715149, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 10.109302325581394, "ram_util_percent": 71.18372093023255, "gpu_util_percent0": 0.24627906976744182, "vram_util_percent0": 0.15613644622093023}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997510766983032}, "cop_policy": {"total_loss": 9.997510766983032, "policy_loss": -0.004043633855030748, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3626220792531967, "mean_kl_loss": 0.010362045866884273, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.15000000596046448}}, "num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.06353560594856, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 60000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 59997, "timers": {"training_iteration_time_ms": 32875.127, "sample_time_ms": 28217.696, "synch_weights_time_ms": 5.743}, "counters": {"num_env_steps_sampled": 60000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 59997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 15, "trial_id": "1772b_00000", "date": "2024-01-13_11-05-32", "timestamp": 1705140332, "time_this_iter_s": 32.7788245677948, "time_total_s": 494.8527958393097, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BA85E0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 494.8527958393097, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 8.902325581395349, "ram_util_percent": 69.89302325581397, "gpu_util_percent0": 0.24511627906976746, "vram_util_percent0": 0.15648467781007752}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996933722496033}, "cop_policy": {"total_loss": 9.996933722496033, "policy_loss": -0.0062649263257000595, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3251948952674866, "mean_kl_loss": 0.021323545980067138, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.22500000894069672}}, "num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.53223688742243, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 64000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 63997, "timers": {"training_iteration_time_ms": 32609.163, "sample_time_ms": 27795.373, "synch_weights_time_ms": 5.744}, "counters": {"num_env_steps_sampled": 64000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 63997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 16, "trial_id": "1772b_00000", "date": "2024-01-13_11-06-04", "timestamp": 1705140364, "time_this_iter_s": 31.87294602394104, "time_total_s": 526.7257418632507, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB0A0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 526.7257418632507, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 8.382926829268293, "ram_util_percent": 67.17804878048781, "gpu_util_percent0": 0.23341463414634148, "vram_util_percent0": 0.15607930005081302}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997742426395416}, "cop_policy": {"total_loss": 9.997742426395416, "policy_loss": -0.004711632342150551, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3574377715587616, "mean_kl_loss": 0.010907274341525408, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.22500000894069672}}, "num_env_steps_sampled": 68000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 67997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 67997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 68000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.75174858777704, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 68000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 67997, "timers": {"training_iteration_time_ms": 32666.339, "sample_time_ms": 27671.701, "synch_weights_time_ms": 5.828}, "counters": {"num_env_steps_sampled": 68000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 67997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 17, "trial_id": "1772b_00000", "date": "2024-01-13_11-06-36", "timestamp": 1705140396, "time_this_iter_s": 32.331799030303955, "time_total_s": 559.0575408935547, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA440>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 559.0575408935547, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 7.299999999999998, "ram_util_percent": 67.20232558139536, "gpu_util_percent0": 0.30046511627906974, "vram_util_percent0": 0.15452019743217055}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999392223358154}, "cop_policy": {"total_loss": 9.999392223358154, "policy_loss": -0.0014429685384129698, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3629193276166915, "mean_kl_loss": 0.0037119896026297284, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.11250000447034836}}, "num_env_steps_sampled": 72000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 71997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 71997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 72000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 121.61993522323074, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 72000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 71997, "timers": {"training_iteration_time_ms": 32708.27, "sample_time_ms": 27538.149, "synch_weights_time_ms": 5.833}, "counters": {"num_env_steps_sampled": 72000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 71997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 18, "trial_id": "1772b_00000", "date": "2024-01-13_11-07-09", "timestamp": 1705140429, "time_this_iter_s": 32.897345304489136, "time_total_s": 591.9548861980438, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C25630>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 591.9548861980438, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 8.311904761904762, "ram_util_percent": 69.81904761904762, "gpu_util_percent0": 0.2783333333333334, "vram_util_percent0": 0.15449063740079363}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997177958488464}, "cop_policy": {"total_loss": 9.997177958488464, "policy_loss": -0.004042819857613722, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3733567774295807, "mean_kl_loss": 0.010850661217216385, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.11250000447034836}}, "num_env_steps_sampled": 76000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 75997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 75997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 76000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 102.10157598816068, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 76000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 75997, "timers": {"training_iteration_time_ms": 33396.052, "sample_time_ms": 28052.717, "synch_weights_time_ms": 5.829}, "counters": {"num_env_steps_sampled": 76000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 75997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 19, "trial_id": "1772b_00000", "date": "2024-01-13_11-07-48", "timestamp": 1705140468, "time_this_iter_s": 39.18524169921875, "time_total_s": 631.1401278972626, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB250>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 631.1401278972626, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 14.249019607843136, "ram_util_percent": 67.23529411764707, "gpu_util_percent0": 0.291764705882353, "vram_util_percent0": 0.1506778492647059}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999797523021698}, "cop_policy": {"total_loss": 9.999797523021698, "policy_loss": -0.0006327297731559157, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3608493000268935, "mean_kl_loss": 0.003824399615712082, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.05625000223517418}}, "num_env_steps_sampled": 80000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 79997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 79997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 80000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.92516688594647, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 80000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 79997, "timers": {"training_iteration_time_ms": 33430.354, "sample_time_ms": 27954.949, "synch_weights_time_ms": 5.581}, "counters": {"num_env_steps_sampled": 80000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 79997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 20, "trial_id": "1772b_00000", "date": "2024-01-13_11-08-20", "timestamp": 1705140500, "time_this_iter_s": 32.2860541343689, "time_total_s": 663.4261820316315, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9AB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 663.4261820316315, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 7.030952380952381, "ram_util_percent": 63.36666666666668, "gpu_util_percent0": 0.22952380952380955, "vram_util_percent0": 0.09716021825396826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99200679063797}, "cop_policy": {"total_loss": 9.99200679063797, "policy_loss": -0.009389165873290039, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3754565328359605, "mean_kl_loss": 0.02481473479934948, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.08437500149011612}}, "num_env_steps_sampled": 84000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 83997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 83997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 84000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.65906216104602, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 84000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 83997, "timers": {"training_iteration_time_ms": 33507.973, "sample_time_ms": 27931.382, "synch_weights_time_ms": 5.584}, "counters": {"num_env_steps_sampled": 84000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 83997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 21, "trial_id": "1772b_00000", "date": "2024-01-13_11-08-53", "timestamp": 1705140533, "time_this_iter_s": 32.62026858329773, "time_total_s": 696.0464506149292, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA560>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 696.0464506149292, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 6.690697674418603, "ram_util_percent": 63.71860465116279, "gpu_util_percent0": 0.23511627906976743, "vram_util_percent0": 0.09391276041666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998890793323516}, "cop_policy": {"total_loss": 9.998890793323516, "policy_loss": -0.0016321859944127936, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.372742097079754, "mean_kl_loss": 0.006197406429282637, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.08437500149011612}}, "num_env_steps_sampled": 88000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 87997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 87997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 88000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.22544641381623, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 88000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 87997, "timers": {"training_iteration_time_ms": 33282.119, "sample_time_ms": 27640.238, "synch_weights_time_ms": 5.496}, "counters": {"num_env_steps_sampled": 88000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 87997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 22, "trial_id": "1772b_00000", "date": "2024-01-13_11-09-26", "timestamp": 1705140566, "time_this_iter_s": 32.47193455696106, "time_total_s": 728.5183851718903, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27C70>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 728.5183851718903, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 7.141860465116277, "ram_util_percent": 64.46744186046512, "gpu_util_percent0": 0.2634883720930233, "vram_util_percent0": 0.09271666061046512}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998640048503876}, "cop_policy": {"total_loss": 9.998640048503876, "policy_loss": -0.0019853118024428795, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3609811261296272, "mean_kl_loss": 0.007411969997224333, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.08437500149011612}}, "num_env_steps_sampled": 92000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 91997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 91997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 92000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 120.38898869908753, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 92000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 91997, "timers": {"training_iteration_time_ms": 33248.769, "sample_time_ms": 27579.772, "synch_weights_time_ms": 5.351}, "counters": {"num_env_steps_sampled": 92000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 91997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 23, "trial_id": "1772b_00000", "date": "2024-01-13_11-09-59", "timestamp": 1705140599, "time_this_iter_s": 33.235151290893555, "time_total_s": 761.7535364627838, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9F30>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 761.7535364627838, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 7.5418604651162795, "ram_util_percent": 65.19767441860463, "gpu_util_percent0": 0.23046511627906976, "vram_util_percent0": 0.09658505935077519}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999352359771729}, "cop_policy": {"total_loss": 9.999352359771729, "policy_loss": -0.0011167181661903669, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3535056799650191, "mean_kl_loss": 0.005558987697236261, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.08437500149011612}}, "num_env_steps_sampled": 96000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 95997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 95997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 96000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.11462698776675, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 96000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 95997, "timers": {"training_iteration_time_ms": 33317.776, "sample_time_ms": 27661.439, "synch_weights_time_ms": 5.254}, "counters": {"num_env_steps_sampled": 96000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 95997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 24, "trial_id": "1772b_00000", "date": "2024-01-13_11-10-33", "timestamp": 1705140633, "time_this_iter_s": 33.59015607833862, "time_total_s": 795.3436925411224, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA290>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 795.3436925411224, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 6.931818181818182, "ram_util_percent": 65.31136363636364, "gpu_util_percent0": 0.32386363636363635, "vram_util_percent0": 0.1003676905776515}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99903416633606}, "cop_policy": {"total_loss": 9.99903416633606, "policy_loss": -0.0016670728285930636, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.3221596494317054, "mean_kl_loss": 0.00831262318113204, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.08437500149011612}}, "num_env_steps_sampled": 100000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 99997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 99997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 100000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 116.96289076061808, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 100000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 99997, "timers": {"training_iteration_time_ms": 33460.682, "sample_time_ms": 27798.906, "synch_weights_time_ms": 5.209}, "counters": {"num_env_steps_sampled": 100000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 99997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 25, "trial_id": "1772b_00000", "date": "2024-01-13_11-11-07", "timestamp": 1705140667, "time_this_iter_s": 34.207900047302246, "time_total_s": 829.5515925884247, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCBC70>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 829.5515925884247, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 10.08, "ram_util_percent": 67.01555555555557, "gpu_util_percent0": 0.20066666666666666, "vram_util_percent0": 0.09864366319444441}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999858462810517}, "cop_policy": {"total_loss": 9.999858462810517, "policy_loss": -0.0004245629137130891, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.294224852323532, "mean_kl_loss": 0.003355205323072141, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04218750074505806}}, "num_env_steps_sampled": 104000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 103997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 103997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 104000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 107.97954788012946, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 104000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 103997, "timers": {"training_iteration_time_ms": 33978.654, "sample_time_ms": 28247.264, "synch_weights_time_ms": 5.064}, "counters": {"num_env_steps_sampled": 104000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 103997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 26, "trial_id": "1772b_00000", "date": "2024-01-13_11-11-44", "timestamp": 1705140704, "time_this_iter_s": 37.05356001853943, "time_total_s": 866.6051526069641, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB760>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 866.6051526069641, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 11.34375, "ram_util_percent": 69.66250000000001, "gpu_util_percent0": 0.29187500000000005, "vram_util_percent0": 0.09554036458333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 10.000108420848846}, "cop_policy": {"total_loss": 10.000108420848846, "policy_loss": -1.5150394233387487e-05, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2758981347084046, "mean_kl_loss": 0.0029292901217388588, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.02109375037252903}}, "num_env_steps_sampled": 108000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 107997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 107997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 108000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 76.90043312028807, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 108000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 107997, "timers": {"training_iteration_time_ms": 35947.908, "sample_time_ms": 30035.201, "synch_weights_time_ms": 5.327}, "counters": {"num_env_steps_sampled": 108000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 107997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 27, "trial_id": "1772b_00000", "date": "2024-01-13_11-12-36", "timestamp": 1705140756, "time_this_iter_s": 52.02432155609131, "time_total_s": 918.6294741630554, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC9C60>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 918.6294741630554, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 30.416129032258063, "ram_util_percent": 68.70161290322582, "gpu_util_percent0": 0.19193548387096776, "vram_util_percent0": 0.09499957997311832}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.994508898258209}, "cop_policy": {"total_loss": 9.994508898258209, "policy_loss": -0.005927624018875121, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2267460912466048, "mean_kl_loss": 0.02069208112019396, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.03164062649011612}}, "num_env_steps_sampled": 112000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 111997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 111997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 112000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 106.38409473697133, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 112000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 111997, "timers": {"training_iteration_time_ms": 36418.934, "sample_time_ms": 30425.191, "synch_weights_time_ms": 5.499}, "counters": {"num_env_steps_sampled": 112000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 111997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 28, "trial_id": "1772b_00000", "date": "2024-01-13_11-13-14", "timestamp": 1705140794, "time_this_iter_s": 37.607216596603394, "time_total_s": 956.2366907596588, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4C0D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 956.2366907596588, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 10.46734693877551, "ram_util_percent": 64.46122448979592, "gpu_util_percent0": 0.2997959183673469, "vram_util_percent0": 0.09400576636904762}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999223875999451}, "cop_policy": {"total_loss": 9.999223875999451, "policy_loss": -0.0009701891598979274, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.175847554206848, "mean_kl_loss": 0.006130937320358498, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.03164062649011612}}, "num_env_steps_sampled": 116000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 115997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 115997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 116000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 116.61642234333544, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 116000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 115997, "timers": {"training_iteration_time_ms": 35931.315, "sample_time_ms": 29904.081, "synch_weights_time_ms": 5.158}, "counters": {"num_env_steps_sampled": 116000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 115997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 29, "trial_id": "1772b_00000", "date": "2024-01-13_11-13-48", "timestamp": 1705140828, "time_this_iter_s": 34.309192419052124, "time_total_s": 990.5458831787109, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA560>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 990.5458831787109, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 8.053333333333335, "ram_util_percent": 65.16888888888889, "gpu_util_percent0": 0.2828888888888889, "vram_util_percent0": 0.09517867476851853}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997594285011292}, "cop_policy": {"total_loss": 9.997594285011292, "policy_loss": -0.0030648827044785776, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2701081737875939, "mean_kl_loss": 0.020834788134834525, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 120000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 119997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 119997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 120000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.69370287565384, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 120000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 119997, "timers": {"training_iteration_time_ms": 36161.066, "sample_time_ms": 30133.44, "synch_weights_time_ms": 5.03}, "counters": {"num_env_steps_sampled": 120000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 119997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 30, "trial_id": "1772b_00000", "date": "2024-01-13_11-14-23", "timestamp": 1705140863, "time_this_iter_s": 34.582780599594116, "time_total_s": 1025.128663778305, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA320>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1025.128663778305, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 7.988888888888888, "ram_util_percent": 65.71555555555557, "gpu_util_percent0": 0.23511111111111116, "vram_util_percent0": 0.10215567129629625}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998015701770782}, "cop_policy": {"total_loss": 9.998015701770782, "policy_loss": -0.0022759986756000217, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2849443584680558, "mean_kl_loss": 0.006145944648778823, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 124000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 123997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 123997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 124000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 121.64369909194804, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 124000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 123997, "timers": {"training_iteration_time_ms": 36188.286, "sample_time_ms": 30141.841, "synch_weights_time_ms": 5.076}, "counters": {"num_env_steps_sampled": 124000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 123997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 31, "trial_id": "1772b_00000", "date": "2024-01-13_11-14-56", "timestamp": 1705140896, "time_this_iter_s": 32.89251947402954, "time_total_s": 1058.0211832523346, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4C940>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1058.0211832523346, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 7.658139534883722, "ram_util_percent": 65.8813953488372, "gpu_util_percent0": 0.2411627906976744, "vram_util_percent0": 0.098629027374031}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998015868663789}, "cop_policy": {"total_loss": 9.998015868663789, "policy_loss": -0.002352240308391629, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2505360960960388, "mean_kl_loss": 0.007755285859191474, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 128000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 127997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 127997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 128000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 113.37038448107606, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 128000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 127997, "timers": {"training_iteration_time_ms": 36470.462, "sample_time_ms": 30338.958, "synch_weights_time_ms": 5.066}, "counters": {"num_env_steps_sampled": 128000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 127997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 32, "trial_id": "1772b_00000", "date": "2024-01-13_11-15-31", "timestamp": 1705140931, "time_this_iter_s": 35.29171442985535, "time_total_s": 1093.31289768219, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA170>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1093.31289768219, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 8.41304347826087, "ram_util_percent": 66.4, "gpu_util_percent0": 0.24956521739130427, "vram_util_percent0": 0.10600656702898548}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998628127574921}, "cop_policy": {"total_loss": 9.998628127574921, "policy_loss": -0.0017227964231807391, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2954572856426239, "mean_kl_loss": 0.00739481248342031, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 132000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 131997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 131997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 132000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.07073841381295, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 132000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 131997, "timers": {"training_iteration_time_ms": 36507.247, "sample_time_ms": 30361.426, "synch_weights_time_ms": 5.111}, "counters": {"num_env_steps_sampled": 132000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 131997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 33, "trial_id": "1772b_00000", "date": "2024-01-13_11-16-05", "timestamp": 1705140965, "time_this_iter_s": 33.602232933044434, "time_total_s": 1126.9151306152344, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C25240>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1126.9151306152344, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 6.8931818181818185, "ram_util_percent": 67.02045454545454, "gpu_util_percent0": 0.21863636363636363, "vram_util_percent0": 0.10179554332386366}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.995140552520752}, "cop_policy": {"total_loss": 9.995140552520752, "policy_loss": -0.005590757016943826, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2737485870718956, "mean_kl_loss": 0.015407838604141943, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 136000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 135997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 135997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 136000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 118.32576467014475, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 136000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 135997, "timers": {"training_iteration_time_ms": 36529.635, "sample_time_ms": 30375.408, "synch_weights_time_ms": 5.173}, "counters": {"num_env_steps_sampled": 136000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 135997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 34, "trial_id": "1772b_00000", "date": "2024-01-13_11-16-39", "timestamp": 1705140999, "time_this_iter_s": 33.81371068954468, "time_total_s": 1160.728841304779, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4D2D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1160.728841304779, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 6.4409090909090905, "ram_util_percent": 67.42954545454546, "gpu_util_percent0": 0.2620454545454546, "vram_util_percent0": 0.10353412050189395}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997632050514222}, "cop_policy": {"total_loss": 9.997632050514222, "policy_loss": -0.003012386043110382, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2826469078660012, "mean_kl_loss": 0.01357737568068842, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 140000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 139997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 139997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 140000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 108.1853356210956, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 140000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 139997, "timers": {"training_iteration_time_ms": 36807.105, "sample_time_ms": 30631.063, "synch_weights_time_ms": 5.133}, "counters": {"num_env_steps_sampled": 140000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 139997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 35, "trial_id": "1772b_00000", "date": "2024-01-13_11-17-16", "timestamp": 1705141036, "time_this_iter_s": 36.98200702667236, "time_total_s": 1197.7108483314514, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27D00>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1197.7108483314514, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 9.25, "ram_util_percent": 74.31041666666665, "gpu_util_percent0": 0.2939583333333333, "vram_util_percent0": 0.10382758246527778}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.995811653137206}, "cop_policy": {"total_loss": 9.995811653137206, "policy_loss": -0.004701032545995076, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2906003594398499, "mean_kl_loss": 0.010803769531594298, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 144000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 143997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 143997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 144000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 110.93260208815356, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 144000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 143997, "timers": {"training_iteration_time_ms": 36708.493, "sample_time_ms": 30577.592, "synch_weights_time_ms": 5.585}, "counters": {"num_env_steps_sampled": 144000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 143997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 36, "trial_id": "1772b_00000", "date": "2024-01-13_11-17-52", "timestamp": 1705141072, "time_this_iter_s": 36.06763768196106, "time_total_s": 1233.7784860134125, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA830>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1233.7784860134125, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 8.865957446808508, "ram_util_percent": 67.96170212765958, "gpu_util_percent0": 0.3080851063829787, "vram_util_percent0": 0.10410433289007097}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998935055732726}, "cop_policy": {"total_loss": 9.998935055732726, "policy_loss": -0.0014460513456469926, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2881535679101943, "mean_kl_loss": 0.008028179538487733, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 148000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 147997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 147997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 148000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 116.09083025581614, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 148000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 147997, "timers": {"training_iteration_time_ms": 34952.54, "sample_time_ms": 28984.209, "synch_weights_time_ms": 5.294}, "counters": {"num_env_steps_sampled": 148000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 147997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 37, "trial_id": "1772b_00000", "date": "2024-01-13_11-18-26", "timestamp": 1705141106, "time_this_iter_s": 34.46388030052185, "time_total_s": 1268.2423663139343, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA8C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1268.2423663139343, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 6.5488888888888885, "ram_util_percent": 59.70444444444444, "gpu_util_percent0": 0.3157777777777778, "vram_util_percent0": 0.10319010416666671}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99859004020691}, "cop_policy": {"total_loss": 9.99859004020691, "policy_loss": -0.0020220463535792987, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2436389729380608, "mean_kl_loss": 0.012895520648572755, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 152000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 151997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 151997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 152000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 118.79903503881337, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 152000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 151997, "timers": {"training_iteration_time_ms": 34559.61, "sample_time_ms": 28645.898, "synch_weights_time_ms": 5.123}, "counters": {"num_env_steps_sampled": 152000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 151997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 38, "trial_id": "1772b_00000", "date": "2024-01-13_11-19-00", "timestamp": 1705141140, "time_this_iter_s": 33.679054975509644, "time_total_s": 1301.921421289444, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BABB50>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1301.921421289444, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 6.668888888888888, "ram_util_percent": 57.042222222222236, "gpu_util_percent0": 0.3162222222222222, "vram_util_percent0": 0.10334563078703703}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996178364753723}, "cop_policy": {"total_loss": 9.996178364753723, "policy_loss": -0.004714735375364399, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1768712937831878, "mean_kl_loss": 0.018814103543422788, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 156000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 155997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 155997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 156000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.27879891827033, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 156000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 155997, "timers": {"training_iteration_time_ms": 34483.049, "sample_time_ms": 28609.542, "synch_weights_time_ms": 5.275}, "counters": {"num_env_steps_sampled": 156000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 155997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 39, "trial_id": "1772b_00000", "date": "2024-01-13_11-19-34", "timestamp": 1705141174, "time_this_iter_s": 33.54454755783081, "time_total_s": 1335.4659688472748, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CC92D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1335.4659688472748, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 7.213636363636363, "ram_util_percent": 57.88409090909091, "gpu_util_percent0": 0.3184090909090909, "vram_util_percent0": 0.10417036576704541}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998870646953582}, "cop_policy": {"total_loss": 9.998870646953582, "policy_loss": -0.0014507068724014971, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.103400920331478, "mean_kl_loss": 0.006771595845202682, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 160000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 159997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 159997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 160000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.80250913765059, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 160000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 159997, "timers": {"training_iteration_time_ms": 34256.596, "sample_time_ms": 28387.339, "synch_weights_time_ms": 5.351}, "counters": {"num_env_steps_sampled": 160000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 159997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 40, "trial_id": "1772b_00000", "date": "2024-01-13_11-20-06", "timestamp": 1705141206, "time_this_iter_s": 32.31877589225769, "time_total_s": 1367.7847447395325, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4D120>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1367.7847447395325, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 6.969047619047619, "ram_util_percent": 58.016666666666666, "gpu_util_percent0": 0.21785714285714286, "vram_util_percent0": 0.10188802083333331}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998804152011871}, "cop_policy": {"total_loss": 9.998804152011871, "policy_loss": -0.0015263308275279997, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1099484458565712, "mean_kl_loss": 0.0069639683481227625, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 164000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 163997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 163997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 164000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.84155051297576, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 164000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 163997, "timers": {"training_iteration_time_ms": 34609.914, "sample_time_ms": 28708.171, "synch_weights_time_ms": 5.312}, "counters": {"num_env_steps_sampled": 164000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 163997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 41, "trial_id": "1772b_00000", "date": "2024-01-13_11-20-42", "timestamp": 1705141242, "time_this_iter_s": 36.42525625228882, "time_total_s": 1404.2100009918213, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27910>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1404.2100009918213, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 10.054347826086957, "ram_util_percent": 60.73478260869567, "gpu_util_percent0": 0.25673913043478264, "vram_util_percent0": 0.10157665307971016}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99697173833847}, "cop_policy": {"total_loss": 9.99697173833847, "policy_loss": -0.0038144235437357565, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.9710988067090511, "mean_kl_loss": 0.016565760026378485, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 168000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 167997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 167997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 168000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 108.84084147282852, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 168000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 167997, "timers": {"training_iteration_time_ms": 34756.746, "sample_time_ms": 28939.735, "synch_weights_time_ms": 5.266}, "counters": {"num_env_steps_sampled": 168000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 167997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 42, "trial_id": "1772b_00000", "date": "2024-01-13_11-21-19", "timestamp": 1705141279, "time_this_iter_s": 36.760459423065186, "time_total_s": 1440.9704604148865, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB7F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1440.9704604148865, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 11.987500000000002, "ram_util_percent": 71.11874999999999, "gpu_util_percent0": 0.24562499999999998, "vram_util_percent0": 0.10074869791666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998594462871552}, "cop_policy": {"total_loss": 9.998594462871552, "policy_loss": -0.001656691450989456, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.9463988751173019, "mean_kl_loss": 0.005292416915744979, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 172000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 171997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 171997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 172000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 109.05578845812909, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 172000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 171997, "timers": {"training_iteration_time_ms": 35065.246, "sample_time_ms": 29210.459, "synch_weights_time_ms": 5.425}, "counters": {"num_env_steps_sampled": 172000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 171997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 43, "trial_id": "1772b_00000", "date": "2024-01-13_11-21-56", "timestamp": 1705141316, "time_this_iter_s": 36.68699240684509, "time_total_s": 1477.6574528217316, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4DA20>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1477.6574528217316, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 10.172340425531916, "ram_util_percent": 74.48297872340426, "gpu_util_percent0": 0.30148936170212765, "vram_util_percent0": 0.09797138187056732}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997904026508332}, "cop_policy": {"total_loss": 9.997904026508332, "policy_loss": -0.0023948599700361227, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.9458730667829514, "mean_kl_loss": 0.006297368515470225, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 176000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 175997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 175997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 176000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 111.00010949020457, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 176000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 175997, "timers": {"training_iteration_time_ms": 35288.248, "sample_time_ms": 29334.016, "synch_weights_time_ms": 6.014}, "counters": {"num_env_steps_sampled": 176000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 175997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 44, "trial_id": "1772b_00000", "date": "2024-01-13_11-22-32", "timestamp": 1705141352, "time_this_iter_s": 36.04651880264282, "time_total_s": 1513.7039716243744, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4E8C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1513.7039716243744, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 10.048936170212764, "ram_util_percent": 70.3063829787234, "gpu_util_percent0": 0.30106382978723406, "vram_util_percent0": 0.09531873337765957}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999872028827667}, "cop_policy": {"total_loss": 9.999872028827667, "policy_loss": -0.0003670722931474302, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.0092352144420147, "mean_kl_loss": 0.005038163458681311, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.04746093973517418}}, "num_env_steps_sampled": 180000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 179997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 179997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 180000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 106.3843517526005, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 180000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 179997, "timers": {"training_iteration_time_ms": 35350.841, "sample_time_ms": 29376.821, "synch_weights_time_ms": 5.959}, "counters": {"num_env_steps_sampled": 180000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 179997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 45, "trial_id": "1772b_00000", "date": "2024-01-13_11-23-10", "timestamp": 1705141390, "time_this_iter_s": 37.611029624938965, "time_total_s": 1551.3150012493134, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB1C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1551.3150012493134, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 11.524489795918369, "ram_util_percent": 59.19795918367347, "gpu_util_percent0": 0.3063265306122449, "vram_util_percent0": 0.09954958545918366}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997675979137421}, "cop_policy": {"total_loss": 9.997675979137421, "policy_loss": -0.00252473234173749, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.0907801285386085, "mean_kl_loss": 0.004230845791187221, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.02373046986758709}}, "num_env_steps_sampled": 184000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 183997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 183997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 184000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.47576699524465, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 184000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 183997, "timers": {"training_iteration_time_ms": 35093.007, "sample_time_ms": 29136.976, "synch_weights_time_ms": 5.669}, "counters": {"num_env_steps_sampled": 184000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 183997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 46, "trial_id": "1772b_00000", "date": "2024-01-13_11-23-43", "timestamp": 1705141423, "time_this_iter_s": 33.488086223602295, "time_total_s": 1584.8030874729156, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4C280>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1584.8030874729156, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 6.8931818181818185, "ram_util_percent": 60.91818181818183, "gpu_util_percent0": 0.2672727272727273, "vram_util_percent0": 0.09783380681818182}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.9950421333313}, "cop_policy": {"total_loss": 9.9950421333313, "policy_loss": -0.005497715759470623, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.9119052723050117, "mean_kl_loss": 0.022747930408570483, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.03559570387005806}}, "num_env_steps_sampled": 188000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 187997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 187997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 188000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 118.27728702144043, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 188000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 187997, "timers": {"training_iteration_time_ms": 35029.313, "sample_time_ms": 29015.572, "synch_weights_time_ms": 5.751}, "counters": {"num_env_steps_sampled": 188000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 187997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 47, "trial_id": "1772b_00000", "date": "2024-01-13_11-24-17", "timestamp": 1705141457, "time_this_iter_s": 33.82788324356079, "time_total_s": 1618.6309707164764, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BAB7F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1618.6309707164764, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 7.938636363636365, "ram_util_percent": 60.854545454545466, "gpu_util_percent0": 0.2734090909090909, "vram_util_percent0": 0.09249230587121214}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997951114177704}, "cop_policy": {"total_loss": 9.997951114177704, "policy_loss": -0.0022861703168928216, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.8839899256825448, "mean_kl_loss": 0.006666904434950993, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.03559570387005806}}, "num_env_steps_sampled": 192000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 191997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 191997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 192000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.98928135413581, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 192000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 191997, "timers": {"training_iteration_time_ms": 34837.155, "sample_time_ms": 28844.251, "synch_weights_time_ms": 5.65}, "counters": {"num_env_steps_sampled": 192000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 191997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 48, "trial_id": "1772b_00000", "date": "2024-01-13_11-24-49", "timestamp": 1705141489, "time_this_iter_s": 31.756242752075195, "time_total_s": 1650.3872134685516, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCA8C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1650.3872134685516, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 6.3428571428571425, "ram_util_percent": 62.73571428571429, "gpu_util_percent0": 0.23309523809523808, "vram_util_percent0": 0.09160698784722221}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997894406318665}, "cop_policy": {"total_loss": 9.997894406318665, "policy_loss": -0.0025191844054745617, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.9837266504764557, "mean_kl_loss": 0.011618054168206982, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.03559570387005806}}, "num_env_steps_sampled": 196000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 195997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 195997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 196000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.71012088543422, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 196000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 195997, "timers": {"training_iteration_time_ms": 34717.033, "sample_time_ms": 28734.097, "synch_weights_time_ms": 5.654}, "counters": {"num_env_steps_sampled": 196000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 195997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 49, "trial_id": "1772b_00000", "date": "2024-01-13_11-25-21", "timestamp": 1705141521, "time_this_iter_s": 32.342790842056274, "time_total_s": 1682.730004310608, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4E170>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1682.730004310608, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 6.014285714285714, "ram_util_percent": 63.14285714285715, "gpu_util_percent0": 0.22309523809523812, "vram_util_percent0": 0.09016152033730158}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999586582183838}, "cop_policy": {"total_loss": 9.999586582183838, "policy_loss": -0.0005484471076442788, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.0605652622878552, "mean_kl_loss": 0.0037923179185384015, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.01779785193502903}}, "num_env_steps_sampled": 200000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 199997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 199997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 200000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.48795370422513, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 200000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 199997, "timers": {"training_iteration_time_ms": 34673.637, "sample_time_ms": 28687.374, "synch_weights_time_ms": 5.754}, "counters": {"num_env_steps_sampled": 200000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 199997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 50, "trial_id": "1772b_00000", "date": "2024-01-13_11-25-53", "timestamp": 1705141553, "time_this_iter_s": 31.884082794189453, "time_total_s": 1714.6140871047974, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4F130>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1714.6140871047974, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 6.204761904761905, "ram_util_percent": 63.67619047619049, "gpu_util_percent0": 0.2266666666666667, "vram_util_percent0": 0.09194800967261905}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999566006660462}, "cop_policy": {"total_loss": 9.999566006660462, "policy_loss": -0.0004987177818293276, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.0449638724327088, "mean_kl_loss": 0.0036416349273736158, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 204000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 203997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 203997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 204000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.5682932995877, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 204000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 203997, "timers": {"training_iteration_time_ms": 34243.118, "sample_time_ms": 28311.141, "synch_weights_time_ms": 5.902}, "counters": {"num_env_steps_sampled": 204000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 203997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 51, "trial_id": "1772b_00000", "date": "2024-01-13_11-26-26", "timestamp": 1705141586, "time_this_iter_s": 32.11842942237854, "time_total_s": 1746.732516527176, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCBEB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1746.732516527176, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 5.938095238095238, "ram_util_percent": 63.68333333333334, "gpu_util_percent0": 0.22500000000000003, "vram_util_percent0": 0.0906769283234127}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999310326576232}, "cop_policy": {"total_loss": 9.999310326576232, "policy_loss": -0.0007622035303484154, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1478952795267106, "mean_kl_loss": 0.00814568912218192, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 208000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 207997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 207997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 208000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.32063543988333, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 208000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 207997, "timers": {"training_iteration_time_ms": 33920.339, "sample_time_ms": 27996.345, "synch_weights_time_ms": 5.947}, "counters": {"num_env_steps_sampled": 208000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 207997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 52, "trial_id": "1772b_00000", "date": "2024-01-13_11-26-59", "timestamp": 1705141619, "time_this_iter_s": 33.5348117351532, "time_total_s": 1780.267328262329, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27D00>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1780.267328262329, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 7.154545454545453, "ram_util_percent": 65.05227272727272, "gpu_util_percent0": 0.25977272727272727, "vram_util_percent0": 0.09001390861742425}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998253977298736}, "cop_policy": {"total_loss": 9.998253977298736, "policy_loss": -0.0018355254499738294, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1763641089200974, "mean_kl_loss": 0.010055954207268769, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 212000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 211997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 211997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 212000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.95875484232269, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 212000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 211997, "timers": {"training_iteration_time_ms": 33505.615, "sample_time_ms": 27592.302, "synch_weights_time_ms": 6.144}, "counters": {"num_env_steps_sampled": 212000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 211997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 53, "trial_id": "1772b_00000", "date": "2024-01-13_11-27-32", "timestamp": 1705141652, "time_this_iter_s": 32.540745973587036, "time_total_s": 1812.8080742359161, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4F400>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1812.8080742359161, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 7.826190476190476, "ram_util_percent": 67.20238095238095, "gpu_util_percent0": 0.2261904761904762, "vram_util_percent0": 0.08928958953373016}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997515535354614}, "cop_policy": {"total_loss": 9.997515535354614, "policy_loss": -0.0025344423544879646, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1541001453995705, "mean_kl_loss": 0.0056121252515566765, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 216000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 215997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 215997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 216000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.76055691526368, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 216000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 215997, "timers": {"training_iteration_time_ms": 33160.491, "sample_time_ms": 27359.645, "synch_weights_time_ms": 5.539}, "counters": {"num_env_steps_sampled": 216000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 215997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 54, "trial_id": "1772b_00000", "date": "2024-01-13_11-28-04", "timestamp": 1705141684, "time_this_iter_s": 32.592273473739624, "time_total_s": 1845.4003477096558, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4EF80>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1845.4003477096558, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 7.865116279069766, "ram_util_percent": 57.255813953488364, "gpu_util_percent0": 0.21465116279069765, "vram_util_percent0": 0.09068783309108527}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999564063549041}, "cop_policy": {"total_loss": 9.999564063549041, "policy_loss": -0.0005054657066978052, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.172373153269291, "mean_kl_loss": 0.007810809846773736, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 220000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 219997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 219997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 220000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 122.10198025217849, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 220000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 219997, "timers": {"training_iteration_time_ms": 32676.489, "sample_time_ms": 26924.584, "synch_weights_time_ms": 5.584}, "counters": {"num_env_steps_sampled": 220000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 219997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 55, "trial_id": "1772b_00000", "date": "2024-01-13_11-28-37", "timestamp": 1705141717, "time_this_iter_s": 32.768646478652954, "time_total_s": 1878.1689941883087, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617BAB7F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1878.1689941883087, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 6.1976744186046515, "ram_util_percent": 57.188372093023276, "gpu_util_percent0": 0.28720930232558145, "vram_util_percent0": 0.0906272710755814}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996415138244629}, "cop_policy": {"total_loss": 9.996415138244629, "policy_loss": -0.0037419422935471404, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.187569411098957, "mean_kl_loss": 0.017650583640784135, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 224000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 223997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 223997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 224000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.75285837784557, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 224000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 223997, "timers": {"training_iteration_time_ms": 32534.869, "sample_time_ms": 26784.546, "synch_weights_time_ms": 5.464}, "counters": {"num_env_steps_sampled": 224000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 223997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 56, "trial_id": "1772b_00000", "date": "2024-01-13_11-29-09", "timestamp": 1705141749, "time_this_iter_s": 32.07291340827942, "time_total_s": 1910.2419075965881, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4EB90>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1910.2419075965881, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 6.045238095238095, "ram_util_percent": 57.70714285714286, "gpu_util_percent0": 0.22571428571428573, "vram_util_percent0": 0.08969261532738096}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99782773256302}, "cop_policy": {"total_loss": 9.99782773256302, "policy_loss": -0.002257405398086121, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2398767918348312, "mean_kl_loss": 0.009569635118077712, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 228000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 227997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 227997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 228000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.11764725710776, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 228000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 227997, "timers": {"training_iteration_time_ms": 32349.977, "sample_time_ms": 26659.806, "synch_weights_time_ms": 5.463}, "counters": {"num_env_steps_sampled": 228000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 227997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 57, "trial_id": "1772b_00000", "date": "2024-01-13_11-29-41", "timestamp": 1705141781, "time_this_iter_s": 31.979418992996216, "time_total_s": 1942.2213265895844, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4F6D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1942.2213265895844, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 5.945238095238096, "ram_util_percent": 57.98095238095239, "gpu_util_percent0": 0.23595238095238097, "vram_util_percent0": 0.08950272817460318}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99561711549759}, "cop_policy": {"total_loss": 9.99561711549759, "policy_loss": -0.004510402338382846, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.2560617193579673, "mean_kl_loss": 0.014332291703067313, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 232000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 231997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 231997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 232000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 127.16561150204477, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 232000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 231997, "timers": {"training_iteration_time_ms": 32320.608, "sample_time_ms": 26633.716, "synch_weights_time_ms": 5.615}, "counters": {"num_env_steps_sampled": 232000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 231997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 58, "trial_id": "1772b_00000", "date": "2024-01-13_11-30-13", "timestamp": 1705141813, "time_this_iter_s": 31.46558403968811, "time_total_s": 1973.6869106292725, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCBF40>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 1973.6869106292725, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 6.188095238095237, "ram_util_percent": 58.00714285714286, "gpu_util_percent0": 0.21761904761904763, "vram_util_percent0": 0.08951822916666667}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996530377864838}, "cop_policy": {"total_loss": 9.996530377864838, "policy_loss": -0.0036316421940682632, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1637016594409944, "mean_kl_loss": 0.01820329341330762, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.008898925967514515}}, "num_env_steps_sampled": 236000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 235997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 235997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 236000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.1955133317476, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 236000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 235997, "timers": {"training_iteration_time_ms": 32282.246, "sample_time_ms": 26595.085, "synch_weights_time_ms": 5.461}, "counters": {"num_env_steps_sampled": 236000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 235997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 59, "trial_id": "1772b_00000", "date": "2024-01-13_11-30-45", "timestamp": 1705141845, "time_this_iter_s": 31.959558963775635, "time_total_s": 2005.646469593048, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4C0D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2005.646469593048, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 13.841463414634147, "ram_util_percent": 58.33414634146342, "gpu_util_percent0": 0.2321951219512195, "vram_util_percent0": 0.09122125889227643}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999337613582611}, "cop_policy": {"total_loss": 9.999337613582611, "policy_loss": -0.0007036588460550775, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.1345684692263602, "mean_kl_loss": 0.004646339301052649, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0044494629837572575}}, "num_env_steps_sampled": 240000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 239997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 239997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 240000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.87300247548802, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 240000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 239997, "timers": {"training_iteration_time_ms": 32272.495, "sample_time_ms": 26588.787, "synch_weights_time_ms": 5.558}, "counters": {"num_env_steps_sampled": 240000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 239997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 60, "trial_id": "1772b_00000", "date": "2024-01-13_11-31-17", "timestamp": 1705141877, "time_this_iter_s": 31.784075260162354, "time_total_s": 2037.4305448532104, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4DEA0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2037.4305448532104, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 6.245238095238095, "ram_util_percent": 58.7, "gpu_util_percent0": 0.2221428571428572, "vram_util_percent0": 0.09105670262896826}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996300148963929}, "cop_policy": {"total_loss": 9.996300148963929, "policy_loss": -0.003789346960934381, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.070395676791668, "mean_kl_loss": 0.020114693414274142, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.00667419470846653}}, "num_env_steps_sampled": 244000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 243997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 243997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 244000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.17014269533365, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 244000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 243997, "timers": {"training_iteration_time_ms": 32257.055, "sample_time_ms": 26576.258, "synch_weights_time_ms": 5.302}, "counters": {"num_env_steps_sampled": 244000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 243997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 61, "trial_id": "1772b_00000", "date": "2024-01-13_11-31-49", "timestamp": 1705141909, "time_this_iter_s": 31.964513301849365, "time_total_s": 2069.39505815506, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368790>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2069.39505815506, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 6.476190476190476, "ram_util_percent": 59.13333333333334, "gpu_util_percent0": 0.22904761904761908, "vram_util_percent0": 0.09099857390873016}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.996404981613159}, "cop_policy": {"total_loss": 9.996404981613159, "policy_loss": -0.003674295645890879, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 1.014915019273758, "mean_kl_loss": 0.011859408659140059, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.00667419470846653}}, "num_env_steps_sampled": 248000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 247997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 247997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 248000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.04453028301847, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 248000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 247997, "timers": {"training_iteration_time_ms": 32103.604, "sample_time_ms": 26427.066, "synch_weights_time_ms": 5.355}, "counters": {"num_env_steps_sampled": 248000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 247997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 62, "trial_id": "1772b_00000", "date": "2024-01-13_11-32-21", "timestamp": 1705141941, "time_this_iter_s": 31.99711322784424, "time_total_s": 2101.392171382904, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4E050>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2101.392171382904, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 6.002380952380953, "ram_util_percent": 59.50952380952381, "gpu_util_percent0": 0.23190476190476192, "vram_util_percent0": 0.09120396205357142}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997062873840331}, "cop_policy": {"total_loss": 9.997062873840331, "policy_loss": -0.0030468789485894377, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.877885653078556, "mean_kl_loss": 0.016451712979460353, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.00667419470846653}}, "num_env_steps_sampled": 252000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 251997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 251997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 252000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 120.74396062886433, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 252000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 251997, "timers": {"training_iteration_time_ms": 32163.275, "sample_time_ms": 26546.403, "synch_weights_time_ms": 5.558}, "counters": {"num_env_steps_sampled": 252000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 251997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 63, "trial_id": "1772b_00000", "date": "2024-01-13_11-32-54", "timestamp": 1705141974, "time_this_iter_s": 33.136472940444946, "time_total_s": 2134.528644323349, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCB7F0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2134.528644323349, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 7.863636363636363, "ram_util_percent": 55.66818181818181, "gpu_util_percent0": 0.2581818181818182, "vram_util_percent0": 0.09180057410037877}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999280869960785}, "cop_policy": {"total_loss": 9.999280869960785, "policy_loss": -0.0007473507049326145, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.837509473413229, "mean_kl_loss": 0.004251940938320331, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.003337097354233265}}, "num_env_steps_sampled": 256000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 255997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 255997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 256000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.23374655857027, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 256000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 255997, "timers": {"training_iteration_time_ms": 32098.927, "sample_time_ms": 26476.487, "synch_weights_time_ms": 5.611}, "counters": {"num_env_steps_sampled": 256000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 255997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 64, "trial_id": "1772b_00000", "date": "2024-01-13_11-33-26", "timestamp": 1705142006, "time_this_iter_s": 31.95079255104065, "time_total_s": 2166.4794368743896, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368CA0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2166.4794368743896, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 5.902439024390245, "ram_util_percent": 56.175609756097565, "gpu_util_percent0": 0.23780487804878048, "vram_util_percent0": 0.0910227705792683}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998623502254485}, "cop_policy": {"total_loss": 9.998623502254485, "policy_loss": -0.001396215552523472, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.7568037897348404, "mean_kl_loss": 0.005896808231381101, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.003337097354233265}}, "num_env_steps_sampled": 260000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 259997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 259997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 260000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 126.25625691147593, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 260000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 259997, "timers": {"training_iteration_time_ms": 31991.137, "sample_time_ms": 26370.489, "synch_weights_time_ms": 5.503}, "counters": {"num_env_steps_sampled": 260000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 259997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 65, "trial_id": "1772b_00000", "date": "2024-01-13_11-33-58", "timestamp": 1705142038, "time_this_iter_s": 31.689953088760376, "time_total_s": 2198.16938996315, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369990>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2198.16938996315, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 6.166666666666667, "ram_util_percent": 56.37619047619047, "gpu_util_percent0": 0.22119047619047622, "vram_util_percent0": 0.09079706101190477}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998369562625886}, "cop_policy": {"total_loss": 9.998369562625886, "policy_loss": -0.0016469376590293905, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.7144824266433716, "mean_kl_loss": 0.004944233993433045, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0016685486771166325}}, "num_env_steps_sampled": 264000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 263997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 263997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 264000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 126.38962385660561, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 264000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 263997, "timers": {"training_iteration_time_ms": 31949.614, "sample_time_ms": 26328.216, "synch_weights_time_ms": 5.608}, "counters": {"num_env_steps_sampled": 264000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 263997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 66, "trial_id": "1772b_00000", "date": "2024-01-13_11-34-30", "timestamp": 1705142070, "time_this_iter_s": 31.657275199890137, "time_total_s": 2229.82666516304, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4F910>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2229.82666516304, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 13.585714285714285, "ram_util_percent": 56.82619047619047, "gpu_util_percent0": 0.22261904761904766, "vram_util_percent0": 0.09133572048611112}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.997642636299133}, "cop_policy": {"total_loss": 9.997642636299133, "policy_loss": -0.0023648816588774935, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.7923918455839157, "mean_kl_loss": 0.004545931946427118, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0008342743385583162}}, "num_env_steps_sampled": 268000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 267997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 267997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 268000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.7721210864044, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 268000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 267997, "timers": {"training_iteration_time_ms": 31958.467, "sample_time_ms": 26337.99, "synch_weights_time_ms": 5.555}, "counters": {"num_env_steps_sampled": 268000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 267997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 67, "trial_id": "1772b_00000", "date": "2024-01-13_11-35-02", "timestamp": 1705142102, "time_this_iter_s": 32.068060874938965, "time_total_s": 2261.894726037979, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369090>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2261.894726037979, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 5.321428571428571, "ram_util_percent": 57.04285714285714, "gpu_util_percent0": 0.23047619047619047, "vram_util_percent0": 0.09114583333333333}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998876845836639}, "cop_policy": {"total_loss": 9.998876845836639, "policy_loss": -0.0011306001852403823, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.6557289533317089, "mean_kl_loss": 0.008922471184189363, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0008342743385583162}}, "num_env_steps_sampled": 272000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 271997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 271997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 272000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.33447090376092, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 272000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 271997, "timers": {"training_iteration_time_ms": 32004.423, "sample_time_ms": 26363.037, "synch_weights_time_ms": 5.503}, "counters": {"num_env_steps_sampled": 272000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 271997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 68, "trial_id": "1772b_00000", "date": "2024-01-13_11-35-34", "timestamp": 1705142134, "time_this_iter_s": 31.92437767982483, "time_total_s": 2293.819103717804, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368940>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2293.819103717804, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 5.809523809523809, "ram_util_percent": 57.416666666666664, "gpu_util_percent0": 0.22976190476190478, "vram_util_percent0": 0.09221927703373015}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999219930171966}, "cop_policy": {"total_loss": 9.999219930171966, "policy_loss": -0.0007823377050044655, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.7101598829030991, "mean_kl_loss": 0.00273471355506274, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0004171371692791581}}, "num_env_steps_sampled": 276000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 275997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 275997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 276000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.74609299844545, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 276000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 275997, "timers": {"training_iteration_time_ms": 31990.434, "sample_time_ms": 26342.198, "synch_weights_time_ms": 5.599}, "counters": {"num_env_steps_sampled": 276000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 275997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 69, "trial_id": "1772b_00000", "date": "2024-01-13_11-36-06", "timestamp": 1705142166, "time_this_iter_s": 31.819406986236572, "time_total_s": 2325.6385107040405, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4DAB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2325.6385107040405, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 5.253658536585366, "ram_util_percent": 57.90487804878049, "gpu_util_percent0": 0.22756097560975613, "vram_util_percent0": 0.09389688135162601}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998097693920135}, "cop_policy": {"total_loss": 9.998097693920135, "policy_loss": -0.0019055748216203483, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.5795552298426628, "mean_kl_loss": 0.008091304178816473, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0004171371692791581}}, "num_env_steps_sampled": 280000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 279997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 279997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 280000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.26167365793312, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 280000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 279997, "timers": {"training_iteration_time_ms": 32005.943, "sample_time_ms": 26356.199, "synch_weights_time_ms": 5.299}, "counters": {"num_env_steps_sampled": 280000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 279997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 70, "trial_id": "1772b_00000", "date": "2024-01-13_11-36-38", "timestamp": 1705142198, "time_this_iter_s": 31.94275975227356, "time_total_s": 2357.581270456314, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368D30>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2357.581270456314, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 5.045238095238095, "ram_util_percent": 57.790476190476184, "gpu_util_percent0": 0.22952380952380955, "vram_util_percent0": 0.09246341765873016}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998752582073212}, "cop_policy": {"total_loss": 9.998752582073212, "policy_loss": -0.0012499501441197935, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.44810769222676755, "mean_kl_loss": 0.0059460872173019656, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.0004171371692791581}}, "num_env_steps_sampled": 284000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 283997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 283997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 284000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.2898136515412, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 284000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 283997, "timers": {"training_iteration_time_ms": 32028.577, "sample_time_ms": 26373.135, "synch_weights_time_ms": 5.396}, "counters": {"num_env_steps_sampled": 284000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 283997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 71, "trial_id": "1772b_00000", "date": "2024-01-13_11-37-10", "timestamp": 1705142230, "time_this_iter_s": 32.19095063209534, "time_total_s": 2389.7722210884094, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617CCBEB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2389.7722210884094, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 6.57674418604651, "ram_util_percent": 61.00000000000001, "gpu_util_percent0": 0.21744186046511627, "vram_util_percent0": 0.09175902374031009}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99870855808258}, "cop_policy": {"total_loss": 9.99870855808258, "policy_loss": -0.0012925683503226537, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.44485434927046297, "mean_kl_loss": 0.002724098502552863, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.00020856858463957906}}, "num_env_steps_sampled": 288000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 287997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 287997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 288000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.79459743103625, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 288000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 287997, "timers": {"training_iteration_time_ms": 32168.766, "sample_time_ms": 26501.621, "synch_weights_time_ms": 5.699}, "counters": {"num_env_steps_sampled": 288000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 287997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 72, "trial_id": "1772b_00000", "date": "2024-01-13_11-37-43", "timestamp": 1705142263, "time_this_iter_s": 33.39843153953552, "time_total_s": 2423.170652627945, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617C27D00>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2423.170652627945, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 7.631818181818182, "ram_util_percent": 59.44318181818184, "gpu_util_percent0": 0.24909090909090906, "vram_util_percent0": 0.09167110558712123}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999080872535705}, "cop_policy": {"total_loss": 9.999080872535705, "policy_loss": -0.0009196999338882961, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.3956442974507809, "mean_kl_loss": 0.002504045519268061, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 0.00010428429231978953}}, "num_env_steps_sampled": 292000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 291997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 291997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 292000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.92040345665299, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 292000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 291997, "timers": {"training_iteration_time_ms": 32083.849, "sample_time_ms": 26414.23, "synch_weights_time_ms": 5.299}, "counters": {"num_env_steps_sampled": 292000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 291997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 73, "trial_id": "1772b_00000", "date": "2024-01-13_11-38-16", "timestamp": 1705142296, "time_this_iter_s": 32.285338163375854, "time_total_s": 2455.455990791321, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4F400>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2455.455990791321, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 7.885714285714287, "ram_util_percent": 57.73809523809524, "gpu_util_percent0": 0.23047619047619047, "vram_util_percent0": 0.09219215029761904}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99778083562851}, "cop_policy": {"total_loss": 9.99778083562851, "policy_loss": -0.002219549191852366, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.2980679143220186, "mean_kl_loss": 0.003997461839600191, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 5.2142146159894764e-05}}, "num_env_steps_sampled": 296000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 295997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 295997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 296000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.71878050049314, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 296000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 295997, "timers": {"training_iteration_time_ms": 32097.037, "sample_time_ms": 26428.841, "synch_weights_time_ms": 5.254}, "counters": {"num_env_steps_sampled": 296000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 295997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 74, "trial_id": "1772b_00000", "date": "2024-01-13_11-38-48", "timestamp": 1705142328, "time_this_iter_s": 32.080668926239014, "time_total_s": 2487.53665971756, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369510>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2487.53665971756, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 6.523809523809523, "ram_util_percent": 59.48095238095237, "gpu_util_percent0": 0.22285714285714284, "vram_util_percent0": 0.09481569320436509}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.998859107494354}, "cop_policy": {"total_loss": 9.998859107494354, "policy_loss": -0.001140862994247982, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.26891954634338616, "mean_kl_loss": 0.001399532332357012, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 2.6071073079947382e-05}}, "num_env_steps_sampled": 300000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 299997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 299997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 300000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 126.23695024363599, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 300000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 299997, "timers": {"training_iteration_time_ms": 32097.522, "sample_time_ms": 26431.05, "synch_weights_time_ms": 5.809}, "counters": {"num_env_steps_sampled": 300000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 299997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 75, "trial_id": "1772b_00000", "date": "2024-01-13_11-39-20", "timestamp": 1705142360, "time_this_iter_s": 31.690444469451904, "time_total_s": 2519.2271041870117, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369AB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2519.2271041870117, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 13.733333333333333, "ram_util_percent": 60.05476190476189, "gpu_util_percent0": 0.21904761904761907, "vram_util_percent0": 0.09436228918650794}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999372327327729}, "cop_policy": {"total_loss": 9.999372327327729, "policy_loss": -0.0006276370703403699, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.3141431849449873, "mean_kl_loss": 0.001381950374194929, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.3035536539973691e-05}}, "num_env_steps_sampled": 304000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 303997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 303997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 304000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.1892551826953, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 304000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 303997, "timers": {"training_iteration_time_ms": 32127.867, "sample_time_ms": 26451.578, "synch_weights_time_ms": 5.804}, "counters": {"num_env_steps_sampled": 304000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 303997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 76, "trial_id": "1772b_00000", "date": "2024-01-13_11-39-52", "timestamp": 1705142392, "time_this_iter_s": 31.95975613594055, "time_total_s": 2551.1868603229523, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4C0D0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2551.1868603229523, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 5.116666666666667, "ram_util_percent": 60.38095238095238, "gpu_util_percent0": 0.22428571428571434, "vram_util_percent0": 0.09238591269841269}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999648296833039}, "cop_policy": {"total_loss": 9.999648296833039, "policy_loss": -0.00035161857906587104, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.34603140167891977, "mean_kl_loss": 0.0013621956657118516, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 6.5177682699868456e-06}}, "num_env_steps_sampled": 308000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 307997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 307997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 308000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.63387867085156, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 308000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 307997, "timers": {"training_iteration_time_ms": 32105.878, "sample_time_ms": 26432.109, "synch_weights_time_ms": 5.803}, "counters": {"num_env_steps_sampled": 308000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 307997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 77, "trial_id": "1772b_00000", "date": "2024-01-13_11-40-24", "timestamp": 1705142424, "time_this_iter_s": 31.848093271255493, "time_total_s": 2583.0349535942078, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369AB0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2583.0349535942078, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 5.704761904761905, "ram_util_percent": 60.69285714285714, "gpu_util_percent0": 0.2252380952380952, "vram_util_percent0": 0.09221540178571429}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999313199520111}, "cop_policy": {"total_loss": 9.999313199520111, "policy_loss": -0.0006867707801347933, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.2533364113420248, "mean_kl_loss": 0.0028375592451595822, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 3.2588841349934228e-06}}, "num_env_steps_sampled": 312000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 311997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 311997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 312000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 123.75222781753463, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 312000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 311997, "timers": {"training_iteration_time_ms": 32146.682, "sample_time_ms": 26481.663, "synch_weights_time_ms": 5.803}, "counters": {"num_env_steps_sampled": 312000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 311997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 78, "trial_id": "1772b_00000", "date": "2024-01-13_11-40-56", "timestamp": 1705142456, "time_this_iter_s": 32.33120155334473, "time_total_s": 2615.3661551475525, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E6073684C0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2615.3661551475525, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 6.142857142857143, "ram_util_percent": 60.852380952380955, "gpu_util_percent0": 0.2580952380952381, "vram_util_percent0": 0.09183175223214286}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999321556091308}, "cop_policy": {"total_loss": 9.999321556091308, "policy_loss": -0.0006786089027798426, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.25617517717182636, "mean_kl_loss": 0.0008546824130064579, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.6294420674967114e-06}}, "num_env_steps_sampled": 316000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 315997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 315997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 316000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.27577901806525, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 316000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 315997, "timers": {"training_iteration_time_ms": 32184.317, "sample_time_ms": 26525.503, "synch_weights_time_ms": 5.862}, "counters": {"num_env_steps_sampled": 316000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 315997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 79, "trial_id": "1772b_00000", "date": "2024-01-13_11-41-28", "timestamp": 1705142488, "time_this_iter_s": 32.19494652748108, "time_total_s": 2647.5611016750336, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4FAC0>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2647.5611016750336, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 6.180952380952381, "ram_util_percent": 61.03095238095237, "gpu_util_percent0": 0.22785714285714287, "vram_util_percent0": 0.09154885912698413}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99911983013153}, "cop_policy": {"total_loss": 9.99911983013153, "policy_loss": -0.0008802113966396519, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.25141306556761267, "mean_kl_loss": 0.0010597675323424482, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 8.147210337483557e-07}}, "num_env_steps_sampled": 320000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 319997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 319997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 320000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 125.59844902847553, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 320000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 319997, "timers": {"training_iteration_time_ms": 32175.754, "sample_time_ms": 26515.723, "synch_weights_time_ms": 5.92}, "counters": {"num_env_steps_sampled": 320000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 319997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 80, "trial_id": "1772b_00000", "date": "2024-01-13_11-42-00", "timestamp": 1705142520, "time_this_iter_s": 31.857099294662476, "time_total_s": 2679.418200969696, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368280>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2679.418200969696, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 6.4142857142857155, "ram_util_percent": 61.54523809523808, "gpu_util_percent0": 0.23309523809523808, "vram_util_percent0": 0.09263392857142858}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999209856987}, "cop_policy": {"total_loss": 9.999209856987, "policy_loss": -0.0007901147283860155, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.2146237226203084, "mean_kl_loss": 0.002556752526869843, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 4.0736051687417785e-07}}, "num_env_steps_sampled": 324000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 323997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 323997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 324000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.16004981615333, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 324000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 323997, "timers": {"training_iteration_time_ms": 32430.897, "sample_time_ms": 26702.342, "synch_weights_time_ms": 6.376}, "counters": {"num_env_steps_sampled": 324000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 323997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 81, "trial_id": "1772b_00000", "date": "2024-01-13_11-42-35", "timestamp": 1705142555, "time_this_iter_s": 34.74378275871277, "time_total_s": 2714.161983728409, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E60736AA70>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2714.161983728409, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 8.08, "ram_util_percent": 61.855555555555554, "gpu_util_percent0": 0.2997777777777778, "vram_util_percent0": 0.09296513310185185}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.999914348125458}, "cop_policy": {"total_loss": 9.999914348125458, "policy_loss": -8.564141895135435e-05, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.23368964325636626, "mean_kl_loss": 0.0006320780687858018, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 2.0368025843708892e-07}}, "num_env_steps_sampled": 328000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 327997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 327997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 328000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 114.07851425925331, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 328000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 327997, "timers": {"training_iteration_time_ms": 32598.205, "sample_time_ms": 26837.188, "synch_weights_time_ms": 6.22}, "counters": {"num_env_steps_sampled": 328000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 327997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 82, "trial_id": "1772b_00000", "date": "2024-01-13_11-43-10", "timestamp": 1705142590, "time_this_iter_s": 35.07283544540405, "time_total_s": 2749.234819173813, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607368280>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2749.234819173813, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 10.678260869565216, "ram_util_percent": 57.8586956521739, "gpu_util_percent0": 0.20956521739130435, "vram_util_percent0": 0.09286897078804347}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.9989732503891}, "cop_policy": {"total_loss": 9.9989732503891, "policy_loss": -0.0010268617118583735, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.2125843957066536, "mean_kl_loss": 0.001290015920679366, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 1.0184012921854446e-07}}, "num_env_steps_sampled": 332000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 331997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 331997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 332000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 119.93597987463424, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 332000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 331997, "timers": {"training_iteration_time_ms": 32705.439, "sample_time_ms": 26927.313, "synch_weights_time_ms": 6.166}, "counters": {"num_env_steps_sampled": 332000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 331997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 83, "trial_id": "1772b_00000", "date": "2024-01-13_11-43-44", "timestamp": 1705142624, "time_this_iter_s": 33.359647274017334, "time_total_s": 2782.59446644783, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E607369990>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2782.59446644783, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 11.343181818181817, "ram_util_percent": 61.311363636363645, "gpu_util_percent0": 0.24204545454545456, "vram_util_percent0": 0.09353545217803032}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.9999009847641}, "cop_policy": {"total_loss": 9.9999009847641, "policy_loss": -9.908302513608191e-05, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.22923141960054635, "mean_kl_loss": 0.0009496710909502326, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 5.092006460927223e-08}}, "num_env_steps_sampled": 336000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 335997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 335997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 336000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 124.02879888418839, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 336000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 335997, "timers": {"training_iteration_time_ms": 32723.281, "sample_time_ms": 26944.568, "synch_weights_time_ms": 6.21}, "counters": {"num_env_steps_sampled": 336000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 335997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 84, "trial_id": "1772b_00000", "date": "2024-01-13_11-44-16", "timestamp": 1705142656, "time_this_iter_s": 32.259716510772705, "time_total_s": 2814.854182958603, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E60736B130>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2814.854182958603, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 6.990697674418604, "ram_util_percent": 62.05348837209303, "gpu_util_percent0": 0.22697674418604652, "vram_util_percent0": 0.09375}}
{"custom_metrics": {}, "episode_media": {}, "info": {"learner": {"__all__": {"num_agent_steps_trained": 500.0, "num_env_steps_trained": 4000.0, "total_loss": 9.99825963973999}, "cop_policy": {"total_loss": 9.99825963973999, "policy_loss": -0.001740401896614685, "vf_loss": 10.0, "vf_loss_unclipped": 70497704.0, "vf_explained_var": -9.5367431640625e-07, "entropy": 0.1768210856243968, "mean_kl_loss": 0.002496198020165252, "default_optimizer_lr": 0.0003, "curr_lr": 0.0003, "curr_entropy_coeff": 0.0, "curr_kl_coeff": 2.5460032304636115e-08}}, "num_env_steps_sampled": 340000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 339997, "num_agent_steps_trained": 0}, "sampler_results": {"episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episode_media": {}, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}}, "episode_reward_max": 1242.1666666664999, "episode_reward_min": -848.8333333342002, "episode_reward_mean": 227.13833333327605, "episode_len_mean": 68.5, "episodes_this_iter": 0, "policy_reward_min": {"cop_policy": -977.5, "mr_x_policy": -1104.0000000001999}, "policy_reward_max": {"cop_policy": 577.0, "mr_x_policy": 442.50000000060004}, "policy_reward_mean": {"cop_policy": 95.44763513513513, "mr_x_policy": -55.38666666672401}, "hist_stats": {"episode_reward": [-294.9999999997, 40.000000000199925, 218.1666666667, 449.9999999994001, 423.66666666709995, 756.1666666670001, 360.83333333319996, 611.1666666663, 695.5000000005, 388.66666666720005, -7.999999999899998, 95.66666666689997, -333.8333333329, 81.00000000039998, -20.333333332899997, 722.5000000005998, -201.16666666649996, 32.500000000200075, -39.000000000499995, 494.66666666480006, 387.33333333180013, 649.0000000002001, 78.49999999969998, 278.8333333332, -108.33333333339999, -19.333333334, 214.83333333210004, -149.99999999929997, 181.50000000080004, 69.66666666660001, 62.99999999959999, 7.833333333900015, 415.6666666662, 18.999999999799996, 313.83333333210004, 952.3333333334, 394.33333333350004, 271.1666666672, -243.83333333409996, 143.83333333379997, -98.3333333331, 80.1666666665, -11.833333333300004, 302.8333333322, -848.8333333342002, 107.33333333300001, 434.49999999949995, 142.49999999970004, 9.000000000100002, -558.0000000002002, 710.3333333339, 834.8333333322, 378.4999999997999, 38.333333333599995, 902.4999999994999, 5.166666666899985, 416.833333333, 829.9999999997, 68.8333333332, 526.3333333331, -104.33333333310001, 116.5000000001, 569.1666666662, -65.16666666750004, 41.999999999799996, 347.3333333335999, 27.99999999970001, 1107.4999999988001, -187.83333333229996, 1242.1666666664999, -153.49999999899998, -59.166666666999944, -404.8333333338, 42.4999999999, -194.66666666670002, -458.9999999996, 253.66666666559996, 32.33333333339999, 750.8333333329999, 350.49999999880004, 123.99999999990001, 207.3333333338, -98.3333333333, 464.33333333389993, 722.6666666670001, -67.1666666667, 850.0, 896.1666666665, 269.50000000010004, -379.9999999999001, -75.16666666700002, 1126.0000000000002, 209.1666666676, -195.6666666665, -247.49999999960005, 379.66666666759994, 577.1666666671, 1214.9999999998, 424.1666666677, 395.1666666669002], "episode_lengths": [7, 102, 62, 101, 65, 96, 99, 78, 95, 66, 20, 84, 29, 73, 18, 101, 103, 98, 26, 102, 95, 98, 100, 35, 8, 100, 95, 66, 104, 13, 18, 30, 53, 25, 102, 96, 100, 41, 98, 99, 4, 103, 13, 102, 109, 15, 97, 72, 15, 107, 98, 98, 89, 21, 100, 9, 101, 100, 25, 94, 3, 99, 99, 59, 16, 99, 101, 94, 100, 93, 23, 101, 15, 23, 37, 57, 85, 26, 98, 98, 26, 34, 1, 86, 95, 40, 85, 98, 90, 109, 13, 67, 59, 33, 28, 91, 95, 98, 99, 104], "policy_cop_policy_reward": [-200.0, 0.0, 0.0, 138.5, 167.0, 199.5, 208.0, 57.0, 51.5, 288.0, 80.5, 397.0, 308.0, 223.5, 211.5, 236.0, 343.5, 66.0, -305.0, 160.5, 269.5, 125.0, 235.0, 285.5, 74.0, 156.5, 278.5, 172.0, 134.0, 171.0, 28.0, 16.0, 45.5, 150.0, -12.0, 67.5, -273.0, 38.5, 28.0, 218.5, 142.0, -65.5, 107.5, -97.5, 57.5, 289.0, -201.5, 192.5, -428.0, 283.0, -142.5, 73.0, 0.5, -11.5, -64.5, 129.0, 21.0, 258.0, 350.0, -31.0, 101.0, 211.5, 240.0, -266.0, 425.5, 257.0, 213.0, -187.5, -29.0, 191.5, 77.0, 11.0, 0.0, 0.0, 0.0, 161.5, 27.5, -6.0, 9.5, 273.0, -82.0, 5.0, 105.0, -174.0, -347.5, 306.0, 203.5, 20.5, 105.0, 18.5, 103.0, 19.0, 40.0, 119.5, -57.5, 72.5, 110.5, 171.0, 176.5, 8.5, 128.0, 24.0, 161.0, 315.0, 64.5, 386.0, 167.5, 138.5, 318.0, 152.5, -291.5, 99.5, 69.0, 175.0, -977.5, 264.5, 300.5, 276.0, -23.0, 225.0, 0.0, 0.0, 0.0, 325.0, 212.0, -73.5, 4.5, 8.5, 101.5, -47.0, 217.0, 179.5, -929.0, -39.5, 160.5, 26.5, 108.0, 36.5, 198.5, 172.0, 261.0, 124.5, 152.0, 6.0, 15.5, 108.0, 8.5, 53.5, 354.0, 138.5, 442.0, 239.5, 147.5, 215.5, 145.5, 192.0, 11.0, 279.0, 88.5, 114.5, 12.0, 39.5, 53.5, 577.0, 309.5, 100.0, 3.0, 3.0, 285.5, 336.0, -106.0, 141.5, 130.0, 256.0, 26.5, 29.5, 125.0, -10.0, 224.5, 245.0, 0.0, 0.0, -243.5, 151.5, 170.5, 206.5, 70.5, 302.5, 126.0, -292.0, 129.5, 23.0, 14.0, 112.0, -145.0, 293.0, 52.5, 150.5, 21.0, 157.5, 142.5, 327.5, 352.0, -652.5, 130.0, 294.5, 272.0, 338.0, 345.0, -183.5, 18.0, 127.0, 57.0, 114.5, -217.5, -297.0, 8.0, 102.0, 29.5, 114.0, 23.0, 66.0, -319.0, 149.0, 234.0, 246.5, -703.5, 126.0, 235.0, -8.0, 109.0, 32.0, 27.0, 402.0, -87.5, 224.5, 90.5, 88.5, 82.5, 56.0, 119.5, 99.0, 25.5, 75.5, 136.5, -65.0, 267.0, 219.5, 339.0, -13.5, 246.5, 126.5, -114.0, -66.0, 186.5, 327.5, 298.5, -173.5, 513.5, 204.0, -16.5, 255.5, 231.0, 245.0, 163.5, -106.0, 3.0, 10.5, 13.0, 278.0, 312.0, 340.5, -32.0, 147.5, 147.0, -206.0, 46.5, 145.0, 119.5, -65.5, -66.5, 195.0, 319.5, 139.5, 191.0, 159.5, 108.0, 361.0, 174.0, 272.0, 75.0, 232.5, 336.0, -169.5, 97.0, 405.5], "policy_mr_x_policy_reward": [-94.99999999970001, -464.9999999998, -98.3333333333, -315.5000000006, -319.3333333329, 110.66666666699999, 235.83333333320002, -34.3333333337, 186.5000000005, -88.3333333328, -97.4999999999, -109.83333333309999, -127.3333333329, -213.9999999996, -87.8333333329, 442.50000000060004, 86.3333333335, -29.499999999800004, -124.5000000005, -82.33333333520001, -165.1666666682, 232.50000000019998, 81.99999999970001, -0.6666666668000119, -108.33333333339999, -202.333333334, 14.333333332099983, -85.9999999993, 19.500000000799986, -74.33333333339999, -99.00000000040001, -126.6666666661, -42.333333333800006, -141.5000000002, -226.66666666789996, 260.3333333334, 215.33333333349998, -72.33333333279998, 168.66666666589998, -334.1666666662, -98.3333333331, -383.3333333335001, -126.3333333333, -46.66666666780003, -40.833333334200006, -63.66666666699999, -197.00000000049997, -140.0000000003, -122.9999999999, -1104.0000000001999, -118.66666666609997, 281.8333333322, -1.999751475523226e-10, -127.6666666664, -37.50000000049998, -100.83333333310001, -98.666666667, 302.49999999970004, -112.1666666668, 66.8333333331, -104.33333333310001, 38.00000000010001, -10.333333333799962, -28.66666666750001, -107.00000000019999, 146.8333333336, -301.0000000002999, 285.4999999987999, 40.1666666677, 287.1666666664999, -114.99999999900001, -13.166666667000007, -217.8333333338, -124.00000000009999, -90.6666666667, -235.9999999996, -99.3333333344, -135.6666666666, 211.83333333299998, 88.99999999879998, -150.50000000010002, -30.1666666662, -98.3333333333, 42.83333333389996, 150.66666666700002, -13.666666666700024, 37.49999999999997, 352.16666666649996, -200.49999999989998, -682.4999999999001, -101.666666667, 195.50000000000006, -53.333333332399995, -181.1666666665, -234.9999999996, -274.33333333240006, 118.66666666709999, 407.9999999997999, -219.33333333230001, 62.16666666690001]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.623329449664967, "mean_inference_ms": 6.168153890259662, "mean_action_processing_ms": 0.13980654717808874, "mean_env_wait_ms": 0.16720895696912869, "mean_env_render_ms": 0.0}, "num_faulty_episodes": 0, "connector_metrics": {"ObsPreprocessorConnector_ms": 0.0055314308434874565, "StateBufferConnector_ms": 0.005651239174694272, "ViewRequirementAgentConnector_ms": 0.30029850389490176}, "num_healthy_workers": 1, "num_in_flight_async_reqs": 0, "num_remote_worker_restarts": 0, "num_agent_steps_sampled": 339997, "num_agent_steps_trained": 0, "num_env_steps_sampled": 340000, "num_env_steps_trained": 0, "num_env_steps_sampled_this_iter": 4000, "num_env_steps_trained_this_iter": 0, "num_env_steps_sampled_throughput_per_sec": 115.91932712906332, "num_env_steps_trained_throughput_per_sec": 0.0, "timesteps_total": 340000, "num_steps_trained_this_iter": 0, "agent_timesteps_total": 339997, "timers": {"training_iteration_time_ms": 33005.312, "sample_time_ms": 27206.328, "synch_weights_time_ms": 5.659}, "counters": {"num_env_steps_sampled": 340000, "num_env_steps_trained": 0, "num_agent_steps_sampled": 339997, "num_agent_steps_trained": 0}, "done": false, "episodes_total": 231, "training_iteration": 85, "trial_id": "1772b_00000", "date": "2024-01-13_11-44-50", "timestamp": 1705142690, "time_this_iter_s": 34.51526880264282, "time_total_s": 2849.3694517612457, "pid": 3652, "hostname": "LAPTOP-3V3SUFB8", "node_ip": "127.0.0.1", "config": {"extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 1, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0.5, "_fake_gpus": false, "num_learner_workers": 0, "num_gpus_per_learner_worker": 0, "num_cpus_per_learner_worker": 1, "local_gpu_idx": 0, "custom_resources_per_worker": {}, "placement_strategy": "PACK", "eager_tracing": true, "eager_max_retraces": 20, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "torch_compile_learner": false, "torch_compile_learner_what_to_compile": "forward_train", "torch_compile_learner_dynamo_backend": "inductor", "torch_compile_learner_dynamo_mode": null, "torch_compile_worker": false, "torch_compile_worker_dynamo_backend": "onnxrt", "torch_compile_worker_dynamo_mode": null, "env": "scotland_env", "env_config": {}, "observation_space": null, "action_space": null, "env_task_fn": null, "render_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "disable_env_checking": false, "auto_wrap_old_gym_envs": true, "action_mask_key": "action_mask", "_is_atari": null, "env_runner_cls": null, "num_envs_per_worker": 1, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "sample_async": false, "enable_connectors": true, "update_worker_filter_stats": true, "use_worker_filter_stats": true, "rollout_fragment_length": 500, "batch_mode": "truncate_episodes", "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "validate_workers_after_construction": true, "preprocessor_pref": "deepmind", "observation_filter": "NoFilter", "compress_observations": false, "enable_tf1_exec_eagerly": false, "sampler_perf_stats_ema_coef": null, "gamma": 0.99, "lr": 0.0003, "grad_clip": null, "grad_clip_by": "global_norm", "train_batch_size": 4000, "model": {"_disable_preprocessor_api": false, "_disable_action_flattening": false, "fcnet_hiddens": [512, 512, 256], "fcnet_activation": "relu", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": false, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "encoder_latent_dim": null, "always_check_shapes": false, "lstm_use_prev_action_reward": -1, "_use_default_native_models": -1}, "optimizer": {}, "max_requests_in_flight_per_sampler_worker": 2, "_learner_class": null, "_enable_learner_api": true, "explore": true, "exploration_config": {}, "algorithm_config_overrides_per_module": {}, "policy_map_capacity": 100, "policy_mapping_fn": "<function <lambda> at 0x000001E617D4FD00>", "policies_to_train": ["mr_x_policy", "cop_policy"], "policy_states_are_swappable": false, "observation_fn": null, "count_steps_by": "env_steps", "input_config": {}, "actions_in_input_normalized": false, "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_config": {}, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "offline_sampling": false, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_sample_timeout_s": 180.0, "evaluation_parallel_to_training": false, "evaluation_config": null, "off_policy_estimation_methods": {}, "ope_split_batch_by_episode": true, "evaluation_num_workers": 0, "always_attach_evaluation_results": false, "enable_async_evaluation": false, "in_evaluation": false, "sync_filters_on_rollout_workers_timeout_s": 60.0, "keep_per_episode_custom_metrics": false, "metrics_episode_collection_timeout_s": 60.0, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_iteration": null, "min_train_timesteps_per_iteration": 0, "min_sample_timesteps_per_iteration": 0, "export_native_model_files": false, "checkpoint_trainable_policies_only": false, "logger_creator": null, "logger_config": null, "log_level": "WARN", "log_sys_usage": true, "fake_sampler": false, "seed": null, "ignore_worker_failures": false, "recreate_failed_workers": false, "max_num_worker_restarts": 1000, "delay_between_worker_restarts_s": 60.0, "restart_failed_sub_environments": false, "num_consecutive_worker_failures_tolerance": 100, "worker_health_probe_timeout_s": 60, "worker_restore_timeout_s": 1800, "rl_module_spec": "SingleAgentRLModuleSpec(module_class=<class 'ray.rllib.algorithms.ppo.torch.ppo_torch_rl_module.PPOTorchRLModule'>, observation_space=None, action_space=None, model_config_dict=None, catalog_class=<class 'ray.rllib.algorithms.ppo.ppo_catalog.PPOCatalog'>, load_state_path=None)", "_enable_rl_module_api": true, "_AlgorithmConfig__prior_exploration_config": {"type": "StochasticSampling"}, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": true, "_disable_initialize_loss_from_dummy_batch": false, "simple_optimizer": true, "policy_map_cache": -1, "worker_cls": -1, "synchronize_filters": -1, "replay_sequence_length": null, "lr_schedule": null, "use_critic": true, "use_gae": true, "use_kl_loss": true, "kl_coeff": 0.2, "kl_target": 0.01, "sgd_minibatch_size": 500, "num_sgd_iter": 10, "shuffle_sequences": true, "vf_loss_coeff": 1.0, "entropy_coeff": 0.0, "entropy_coeff_schedule": null, "clip_param": 0.3, "vf_clip_param": 10.0, "vf_share_layers": -1, "optimization": {"optimizer": "adam", "adam_epsilon": 1e-08, "adam_beta1": 0.9, "adam_beta2": 0.999}, "stop": {"episodes_total": 1000}, "custom_model": "cc_model", "checkpoint_freq": 5, "name": "PPO", "local_dir": "C:/Users/cmich/Documents/Projects/school/scotland_yard_thesis/tuned_results", "checkpoint_at_end": true, "__stdout_file__": null, "__stderr_file__": null, "lambda": 1.0, "input": "sampler", "policies": {"mr_x_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (17,), float32)", "Discrete(4)", null], "cop_policy": [null, "Box([ 0.  0.  0.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0.], [24. 24. 24. 10. 10. 10. 10. 20. 10. 10. 20. 10. 10. 20.], (14,), float32)", "Discrete(4)", null]}, "callbacks": "<class 'ray.rllib.algorithms.callbacks.DefaultCallbacks'>", "create_env_on_driver": false, "custom_eval_function": null, "framework": "torch", "num_cpus_for_driver": 1, "num_workers": 1}, "time_since_restore": 2849.3694517612457, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 10.624444444444444, "ram_util_percent": 63.87333333333333, "gpu_util_percent0": 0.21777777777777776, "vram_util_percent0": 0.09362702546296298}}
